{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "T2T_ViT_CIFAR_10.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6681b6aa3fee44bf8dcb86e7aab90b33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0b6ff3553a5a45c5a6268116859a1f2f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c3db4b6e707a4ce3a6fd2f2c6c6c17db",
              "IPY_MODEL_dbc47e1ac34944c5a197f65e343a33db"
            ]
          }
        },
        "0b6ff3553a5a45c5a6268116859a1f2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c3db4b6e707a4ce3a6fd2f2c6c6c17db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0b2983aebae84b71a99461d8caa6d805",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 10,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 10,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f515b5ce7fc447329f91a3c12578c17c"
          }
        },
        "dbc47e1ac34944c5a197f65e343a33db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d19c109680404691abfd907576ea9101",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 10/10 [02:20&lt;00:00, 14.02s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fe059114cee74e7db3a5348ef233b5eb"
          }
        },
        "0b2983aebae84b71a99461d8caa6d805": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f515b5ce7fc447329f91a3c12578c17c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d19c109680404691abfd907576ea9101": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fe059114cee74e7db3a5348ef233b5eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "98ad330e902f4068aced99e3e6976a75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_bdd2deb6eae94976802220d7629ecefc",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3953b84c0cb94a3c92e0233e09be47c8",
              "IPY_MODEL_05d3c5a699a342438cabf3aa5f4bc51b"
            ]
          }
        },
        "bdd2deb6eae94976802220d7629ecefc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3953b84c0cb94a3c92e0233e09be47c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a7edf0d895834dbb806ab5c8b4c86733",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 10,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 10,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_542691885c654d7cb02d67ad6755680f"
          }
        },
        "05d3c5a699a342438cabf3aa5f4bc51b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5147e212ef1d4cc5b63d8c05be0c566b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 10/10 [00:34&lt;00:00,  3.40s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_634a5e2ae53f4a2c979072af4a5d7391"
          }
        },
        "a7edf0d895834dbb806ab5c8b4c86733": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "542691885c654d7cb02d67ad6755680f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5147e212ef1d4cc5b63d8c05be0c566b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "634a5e2ae53f4a2c979072af4a5d7391": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f237fced75d64f77a64553329ccf9a23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8644ba04238e4d28a56166ef4bcdfde2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_bf446d5986aa4fee88e777a2013782c4",
              "IPY_MODEL_3e04b216c1854eac82169b52f774ad23"
            ]
          }
        },
        "8644ba04238e4d28a56166ef4bcdfde2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bf446d5986aa4fee88e777a2013782c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c8f686de94394e8289689432f0ffe9b7",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 50000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 50000,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_62d33169f73e415eb3e64aa898b805fd"
          }
        },
        "3e04b216c1854eac82169b52f774ad23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_40c7267c422c447dabca413ee4fed1c3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 50000/50000 [02:25&lt;00:00, 344.71it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2bfe6f9f1d6d49ce9876231e24c1926e"
          }
        },
        "c8f686de94394e8289689432f0ffe9b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "62d33169f73e415eb3e64aa898b805fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "40c7267c422c447dabca413ee4fed1c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2bfe6f9f1d6d49ce9876231e24c1926e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSDNaj2RzPq6",
        "outputId": "4c094bd3-7355-4aa6-94b9-7f9bf5ca7e94"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Feb 19 07:17:31 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.39       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Swkafvys1zGC",
        "outputId": "aaea3aa4-651e-4dbe-97cd-6ea36dd84fc6"
      },
      "source": [
        "#get CIFAR-10 images in jpg format from this repository\r\n",
        "!git clone https://github.com/YoongiKim/CIFAR-10-images"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'CIFAR-10-images'...\n",
            "remote: Enumerating objects: 60027, done.\u001b[K\n",
            "remote: Total 60027 (delta 0), reused 0 (delta 0), pack-reused 60027\u001b[K\n",
            "Receiving objects: 100% (60027/60027), 19.94 MiB | 13.90 MiB/s, done.\n",
            "Resolving deltas: 100% (59990/59990), done.\n",
            "Checking out files: 100% (60001/60001), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153,
          "referenced_widgets": [
            "6681b6aa3fee44bf8dcb86e7aab90b33",
            "0b6ff3553a5a45c5a6268116859a1f2f",
            "c3db4b6e707a4ce3a6fd2f2c6c6c17db",
            "dbc47e1ac34944c5a197f65e343a33db",
            "0b2983aebae84b71a99461d8caa6d805",
            "f515b5ce7fc447329f91a3c12578c17c",
            "d19c109680404691abfd907576ea9101",
            "fe059114cee74e7db3a5348ef233b5eb",
            "98ad330e902f4068aced99e3e6976a75",
            "bdd2deb6eae94976802220d7629ecefc",
            "3953b84c0cb94a3c92e0233e09be47c8",
            "05d3c5a699a342438cabf3aa5f4bc51b",
            "a7edf0d895834dbb806ab5c8b4c86733",
            "542691885c654d7cb02d67ad6755680f",
            "5147e212ef1d4cc5b63d8c05be0c566b",
            "634a5e2ae53f4a2c979072af4a5d7391"
          ]
        },
        "id": "si10HcZQ9E55",
        "outputId": "2c6362ce-900c-4018-a8d0-f37f7b241379"
      },
      "source": [
        "import os\r\n",
        "from tqdm.auto import tqdm\r\n",
        "from PIL import Image\r\n",
        "\r\n",
        "#get labels of data\r\n",
        "cifar_dir = '/content/CIFAR-10-images'\r\n",
        "label_list = []\r\n",
        "for dir in os.listdir(cifar_dir):\r\n",
        "    if dir == 'train':\r\n",
        "        for label in os.listdir(os.path.join(cifar_dir, dir)):\r\n",
        "            label_list.append(label)\r\n",
        "\r\n",
        "#make train and validation folders\r\n",
        "for f in ['train', 'val']:\r\n",
        "    for label in label_list:\r\n",
        "        os.makedirs(f'/content/data/{f}/{label}', exist_ok=True)\r\n",
        "\r\n",
        "#resize images to 224 by 224\r\n",
        "for f_in in ['train', 'test']:\r\n",
        "    print(f'{f_in} folder')\r\n",
        "    for label in tqdm(label_list):\r\n",
        "        dir = f'{cifar_dir}/{f_in}/{label}'\r\n",
        "        for image in os.listdir(dir):\r\n",
        "            path_in = os.path.join(dir, image)\r\n",
        "            I = Image.open(path_in).resize((224, 224))\r\n",
        "            if f_in == 'train':\r\n",
        "                f_out = 'train'\r\n",
        "            else:\r\n",
        "                f_out = 'val'\r\n",
        "            path_out = f'/content/data/{f_out}/{label}/{image}'\r\n",
        "            I.save(path_out)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train folder\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6681b6aa3fee44bf8dcb86e7aab90b33",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "test folder\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "98ad330e902f4068aced99e3e6976a75",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103,
          "referenced_widgets": [
            "f237fced75d64f77a64553329ccf9a23",
            "8644ba04238e4d28a56166ef4bcdfde2",
            "bf446d5986aa4fee88e777a2013782c4",
            "3e04b216c1854eac82169b52f774ad23",
            "c8f686de94394e8289689432f0ffe9b7",
            "62d33169f73e415eb3e64aa898b805fd",
            "40c7267c422c447dabca413ee4fed1c3",
            "2bfe6f9f1d6d49ce9876231e24c1926e"
          ]
        },
        "id": "OXNcKSQ5JzF0",
        "outputId": "dde578d1-f9ca-4100-a752-9159b06ba2b9"
      },
      "source": [
        "#calculate the means and standard deviations of train data\r\n",
        "import cv2\r\n",
        "import numpy as np\r\n",
        "from pathlib import Path\r\n",
        "\r\n",
        "path_images = Path('/content/data/train')\r\n",
        "num_images = len(list(path_images.glob('**/*.jpg')))\r\n",
        "num_channels = 3\r\n",
        "num_pixels = 0\r\n",
        "channel_sum = np.zeros(num_channels)\r\n",
        "channel_square_sum = np.zeros(num_channels)\r\n",
        "\r\n",
        "for image in tqdm(path_images.glob('**/*.jpg'), total=num_images):\r\n",
        "    img = cv2.imread(str(image))\r\n",
        "    img = img / 255.0\r\n",
        "    num_pixels += img.size / num_channels\r\n",
        "    channel_sum += np.sum(img, axis=(0, 1))\r\n",
        "    channel_square_sum += np.sum(np.square(img), axis=(0, 1))\r\n",
        "mean = list(channel_sum / num_pixels)\r\n",
        "std = list(np.sqrt(channel_square_sum / num_pixels - np.square(mean)))\r\n",
        "\r\n",
        "mean[::-1], std[::-1]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f237fced75d64f77a64553329ccf9a23",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=50000.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([0.4913320721179005, 0.4819964753151303, 0.4466457658532243],\n",
              " [0.2440862706333845, 0.24137420221502995, 0.25950901797186166])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1lWN1NBd5RlC",
        "outputId": "941b9ab6-09af-4170-801a-111dc59da7ef"
      },
      "source": [
        "#install timm and clone T2T-ViT repository\r\n",
        "!pip install timm\r\n",
        "!git clone https://github.com/yitu-opensource/T2T-ViT"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: timm in /usr/local/lib/python3.6/dist-packages (0.3.4)\n",
            "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.6/dist-packages (from timm) (1.7.0+cu101)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (from timm) (0.8.1+cu101)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.4->timm) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch>=1.4->timm) (1.19.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.4->timm) (0.16.0)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.4->timm) (0.8)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision->timm) (7.0.0)\n",
            "fatal: destination path 'T2T-ViT' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owzKbWAU4Mhy",
        "outputId": "0c5d125e-a6f9-49df-c21d-f33e49dcc912"
      },
      "source": [
        "#train T2T-ViT on CIFAR-10\r\n",
        "import os\r\n",
        "os.chdir('/content/T2T-ViT')\r\n",
        "\r\n",
        "PATH_TO_DATA = '/content/data'\r\n",
        "\r\n",
        "!bash distributed_train.sh 1 \"$PATH_TO_DATA\"\\\r\n",
        "    --model T2t_vit_14\\\r\n",
        "    --batch-size 32\\\r\n",
        "    --num-classes 10\\\r\n",
        "    --img-size 224\\\r\n",
        "    --mean 0.491 0.482 0.447\\\r\n",
        "    --std 0.244 0.241 0.260\\\r\n",
        "    --lr 1e-4\\\r\n",
        "    --epochs 40\\"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training with a single process on 1 GPUs.\n",
            "adopt performer encoder for tokens-to-token\n",
            "Model T2t_vit_14 created, param count: 21164400\n",
            "Data processing configuration for current model + dataset:\n",
            "\tinput_size: (3, 224, 224)\n",
            "\tinterpolation: bicubic\n",
            "\tmean: (0.491, 0.482, 0.447)\n",
            "\tstd: (0.244, 0.241, 0.26)\n",
            "\tcrop_pct: 0.9\n",
            "AMP not enabled. Training in float32.\n",
            "Scheduled epochs: 50\n",
            "Train: 0 [   0/1562 (  0%)]  Loss:  2.301804 (2.3018)  Time: 1.918s,   16.69/s  (1.918s,   16.69/s)  LR: 1.000e-06  Data: 1.242 (1.242)\n",
            "Train: 0 [  50/1562 (  3%)]  Loss:  2.224470 (2.3247)  Time: 0.321s,   99.59/s  (0.322s,   99.48/s)  LR: 1.000e-06  Data: 0.003 (0.028)\n",
            "Train: 0 [ 100/1562 (  6%)]  Loss:  2.278226 (2.3211)  Time: 0.286s,  111.72/s  (0.304s,  105.20/s)  LR: 1.000e-06  Data: 0.004 (0.016)\n",
            "Train: 0 [ 150/1562 ( 10%)]  Loss:  2.295002 (2.3180)  Time: 0.286s,  112.06/s  (0.298s,  107.26/s)  LR: 1.000e-06  Data: 0.004 (0.012)\n",
            "Train: 0 [ 200/1562 ( 13%)]  Loss:  2.283942 (2.3145)  Time: 0.285s,  112.19/s  (0.296s,  108.25/s)  LR: 1.000e-06  Data: 0.004 (0.010)\n",
            "Train: 0 [ 250/1562 ( 16%)]  Loss:  2.334743 (2.3131)  Time: 0.287s,  111.48/s  (0.294s,  108.90/s)  LR: 1.000e-06  Data: 0.004 (0.009)\n",
            "Train: 0 [ 300/1562 ( 19%)]  Loss:  2.251007 (2.3105)  Time: 0.286s,  112.05/s  (0.293s,  109.36/s)  LR: 1.000e-06  Data: 0.004 (0.008)\n",
            "Train: 0 [ 350/1562 ( 22%)]  Loss:  2.300412 (2.3081)  Time: 0.286s,  111.95/s  (0.292s,  109.68/s)  LR: 1.000e-06  Data: 0.004 (0.007)\n",
            "Train: 0 [ 400/1562 ( 26%)]  Loss:  2.331885 (2.3050)  Time: 0.287s,  111.68/s  (0.291s,  109.91/s)  LR: 1.000e-06  Data: 0.004 (0.007)\n",
            "Train: 0 [ 450/1562 ( 29%)]  Loss:  2.308063 (2.3044)  Time: 0.285s,  112.21/s  (0.291s,  110.12/s)  LR: 1.000e-06  Data: 0.004 (0.007)\n",
            "Train: 0 [ 500/1562 ( 32%)]  Loss:  2.312541 (2.3021)  Time: 0.288s,  111.29/s  (0.290s,  110.26/s)  LR: 1.000e-06  Data: 0.004 (0.006)\n",
            "Train: 0 [ 550/1562 ( 35%)]  Loss:  2.308537 (2.3006)  Time: 0.287s,  111.45/s  (0.290s,  110.40/s)  LR: 1.000e-06  Data: 0.004 (0.006)\n",
            "Train: 0 [ 600/1562 ( 38%)]  Loss:  2.339959 (2.2986)  Time: 0.286s,  111.75/s  (0.290s,  110.49/s)  LR: 1.000e-06  Data: 0.004 (0.006)\n",
            "Train: 0 [ 650/1562 ( 42%)]  Loss:  2.231639 (2.2975)  Time: 0.286s,  111.90/s  (0.289s,  110.58/s)  LR: 1.000e-06  Data: 0.004 (0.006)\n",
            "Train: 0 [ 700/1562 ( 45%)]  Loss:  2.353251 (2.2966)  Time: 0.286s,  111.93/s  (0.289s,  110.65/s)  LR: 1.000e-06  Data: 0.004 (0.006)\n",
            "Train: 0 [ 750/1562 ( 48%)]  Loss:  2.272642 (2.2957)  Time: 0.290s,  110.17/s  (0.289s,  110.70/s)  LR: 1.000e-06  Data: 0.004 (0.005)\n",
            "Train: 0 [ 800/1562 ( 51%)]  Loss:  2.289325 (2.2952)  Time: 0.286s,  112.02/s  (0.289s,  110.77/s)  LR: 1.000e-06  Data: 0.004 (0.005)\n",
            "Train: 0 [ 850/1562 ( 54%)]  Loss:  2.270022 (2.2942)  Time: 0.286s,  111.98/s  (0.289s,  110.81/s)  LR: 1.000e-06  Data: 0.004 (0.005)\n",
            "Train: 0 [ 900/1562 ( 58%)]  Loss:  2.335984 (2.2938)  Time: 0.286s,  111.92/s  (0.289s,  110.85/s)  LR: 1.000e-06  Data: 0.004 (0.005)\n",
            "Train: 0 [ 950/1562 ( 61%)]  Loss:  2.251245 (2.2929)  Time: 0.288s,  111.14/s  (0.289s,  110.88/s)  LR: 1.000e-06  Data: 0.004 (0.005)\n",
            "Train: 0 [1000/1562 ( 64%)]  Loss:  2.341679 (2.2925)  Time: 0.286s,  111.94/s  (0.289s,  110.90/s)  LR: 1.000e-06  Data: 0.004 (0.005)\n",
            "Train: 0 [1050/1562 ( 67%)]  Loss:  2.294117 (2.2917)  Time: 0.286s,  112.05/s  (0.288s,  110.93/s)  LR: 1.000e-06  Data: 0.004 (0.005)\n",
            "Train: 0 [1100/1562 ( 70%)]  Loss:  2.266169 (2.2914)  Time: 0.285s,  112.12/s  (0.288s,  110.95/s)  LR: 1.000e-06  Data: 0.004 (0.005)\n",
            "Train: 0 [1150/1562 ( 74%)]  Loss:  2.311920 (2.2914)  Time: 0.289s,  110.88/s  (0.288s,  110.98/s)  LR: 1.000e-06  Data: 0.004 (0.005)\n",
            "Train: 0 [1200/1562 ( 77%)]  Loss:  2.351649 (2.2915)  Time: 0.287s,  111.62/s  (0.288s,  111.00/s)  LR: 1.000e-06  Data: 0.004 (0.005)\n",
            "Train: 0 [1250/1562 ( 80%)]  Loss:  2.258360 (2.2908)  Time: 0.286s,  111.79/s  (0.288s,  111.02/s)  LR: 1.000e-06  Data: 0.004 (0.005)\n",
            "Train: 0 [1300/1562 ( 83%)]  Loss:  2.266768 (2.2905)  Time: 0.289s,  110.90/s  (0.288s,  111.04/s)  LR: 1.000e-06  Data: 0.004 (0.005)\n",
            "Train: 0 [1350/1562 ( 86%)]  Loss:  2.265964 (2.2905)  Time: 0.286s,  111.85/s  (0.288s,  111.06/s)  LR: 1.000e-06  Data: 0.004 (0.005)\n",
            "Train: 0 [1400/1562 ( 90%)]  Loss:  2.307370 (2.2896)  Time: 0.289s,  110.89/s  (0.288s,  111.07/s)  LR: 1.000e-06  Data: 0.004 (0.005)\n",
            "Train: 0 [1450/1562 ( 93%)]  Loss:  2.331541 (2.2892)  Time: 0.285s,  112.14/s  (0.288s,  111.09/s)  LR: 1.000e-06  Data: 0.004 (0.005)\n",
            "Train: 0 [1500/1562 ( 96%)]  Loss:  2.313943 (2.2888)  Time: 0.287s,  111.60/s  (0.288s,  111.10/s)  LR: 1.000e-06  Data: 0.004 (0.005)\n",
            "Train: 0 [1550/1562 ( 99%)]  Loss:  2.284742 (2.2883)  Time: 0.283s,  113.15/s  (0.288s,  111.12/s)  LR: 1.000e-06  Data: 0.003 (0.005)\n",
            "Train: 0 [1561/1562 (100%)]  Loss:  2.288168 (2.2881)  Time: 0.368s,   86.96/s  (0.288s,  111.11/s)  LR: 1.000e-06  Data: 0.086 (0.005)\n",
            "Test: [   0/312]  Time: 0.825 (0.825)  Loss:  2.3371 (2.3371)  Acc@1:  0.0000 ( 0.0000)  Acc@5: 56.2500 (56.2500)\n",
            "Test: [  50/312]  Time: 0.087 (0.112)  Loss:  2.2087 (2.2058)  Acc@1:  9.3750 ( 2.0221)  Acc@5: 71.8750 (70.8333)\n",
            "Test: [ 100/312]  Time: 0.090 (0.102)  Loss:  2.1602 (2.2009)  Acc@1:  9.3750 ( 5.8787)  Acc@5: 65.6250 (69.0285)\n",
            "Test: [ 150/312]  Time: 0.091 (0.099)  Loss:  2.2575 (2.2055)  Acc@1:  0.0000 ( 4.6978)  Acc@5: 65.6250 (67.0944)\n",
            "Test: [ 200/312]  Time: 0.089 (0.097)  Loss:  1.8667 (2.1675)  Acc@1: 62.5000 (10.9919)  Acc@5: 87.5000 (72.3725)\n",
            "Test: [ 250/312]  Time: 0.087 (0.096)  Loss:  2.1202 (2.1401)  Acc@1: 62.5000 (14.6414)  Acc@5: 81.2500 (75.6599)\n",
            "Test: [ 300/312]  Time: 0.086 (0.096)  Loss:  2.2447 (2.1340)  Acc@1: 25.0000 (20.2243)  Acc@5: 68.7500 (76.2874)\n",
            "Test: [ 312/312]  Time: 0.137 (0.096)  Loss:  2.2208 (2.1362)  Acc@1: 12.5000 (20.1800)  Acc@5: 75.0000 (76.4600)\n",
            "Test (EMA): [   0/312]  Time: 0.939 (0.939)  Loss:  2.0401 (2.0401)  Acc@1:  0.0000 ( 0.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test (EMA): [  50/312]  Time: 0.100 (0.112)  Loss:  2.2915 (2.1462)  Acc@1:  0.0000 ( 0.0000)  Acc@5: 100.0000 (99.8775)\n",
            "Test (EMA): [ 100/312]  Time: 0.095 (0.103)  Loss:  2.6601 (2.0383)  Acc@1:  0.0000 (30.9406)  Acc@5:  0.0000 (92.7599)\n",
            "Test (EMA): [ 150/312]  Time: 0.094 (0.099)  Loss:  2.5253 (2.2230)  Acc@1:  0.0000 (20.6954)  Acc@5: 28.1250 (69.3088)\n",
            "Test (EMA): [ 200/312]  Time: 0.100 (0.097)  Loss:  2.6003 (2.3284)  Acc@1:  0.0000 (15.5473)  Acc@5:  3.1250 (53.5137)\n",
            "Test (EMA): [ 250/312]  Time: 0.093 (0.096)  Loss:  2.5944 (2.3140)  Acc@1:  0.0000 (12.4502)  Acc@5: 28.1250 (55.5030)\n",
            "Test (EMA): [ 300/312]  Time: 0.086 (0.096)  Loss:  2.5032 (2.3559)  Acc@1:  0.0000 (10.3821)  Acc@5: 87.5000 (53.9867)\n",
            "Test (EMA): [ 312/312]  Time: 0.132 (0.095)  Loss:  2.5200 (2.3619)  Acc@1:  0.0000 (10.0000)  Acc@5: 68.7500 (55.0200)\n",
            "Current checkpoints:\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-0.pth.tar', 10.0)\n",
            "\n",
            "Train: 1 [   0/1562 (  0%)]  Loss:  2.269317 (2.2693)  Time: 1.649s,   19.41/s  (1.649s,   19.41/s)  LR: 3.400e-05  Data: 1.179 (1.179)\n",
            "Train: 1 [  50/1562 (  3%)]  Loss:  2.204479 (2.3071)  Time: 0.286s,  111.80/s  (0.319s,  100.38/s)  LR: 3.400e-05  Data: 0.004 (0.027)\n",
            "Train: 1 [ 100/1562 (  6%)]  Loss:  2.142066 (2.2890)  Time: 0.286s,  111.91/s  (0.303s,  105.65/s)  LR: 3.400e-05  Data: 0.004 (0.016)\n",
            "Train: 1 [ 150/1562 ( 10%)]  Loss:  2.293084 (2.2839)  Time: 0.289s,  110.68/s  (0.297s,  107.58/s)  LR: 3.400e-05  Data: 0.004 (0.012)\n",
            "Train: 1 [ 200/1562 ( 13%)]  Loss:  2.301090 (2.2770)  Time: 0.285s,  112.13/s  (0.295s,  108.57/s)  LR: 3.400e-05  Data: 0.004 (0.010)\n",
            "Train: 1 [ 250/1562 ( 16%)]  Loss:  2.287445 (2.2706)  Time: 0.286s,  112.04/s  (0.293s,  109.17/s)  LR: 3.400e-05  Data: 0.003 (0.008)\n",
            "Train: 1 [ 300/1562 ( 19%)]  Loss:  2.255993 (2.2688)  Time: 0.297s,  107.89/s  (0.292s,  109.53/s)  LR: 3.400e-05  Data: 0.004 (0.008)\n",
            "Train: 1 [ 350/1562 ( 22%)]  Loss:  2.214731 (2.2626)  Time: 0.286s,  111.87/s  (0.291s,  109.82/s)  LR: 3.400e-05  Data: 0.004 (0.007)\n",
            "Train: 1 [ 400/1562 ( 26%)]  Loss:  2.270110 (2.2570)  Time: 0.286s,  111.98/s  (0.291s,  110.05/s)  LR: 3.400e-05  Data: 0.004 (0.007)\n",
            "Train: 1 [ 450/1562 ( 29%)]  Loss:  2.213631 (2.2551)  Time: 0.285s,  112.16/s  (0.290s,  110.22/s)  LR: 3.400e-05  Data: 0.004 (0.006)\n",
            "Train: 1 [ 500/1562 ( 32%)]  Loss:  2.261874 (2.2523)  Time: 0.286s,  111.93/s  (0.290s,  110.37/s)  LR: 3.400e-05  Data: 0.004 (0.006)\n",
            "Train: 1 [ 550/1562 ( 35%)]  Loss:  2.188003 (2.2484)  Time: 0.287s,  111.63/s  (0.290s,  110.44/s)  LR: 3.400e-05  Data: 0.004 (0.006)\n",
            "Train: 1 [ 600/1562 ( 38%)]  Loss:  2.276000 (2.2460)  Time: 0.286s,  111.84/s  (0.290s,  110.52/s)  LR: 3.400e-05  Data: 0.004 (0.006)\n",
            "Train: 1 [ 650/1562 ( 42%)]  Loss:  2.242916 (2.2450)  Time: 0.286s,  111.94/s  (0.289s,  110.61/s)  LR: 3.400e-05  Data: 0.004 (0.006)\n",
            "Train: 1 [ 700/1562 ( 45%)]  Loss:  2.182034 (2.2442)  Time: 0.286s,  112.05/s  (0.289s,  110.69/s)  LR: 3.400e-05  Data: 0.004 (0.005)\n",
            "Train: 1 [ 750/1562 ( 48%)]  Loss:  2.247413 (2.2431)  Time: 0.286s,  112.03/s  (0.289s,  110.75/s)  LR: 3.400e-05  Data: 0.004 (0.005)\n",
            "Train: 1 [ 800/1562 ( 51%)]  Loss:  2.190982 (2.2418)  Time: 0.286s,  112.04/s  (0.289s,  110.80/s)  LR: 3.400e-05  Data: 0.004 (0.005)\n",
            "Train: 1 [ 850/1562 ( 54%)]  Loss:  2.242065 (2.2407)  Time: 0.287s,  111.63/s  (0.289s,  110.84/s)  LR: 3.400e-05  Data: 0.004 (0.005)\n",
            "Train: 1 [ 900/1562 ( 58%)]  Loss:  2.050177 (2.2399)  Time: 0.286s,  112.08/s  (0.289s,  110.89/s)  LR: 3.400e-05  Data: 0.004 (0.005)\n",
            "Train: 1 [ 950/1562 ( 61%)]  Loss:  2.142761 (2.2374)  Time: 0.286s,  111.94/s  (0.288s,  110.92/s)  LR: 3.400e-05  Data: 0.004 (0.005)\n",
            "Train: 1 [1000/1562 ( 64%)]  Loss:  2.222620 (2.2363)  Time: 0.288s,  111.30/s  (0.288s,  110.96/s)  LR: 3.400e-05  Data: 0.004 (0.005)\n",
            "Train: 1 [1050/1562 ( 67%)]  Loss:  2.071068 (2.2356)  Time: 0.290s,  110.23/s  (0.288s,  110.99/s)  LR: 3.400e-05  Data: 0.004 (0.005)\n",
            "Train: 1 [1100/1562 ( 70%)]  Loss:  2.199819 (2.2348)  Time: 0.289s,  110.57/s  (0.288s,  111.02/s)  LR: 3.400e-05  Data: 0.007 (0.005)\n",
            "Train: 1 [1150/1562 ( 74%)]  Loss:  2.271532 (2.2357)  Time: 0.286s,  111.83/s  (0.288s,  111.03/s)  LR: 3.400e-05  Data: 0.004 (0.005)\n",
            "Train: 1 [1200/1562 ( 77%)]  Loss:  2.122958 (2.2360)  Time: 0.289s,  110.76/s  (0.288s,  111.05/s)  LR: 3.400e-05  Data: 0.004 (0.005)\n",
            "Train: 1 [1250/1562 ( 80%)]  Loss:  2.260658 (2.2343)  Time: 0.288s,  111.23/s  (0.288s,  111.07/s)  LR: 3.400e-05  Data: 0.004 (0.005)\n",
            "Train: 1 [1300/1562 ( 83%)]  Loss:  2.093137 (2.2337)  Time: 0.286s,  111.90/s  (0.288s,  111.09/s)  LR: 3.400e-05  Data: 0.004 (0.005)\n",
            "Train: 1 [1350/1562 ( 86%)]  Loss:  2.242921 (2.2328)  Time: 0.287s,  111.67/s  (0.288s,  111.10/s)  LR: 3.400e-05  Data: 0.004 (0.005)\n",
            "Train: 1 [1400/1562 ( 90%)]  Loss:  2.287579 (2.2304)  Time: 0.286s,  111.79/s  (0.288s,  111.12/s)  LR: 3.400e-05  Data: 0.004 (0.005)\n",
            "Train: 1 [1450/1562 ( 93%)]  Loss:  2.201641 (2.2296)  Time: 0.292s,  109.63/s  (0.288s,  111.14/s)  LR: 3.400e-05  Data: 0.004 (0.005)\n",
            "Train: 1 [1500/1562 ( 96%)]  Loss:  2.134299 (2.2287)  Time: 0.290s,  110.44/s  (0.288s,  111.16/s)  LR: 3.400e-05  Data: 0.004 (0.005)\n",
            "Train: 1 [1550/1562 ( 99%)]  Loss:  2.161887 (2.2267)  Time: 0.283s,  113.05/s  (0.288s,  111.17/s)  LR: 3.400e-05  Data: 0.003 (0.005)\n",
            "Train: 1 [1561/1562 (100%)]  Loss:  2.052235 (2.2260)  Time: 0.370s,   86.57/s  (0.288s,  111.16/s)  LR: 3.400e-05  Data: 0.090 (0.005)\n",
            "Test: [   0/312]  Time: 0.805 (0.805)  Loss:  2.2828 (2.2828)  Acc@1:  6.2500 ( 6.2500)  Acc@5: 68.7500 (68.7500)\n",
            "Test: [  50/312]  Time: 0.093 (0.112)  Loss:  1.4449 (1.8023)  Acc@1: 93.7500 (40.3799)  Acc@5: 100.0000 (86.5809)\n",
            "Test: [ 100/312]  Time: 0.095 (0.102)  Loss:  1.7666 (1.8699)  Acc@1: 65.6250 (36.3861)  Acc@5: 96.8750 (84.3750)\n",
            "Test: [ 150/312]  Time: 0.099 (0.099)  Loss:  2.0277 (1.8589)  Acc@1: 31.2500 (41.1010)  Acc@5: 68.7500 (85.0786)\n",
            "Test: [ 200/312]  Time: 0.089 (0.097)  Loss:  1.9125 (1.9052)  Acc@1: 12.5000 (33.2245)  Acc@5: 78.1250 (83.6443)\n",
            "Test: [ 250/312]  Time: 0.088 (0.097)  Loss:  1.7542 (1.9360)  Acc@1: 34.3750 (29.7809)  Acc@5: 90.6250 (83.0802)\n",
            "Test: [ 300/312]  Time: 0.086 (0.096)  Loss:  1.8898 (1.9060)  Acc@1:  0.0000 (29.2670)  Acc@5: 93.7500 (84.9356)\n",
            "Test: [ 312/312]  Time: 0.132 (0.096)  Loss:  1.8916 (1.9079)  Acc@1:  0.0000 (28.2000)  Acc@5: 100.0000 (85.2800)\n",
            "Test (EMA): [   0/312]  Time: 0.869 (0.869)  Loss:  2.0568 (2.0568)  Acc@1:  0.0000 ( 0.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test (EMA): [  50/312]  Time: 0.093 (0.111)  Loss:  2.2827 (2.1403)  Acc@1:  0.0000 ( 0.0000)  Acc@5: 96.8750 (98.7132)\n",
            "Test (EMA): [ 100/312]  Time: 0.094 (0.102)  Loss:  2.5201 (2.0563)  Acc@1:  0.0000 (30.9406)  Acc@5:  0.0000 (91.7698)\n",
            "Test (EMA): [ 150/312]  Time: 0.099 (0.099)  Loss:  2.4351 (2.1977)  Acc@1:  0.0000 (20.6954)  Acc@5: 53.1250 (72.2889)\n",
            "Test (EMA): [ 200/312]  Time: 0.092 (0.098)  Loss:  2.4336 (2.2793)  Acc@1:  0.0000 (15.5473)  Acc@5: 53.1250 (59.4527)\n",
            "Test (EMA): [ 250/312]  Time: 0.087 (0.097)  Loss:  2.5396 (2.2653)  Acc@1:  0.0000 (12.4502)  Acc@5: 18.7500 (63.7326)\n",
            "Test (EMA): [ 300/312]  Time: 0.086 (0.096)  Loss:  2.4480 (2.3047)  Acc@1:  0.0000 (10.3821)  Acc@5: 68.7500 (61.2438)\n",
            "Test (EMA): [ 312/312]  Time: 0.134 (0.096)  Loss:  2.4584 (2.3103)  Acc@1:  0.0000 (10.0000)  Acc@5: 56.2500 (61.5900)\n",
            "Current checkpoints:\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-0.pth.tar', 10.0)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-1.pth.tar', 10.0)\n",
            "\n",
            "Train: 2 [   0/1562 (  0%)]  Loss:  2.149329 (2.1493)  Time: 1.676s,   19.09/s  (1.676s,   19.09/s)  LR: 6.700e-05  Data: 1.228 (1.228)\n",
            "Train: 2 [  50/1562 (  3%)]  Loss:  2.128692 (2.2136)  Time: 0.286s,  111.90/s  (0.319s,  100.40/s)  LR: 6.700e-05  Data: 0.004 (0.028)\n",
            "Train: 2 [ 100/1562 (  6%)]  Loss:  2.143278 (2.2042)  Time: 0.294s,  108.87/s  (0.303s,  105.61/s)  LR: 6.700e-05  Data: 0.004 (0.016)\n",
            "Train: 2 [ 150/1562 ( 10%)]  Loss:  2.185581 (2.2025)  Time: 0.286s,  111.94/s  (0.298s,  107.51/s)  LR: 6.700e-05  Data: 0.004 (0.012)\n",
            "Train: 2 [ 200/1562 ( 13%)]  Loss:  2.213979 (2.2005)  Time: 0.286s,  111.72/s  (0.295s,  108.50/s)  LR: 6.700e-05  Data: 0.004 (0.010)\n",
            "Train: 2 [ 250/1562 ( 16%)]  Loss:  2.202812 (2.1974)  Time: 0.289s,  110.82/s  (0.293s,  109.06/s)  LR: 6.700e-05  Data: 0.004 (0.009)\n",
            "Train: 2 [ 300/1562 ( 19%)]  Loss:  2.285387 (2.1985)  Time: 0.286s,  111.93/s  (0.292s,  109.47/s)  LR: 6.700e-05  Data: 0.004 (0.008)\n",
            "Train: 2 [ 350/1562 ( 22%)]  Loss:  2.213528 (2.1938)  Time: 0.285s,  112.16/s  (0.292s,  109.78/s)  LR: 6.700e-05  Data: 0.004 (0.007)\n",
            "Train: 2 [ 400/1562 ( 26%)]  Loss:  2.267909 (2.1855)  Time: 0.286s,  111.94/s  (0.291s,  110.00/s)  LR: 6.700e-05  Data: 0.004 (0.007)\n",
            "Train: 2 [ 450/1562 ( 29%)]  Loss:  2.322480 (2.1866)  Time: 0.289s,  110.72/s  (0.290s,  110.18/s)  LR: 6.700e-05  Data: 0.006 (0.006)\n",
            "Train: 2 [ 500/1562 ( 32%)]  Loss:  2.226425 (2.1842)  Time: 0.287s,  111.38/s  (0.290s,  110.31/s)  LR: 6.700e-05  Data: 0.004 (0.006)\n",
            "Train: 2 [ 550/1562 ( 35%)]  Loss:  2.065586 (2.1826)  Time: 0.286s,  112.00/s  (0.290s,  110.43/s)  LR: 6.700e-05  Data: 0.004 (0.006)\n",
            "Train: 2 [ 600/1562 ( 38%)]  Loss:  2.322824 (2.1810)  Time: 0.286s,  112.03/s  (0.290s,  110.52/s)  LR: 6.700e-05  Data: 0.004 (0.006)\n",
            "Train: 2 [ 650/1562 ( 42%)]  Loss:  2.021503 (2.1798)  Time: 0.286s,  111.81/s  (0.289s,  110.60/s)  LR: 6.700e-05  Data: 0.004 (0.006)\n",
            "Train: 2 [ 700/1562 ( 45%)]  Loss:  2.113598 (2.1797)  Time: 0.289s,  110.69/s  (0.289s,  110.67/s)  LR: 6.700e-05  Data: 0.004 (0.005)\n",
            "Train: 2 [ 750/1562 ( 48%)]  Loss:  2.081731 (2.1801)  Time: 0.286s,  111.75/s  (0.289s,  110.74/s)  LR: 6.700e-05  Data: 0.004 (0.005)\n",
            "Train: 2 [ 800/1562 ( 51%)]  Loss:  2.198920 (2.1802)  Time: 0.286s,  112.00/s  (0.289s,  110.80/s)  LR: 6.700e-05  Data: 0.004 (0.005)\n",
            "Train: 2 [ 850/1562 ( 54%)]  Loss:  2.275747 (2.1804)  Time: 0.286s,  111.96/s  (0.289s,  110.85/s)  LR: 6.700e-05  Data: 0.004 (0.005)\n",
            "Train: 2 [ 900/1562 ( 58%)]  Loss:  2.102804 (2.1805)  Time: 0.286s,  111.97/s  (0.289s,  110.89/s)  LR: 6.700e-05  Data: 0.004 (0.005)\n",
            "Train: 2 [ 950/1562 ( 61%)]  Loss:  1.982860 (2.1793)  Time: 0.287s,  111.36/s  (0.289s,  110.91/s)  LR: 6.700e-05  Data: 0.004 (0.005)\n",
            "Train: 2 [1000/1562 ( 64%)]  Loss:  2.246673 (2.1782)  Time: 0.286s,  111.92/s  (0.288s,  110.94/s)  LR: 6.700e-05  Data: 0.004 (0.005)\n",
            "Train: 2 [1050/1562 ( 67%)]  Loss:  2.059140 (2.1794)  Time: 0.286s,  112.01/s  (0.288s,  110.97/s)  LR: 6.700e-05  Data: 0.004 (0.005)\n",
            "Train: 2 [1100/1562 ( 70%)]  Loss:  2.091429 (2.1795)  Time: 0.288s,  111.08/s  (0.288s,  110.99/s)  LR: 6.700e-05  Data: 0.004 (0.005)\n",
            "Train: 2 [1150/1562 ( 74%)]  Loss:  2.205650 (2.1816)  Time: 0.287s,  111.66/s  (0.288s,  111.02/s)  LR: 6.700e-05  Data: 0.004 (0.005)\n",
            "Train: 2 [1200/1562 ( 77%)]  Loss:  2.161030 (2.1832)  Time: 0.288s,  111.21/s  (0.288s,  111.04/s)  LR: 6.700e-05  Data: 0.004 (0.005)\n",
            "Train: 2 [1250/1562 ( 80%)]  Loss:  2.192810 (2.1818)  Time: 0.294s,  109.02/s  (0.288s,  111.07/s)  LR: 6.700e-05  Data: 0.004 (0.005)\n",
            "Train: 2 [1300/1562 ( 83%)]  Loss:  2.039337 (2.1820)  Time: 0.287s,  111.64/s  (0.288s,  111.08/s)  LR: 6.700e-05  Data: 0.004 (0.005)\n",
            "Train: 2 [1350/1562 ( 86%)]  Loss:  2.202257 (2.1812)  Time: 0.286s,  111.90/s  (0.288s,  111.08/s)  LR: 6.700e-05  Data: 0.004 (0.005)\n",
            "Train: 2 [1400/1562 ( 90%)]  Loss:  2.156977 (2.1786)  Time: 0.286s,  111.97/s  (0.288s,  111.10/s)  LR: 6.700e-05  Data: 0.004 (0.005)\n",
            "Train: 2 [1450/1562 ( 93%)]  Loss:  2.151770 (2.1782)  Time: 0.296s,  108.17/s  (0.288s,  111.11/s)  LR: 6.700e-05  Data: 0.004 (0.005)\n",
            "Train: 2 [1500/1562 ( 96%)]  Loss:  2.203005 (2.1780)  Time: 0.286s,  111.94/s  (0.288s,  111.12/s)  LR: 6.700e-05  Data: 0.004 (0.005)\n",
            "Train: 2 [1550/1562 ( 99%)]  Loss:  2.109955 (2.1763)  Time: 0.291s,  109.91/s  (0.288s,  111.13/s)  LR: 6.700e-05  Data: 0.003 (0.005)\n",
            "Train: 2 [1561/1562 (100%)]  Loss:  2.058562 (2.1755)  Time: 0.369s,   86.70/s  (0.288s,  111.12/s)  LR: 6.700e-05  Data: 0.089 (0.005)\n",
            "Test: [   0/312]  Time: 0.898 (0.898)  Loss:  1.8593 (1.8593)  Acc@1: 31.2500 (31.2500)  Acc@5: 71.8750 (71.8750)\n",
            "Test: [  50/312]  Time: 0.090 (0.112)  Loss:  1.5136 (1.5725)  Acc@1: 46.8750 (36.6422)  Acc@5: 96.8750 (90.8701)\n",
            "Test: [ 100/312]  Time: 0.086 (0.102)  Loss:  1.9483 (1.7979)  Acc@1: 15.6250 (25.7426)  Acc@5: 84.3750 (85.7054)\n",
            "Test: [ 150/312]  Time: 0.091 (0.099)  Loss:  1.8882 (1.8274)  Acc@1: 21.8750 (27.1109)  Acc@5: 81.2500 (85.3477)\n",
            "Test: [ 200/312]  Time: 0.099 (0.098)  Loss:  1.6233 (1.8180)  Acc@1: 53.1250 (30.3638)  Acc@5: 100.0000 (86.8626)\n",
            "Test: [ 250/312]  Time: 0.094 (0.097)  Loss:  1.4036 (1.7609)  Acc@1: 68.7500 (35.4084)  Acc@5: 93.7500 (87.8362)\n",
            "Test: [ 300/312]  Time: 0.086 (0.096)  Loss:  1.4752 (1.7038)  Acc@1: 65.6250 (39.7841)  Acc@5: 93.7500 (89.0262)\n",
            "Test: [ 312/312]  Time: 0.132 (0.096)  Loss:  1.5338 (1.6993)  Acc@1: 50.0000 (40.2500)  Acc@5: 93.7500 (89.2100)\n",
            "Test (EMA): [   0/312]  Time: 0.921 (0.921)  Loss:  2.0404 (2.0404)  Acc@1: 12.5000 (12.5000)  Acc@5: 100.0000 (100.0000)\n",
            "Test (EMA): [  50/312]  Time: 0.087 (0.111)  Loss:  2.3074 (2.1253)  Acc@1:  0.0000 ( 8.7010)  Acc@5: 81.2500 (90.5637)\n",
            "Test (EMA): [ 100/312]  Time: 0.094 (0.102)  Loss:  2.3723 (2.0787)  Acc@1:  0.0000 (34.5916)  Acc@5: 31.2500 (87.3453)\n",
            "Test (EMA): [ 150/312]  Time: 0.095 (0.099)  Loss:  2.3297 (2.1710)  Acc@1:  0.0000 (23.1374)  Acc@5: 65.6250 (74.5654)\n",
            "Test (EMA): [ 200/312]  Time: 0.087 (0.097)  Loss:  2.2050 (2.2293)  Acc@1:  0.0000 (17.3818)  Acc@5: 96.8750 (64.5211)\n",
            "Test (EMA): [ 250/312]  Time: 0.088 (0.096)  Loss:  2.4335 (2.2164)  Acc@1:  0.0000 (13.9318)  Acc@5: 53.1250 (71.1653)\n",
            "Test (EMA): [ 300/312]  Time: 0.086 (0.095)  Loss:  2.4485 (2.2516)  Acc@1:  0.0000 (11.6175)  Acc@5:  9.3750 (65.8015)\n",
            "Test (EMA): [ 312/312]  Time: 0.132 (0.095)  Loss:  2.4515 (2.2587)  Acc@1:  0.0000 (11.1900)  Acc@5:  0.0000 (63.6800)\n",
            "Current checkpoints:\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-2.pth.tar', 11.19)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-0.pth.tar', 10.0)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-1.pth.tar', 10.0)\n",
            "\n",
            "Train: 3 [   0/1562 (  0%)]  Loss:  2.102372 (2.1024)  Time: 1.717s,   18.64/s  (1.717s,   18.64/s)  LR: 9.876e-05  Data: 1.245 (1.245)\n",
            "Train: 3 [  50/1562 (  3%)]  Loss:  2.181336 (2.1838)  Time: 0.286s,  111.80/s  (0.320s,  100.11/s)  LR: 9.876e-05  Data: 0.004 (0.029)\n",
            "Train: 3 [ 100/1562 (  6%)]  Loss:  1.901222 (2.1642)  Time: 0.286s,  111.77/s  (0.303s,  105.51/s)  LR: 9.876e-05  Data: 0.004 (0.016)\n",
            "Train: 3 [ 150/1562 ( 10%)]  Loss:  2.243686 (2.1595)  Time: 0.286s,  111.77/s  (0.298s,  107.41/s)  LR: 9.876e-05  Data: 0.004 (0.012)\n",
            "Train: 3 [ 200/1562 ( 13%)]  Loss:  2.040581 (2.1556)  Time: 0.286s,  111.97/s  (0.295s,  108.43/s)  LR: 9.876e-05  Data: 0.004 (0.010)\n",
            "Train: 3 [ 250/1562 ( 16%)]  Loss:  2.187530 (2.1526)  Time: 0.286s,  111.72/s  (0.294s,  108.99/s)  LR: 9.876e-05  Data: 0.004 (0.009)\n",
            "Train: 3 [ 300/1562 ( 19%)]  Loss:  2.087431 (2.1517)  Time: 0.287s,  111.41/s  (0.292s,  109.40/s)  LR: 9.876e-05  Data: 0.004 (0.008)\n",
            "Train: 3 [ 350/1562 ( 22%)]  Loss:  2.060739 (2.1442)  Time: 0.287s,  111.44/s  (0.292s,  109.70/s)  LR: 9.876e-05  Data: 0.005 (0.007)\n",
            "Train: 3 [ 400/1562 ( 26%)]  Loss:  2.306653 (2.1351)  Time: 0.286s,  111.96/s  (0.291s,  109.94/s)  LR: 9.876e-05  Data: 0.004 (0.007)\n",
            "Train: 3 [ 450/1562 ( 29%)]  Loss:  2.144554 (2.1325)  Time: 0.286s,  111.96/s  (0.291s,  110.13/s)  LR: 9.876e-05  Data: 0.004 (0.007)\n",
            "Train: 3 [ 500/1562 ( 32%)]  Loss:  2.012875 (2.1331)  Time: 0.286s,  112.00/s  (0.290s,  110.27/s)  LR: 9.876e-05  Data: 0.004 (0.006)\n",
            "Train: 3 [ 550/1562 ( 35%)]  Loss:  1.982680 (2.1311)  Time: 0.293s,  109.15/s  (0.290s,  110.39/s)  LR: 9.876e-05  Data: 0.004 (0.006)\n",
            "Train: 3 [ 600/1562 ( 38%)]  Loss:  2.196162 (2.1278)  Time: 0.292s,  109.49/s  (0.290s,  110.48/s)  LR: 9.876e-05  Data: 0.004 (0.006)\n",
            "Train: 3 [ 650/1562 ( 42%)]  Loss:  1.951561 (2.1281)  Time: 0.286s,  112.05/s  (0.289s,  110.56/s)  LR: 9.876e-05  Data: 0.004 (0.006)\n",
            "Train: 3 [ 700/1562 ( 45%)]  Loss:  1.982896 (2.1277)  Time: 0.286s,  111.94/s  (0.289s,  110.63/s)  LR: 9.876e-05  Data: 0.004 (0.006)\n",
            "Train: 3 [ 750/1562 ( 48%)]  Loss:  2.025435 (2.1293)  Time: 0.286s,  111.99/s  (0.289s,  110.69/s)  LR: 9.876e-05  Data: 0.004 (0.005)\n",
            "Train: 3 [ 800/1562 ( 51%)]  Loss:  2.072503 (2.1286)  Time: 0.286s,  111.71/s  (0.289s,  110.73/s)  LR: 9.876e-05  Data: 0.004 (0.005)\n",
            "Train: 3 [ 850/1562 ( 54%)]  Loss:  2.255073 (2.1309)  Time: 0.286s,  111.90/s  (0.289s,  110.77/s)  LR: 9.876e-05  Data: 0.004 (0.005)\n",
            "Train: 3 [ 900/1562 ( 58%)]  Loss:  2.087027 (2.1318)  Time: 0.287s,  111.61/s  (0.289s,  110.82/s)  LR: 9.876e-05  Data: 0.004 (0.005)\n",
            "Train: 3 [ 950/1562 ( 61%)]  Loss:  1.908831 (2.1295)  Time: 0.287s,  111.43/s  (0.289s,  110.86/s)  LR: 9.876e-05  Data: 0.005 (0.005)\n",
            "Train: 3 [1000/1562 ( 64%)]  Loss:  2.238092 (2.1298)  Time: 0.286s,  111.73/s  (0.289s,  110.89/s)  LR: 9.876e-05  Data: 0.004 (0.005)\n",
            "Train: 3 [1050/1562 ( 67%)]  Loss:  1.983443 (2.1317)  Time: 0.286s,  111.70/s  (0.288s,  110.93/s)  LR: 9.876e-05  Data: 0.004 (0.005)\n",
            "Train: 3 [1100/1562 ( 70%)]  Loss:  2.133114 (2.1323)  Time: 0.286s,  112.01/s  (0.288s,  110.96/s)  LR: 9.876e-05  Data: 0.004 (0.005)\n",
            "Train: 3 [1150/1562 ( 74%)]  Loss:  2.157804 (2.1352)  Time: 0.286s,  111.98/s  (0.288s,  110.99/s)  LR: 9.876e-05  Data: 0.004 (0.005)\n",
            "Train: 3 [1200/1562 ( 77%)]  Loss:  2.089360 (2.1370)  Time: 0.286s,  111.95/s  (0.288s,  111.01/s)  LR: 9.876e-05  Data: 0.004 (0.005)\n",
            "Train: 3 [1250/1562 ( 80%)]  Loss:  2.264826 (2.1356)  Time: 0.286s,  111.89/s  (0.288s,  111.03/s)  LR: 9.876e-05  Data: 0.004 (0.005)\n",
            "Train: 3 [1300/1562 ( 83%)]  Loss:  2.062787 (2.1355)  Time: 0.290s,  110.38/s  (0.288s,  111.05/s)  LR: 9.876e-05  Data: 0.004 (0.005)\n",
            "Train: 3 [1350/1562 ( 86%)]  Loss:  2.326341 (2.1348)  Time: 0.287s,  111.55/s  (0.288s,  111.06/s)  LR: 9.876e-05  Data: 0.004 (0.005)\n",
            "Train: 3 [1400/1562 ( 90%)]  Loss:  2.176940 (2.1324)  Time: 0.286s,  111.76/s  (0.288s,  111.06/s)  LR: 9.876e-05  Data: 0.004 (0.005)\n",
            "Train: 3 [1450/1562 ( 93%)]  Loss:  2.134621 (2.1326)  Time: 0.289s,  110.70/s  (0.288s,  111.08/s)  LR: 9.876e-05  Data: 0.004 (0.005)\n",
            "Train: 3 [1500/1562 ( 96%)]  Loss:  2.220232 (2.1335)  Time: 0.286s,  111.82/s  (0.288s,  111.10/s)  LR: 9.876e-05  Data: 0.004 (0.005)\n",
            "Train: 3 [1550/1562 ( 99%)]  Loss:  2.116520 (2.1321)  Time: 0.283s,  113.06/s  (0.288s,  111.12/s)  LR: 9.876e-05  Data: 0.003 (0.005)\n",
            "Train: 3 [1561/1562 (100%)]  Loss:  2.190315 (2.1313)  Time: 0.369s,   86.80/s  (0.288s,  111.11/s)  LR: 9.876e-05  Data: 0.088 (0.005)\n",
            "Test: [   0/312]  Time: 0.804 (0.804)  Loss:  1.6063 (1.6063)  Acc@1: 53.1250 (53.1250)  Acc@5: 75.0000 (75.0000)\n",
            "Test: [  50/312]  Time: 0.093 (0.111)  Loss:  1.6629 (1.4585)  Acc@1: 50.0000 (57.7819)  Acc@5: 87.5000 (89.2770)\n",
            "Test: [ 100/312]  Time: 0.093 (0.102)  Loss:  1.8390 (1.7508)  Acc@1: 15.6250 (36.2314)  Acc@5: 93.7500 (86.0458)\n",
            "Test: [ 150/312]  Time: 0.092 (0.099)  Loss:  1.9497 (1.7670)  Acc@1: 21.8750 (32.1606)  Acc@5: 84.3750 (86.9619)\n",
            "Test: [ 200/312]  Time: 0.087 (0.097)  Loss:  1.1716 (1.7185)  Acc@1: 84.3750 (38.2307)  Acc@5: 100.0000 (89.2257)\n",
            "Test: [ 250/312]  Time: 0.097 (0.096)  Loss:  1.3862 (1.6315)  Acc@1: 46.8750 (43.8247)  Acc@5: 90.6250 (89.8655)\n",
            "Test: [ 300/312]  Time: 0.086 (0.096)  Loss:  1.3334 (1.6014)  Acc@1: 68.7500 (43.0959)  Acc@5: 96.8750 (90.6873)\n",
            "Test: [ 312/312]  Time: 0.130 (0.095)  Loss:  1.6087 (1.6026)  Acc@1: 43.7500 (43.2500)  Acc@5: 87.5000 (90.7800)\n",
            "Test (EMA): [   0/312]  Time: 0.944 (0.944)  Loss:  2.0102 (2.0102)  Acc@1: 53.1250 (53.1250)  Acc@5: 93.7500 (93.7500)\n",
            "Test (EMA): [  50/312]  Time: 0.087 (0.113)  Loss:  2.3516 (2.1114)  Acc@1:  0.0000 (40.9926)  Acc@5: 46.8750 (76.4706)\n",
            "Test (EMA): [ 100/312]  Time: 0.089 (0.102)  Loss:  2.2733 (2.0960)  Acc@1:  0.0000 (39.3564)  Acc@5: 78.1250 (79.5792)\n",
            "Test (EMA): [ 150/312]  Time: 0.107 (0.099)  Loss:  2.1998 (2.1441)  Acc@1:  0.0000 (26.5522)  Acc@5: 75.0000 (76.4487)\n",
            "Test (EMA): [ 200/312]  Time: 0.097 (0.097)  Loss:  2.0032 (2.1851)  Acc@1: 37.5000 (22.8078)  Acc@5: 96.8750 (66.3713)\n",
            "Test (EMA): [ 250/312]  Time: 0.099 (0.096)  Loss:  2.3433 (2.1761)  Acc@1:  0.0000 (21.3023)  Acc@5: 62.5000 (72.5473)\n",
            "Test (EMA): [ 300/312]  Time: 0.086 (0.095)  Loss:  2.4984 (2.2107)  Acc@1:  0.0000 (17.7637)  Acc@5:  0.0000 (67.5249)\n",
            "Test (EMA): [ 312/312]  Time: 0.133 (0.095)  Loss:  2.4955 (2.2209)  Acc@1:  0.0000 (17.1100)  Acc@5:  6.2500 (65.1300)\n",
            "Current checkpoints:\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-3.pth.tar', 17.11)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-2.pth.tar', 11.19)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-0.pth.tar', 10.0)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-1.pth.tar', 10.0)\n",
            "\n",
            "Train: 4 [   0/1562 (  0%)]  Loss:  1.945221 (1.9452)  Time: 1.708s,   18.73/s  (1.708s,   18.73/s)  LR: 9.780e-05  Data: 1.238 (1.238)\n",
            "Train: 4 [  50/1562 (  3%)]  Loss:  2.078731 (2.1402)  Time: 0.286s,  112.03/s  (0.318s,  100.52/s)  LR: 9.780e-05  Data: 0.003 (0.028)\n",
            "Train: 4 [ 100/1562 (  6%)]  Loss:  1.966620 (2.1085)  Time: 0.285s,  112.13/s  (0.303s,  105.70/s)  LR: 9.780e-05  Data: 0.004 (0.016)\n",
            "Train: 4 [ 150/1562 ( 10%)]  Loss:  2.296108 (2.1156)  Time: 0.286s,  111.90/s  (0.297s,  107.64/s)  LR: 9.780e-05  Data: 0.004 (0.012)\n",
            "Train: 4 [ 200/1562 ( 13%)]  Loss:  2.173361 (2.1072)  Time: 0.293s,  109.10/s  (0.295s,  108.59/s)  LR: 9.780e-05  Data: 0.004 (0.010)\n",
            "Train: 4 [ 250/1562 ( 16%)]  Loss:  2.060314 (2.1044)  Time: 0.286s,  111.98/s  (0.293s,  109.21/s)  LR: 9.780e-05  Data: 0.003 (0.009)\n",
            "Train: 4 [ 300/1562 ( 19%)]  Loss:  2.108814 (2.1056)  Time: 0.286s,  111.74/s  (0.292s,  109.55/s)  LR: 9.780e-05  Data: 0.004 (0.008)\n",
            "Train: 4 [ 350/1562 ( 22%)]  Loss:  1.989125 (2.0995)  Time: 0.287s,  111.68/s  (0.291s,  109.85/s)  LR: 9.780e-05  Data: 0.004 (0.007)\n",
            "Train: 4 [ 400/1562 ( 26%)]  Loss:  2.021029 (2.0948)  Time: 0.286s,  111.85/s  (0.291s,  110.06/s)  LR: 9.780e-05  Data: 0.004 (0.007)\n",
            "Train: 4 [ 450/1562 ( 29%)]  Loss:  2.241263 (2.0929)  Time: 0.286s,  111.71/s  (0.290s,  110.20/s)  LR: 9.780e-05  Data: 0.004 (0.006)\n",
            "Train: 4 [ 500/1562 ( 32%)]  Loss:  2.095929 (2.0916)  Time: 0.286s,  111.90/s  (0.290s,  110.29/s)  LR: 9.780e-05  Data: 0.004 (0.006)\n",
            "Train: 4 [ 550/1562 ( 35%)]  Loss:  2.142999 (2.0887)  Time: 0.288s,  111.17/s  (0.290s,  110.39/s)  LR: 9.780e-05  Data: 0.004 (0.006)\n",
            "Train: 4 [ 600/1562 ( 38%)]  Loss:  2.225973 (2.0874)  Time: 0.286s,  111.84/s  (0.290s,  110.48/s)  LR: 9.780e-05  Data: 0.004 (0.006)\n",
            "Train: 4 [ 650/1562 ( 42%)]  Loss:  1.910240 (2.0878)  Time: 0.287s,  111.56/s  (0.289s,  110.54/s)  LR: 9.780e-05  Data: 0.004 (0.006)\n",
            "Train: 4 [ 700/1562 ( 45%)]  Loss:  1.824435 (2.0865)  Time: 0.286s,  111.94/s  (0.289s,  110.60/s)  LR: 9.780e-05  Data: 0.004 (0.005)\n",
            "Train: 4 [ 750/1562 ( 48%)]  Loss:  2.102004 (2.0885)  Time: 0.286s,  111.83/s  (0.289s,  110.65/s)  LR: 9.780e-05  Data: 0.004 (0.005)\n",
            "Train: 4 [ 800/1562 ( 51%)]  Loss:  2.117847 (2.0876)  Time: 0.291s,  110.05/s  (0.289s,  110.70/s)  LR: 9.780e-05  Data: 0.004 (0.005)\n",
            "Train: 4 [ 850/1562 ( 54%)]  Loss:  2.208451 (2.0906)  Time: 0.285s,  112.09/s  (0.289s,  110.75/s)  LR: 9.780e-05  Data: 0.004 (0.005)\n",
            "Train: 4 [ 900/1562 ( 58%)]  Loss:  2.073706 (2.0930)  Time: 0.293s,  109.09/s  (0.289s,  110.77/s)  LR: 9.780e-05  Data: 0.004 (0.005)\n",
            "Train: 4 [ 950/1562 ( 61%)]  Loss:  2.156977 (2.0899)  Time: 0.286s,  111.84/s  (0.289s,  110.81/s)  LR: 9.780e-05  Data: 0.004 (0.005)\n",
            "Train: 4 [1000/1562 ( 64%)]  Loss:  2.155601 (2.0908)  Time: 0.286s,  111.90/s  (0.289s,  110.83/s)  LR: 9.780e-05  Data: 0.004 (0.005)\n",
            "Train: 4 [1050/1562 ( 67%)]  Loss:  2.024018 (2.0921)  Time: 0.286s,  111.89/s  (0.289s,  110.86/s)  LR: 9.780e-05  Data: 0.004 (0.005)\n",
            "Train: 4 [1100/1562 ( 70%)]  Loss:  2.181539 (2.0934)  Time: 0.289s,  110.85/s  (0.289s,  110.89/s)  LR: 9.780e-05  Data: 0.004 (0.005)\n",
            "Train: 4 [1150/1562 ( 74%)]  Loss:  2.198494 (2.0968)  Time: 0.290s,  110.46/s  (0.289s,  110.91/s)  LR: 9.780e-05  Data: 0.004 (0.005)\n",
            "Train: 4 [1200/1562 ( 77%)]  Loss:  1.951077 (2.1000)  Time: 0.286s,  111.81/s  (0.288s,  110.93/s)  LR: 9.780e-05  Data: 0.004 (0.005)\n",
            "Train: 4 [1250/1562 ( 80%)]  Loss:  2.191610 (2.0988)  Time: 0.286s,  111.86/s  (0.288s,  110.95/s)  LR: 9.780e-05  Data: 0.004 (0.005)\n",
            "Train: 4 [1300/1562 ( 83%)]  Loss:  2.074968 (2.1002)  Time: 0.288s,  111.05/s  (0.288s,  110.96/s)  LR: 9.780e-05  Data: 0.004 (0.005)\n",
            "Train: 4 [1350/1562 ( 86%)]  Loss:  2.130796 (2.1001)  Time: 0.289s,  110.76/s  (0.288s,  110.98/s)  LR: 9.780e-05  Data: 0.004 (0.005)\n",
            "Train: 4 [1400/1562 ( 90%)]  Loss:  2.167395 (2.0976)  Time: 0.291s,  109.97/s  (0.288s,  110.99/s)  LR: 9.780e-05  Data: 0.004 (0.005)\n",
            "Train: 4 [1450/1562 ( 93%)]  Loss:  2.189809 (2.0984)  Time: 0.286s,  111.94/s  (0.288s,  111.00/s)  LR: 9.780e-05  Data: 0.004 (0.005)\n",
            "Train: 4 [1500/1562 ( 96%)]  Loss:  2.204515 (2.0983)  Time: 0.286s,  111.77/s  (0.288s,  111.01/s)  LR: 9.780e-05  Data: 0.004 (0.005)\n",
            "Train: 4 [1550/1562 ( 99%)]  Loss:  2.035618 (2.0974)  Time: 0.283s,  113.03/s  (0.288s,  111.03/s)  LR: 9.780e-05  Data: 0.003 (0.005)\n",
            "Train: 4 [1561/1562 (100%)]  Loss:  2.029377 (2.0962)  Time: 0.366s,   87.49/s  (0.288s,  111.02/s)  LR: 9.780e-05  Data: 0.086 (0.005)\n",
            "Test: [   0/312]  Time: 0.872 (0.872)  Loss:  1.5618 (1.5618)  Acc@1: 53.1250 (53.1250)  Acc@5: 87.5000 (87.5000)\n",
            "Test: [  50/312]  Time: 0.086 (0.112)  Loss:  1.1467 (1.2039)  Acc@1: 68.7500 (70.2819)  Acc@5: 100.0000 (95.2819)\n",
            "Test: [ 100/312]  Time: 0.093 (0.102)  Loss:  1.8941 (1.5332)  Acc@1: 21.8750 (46.7822)  Acc@5: 90.6250 (93.6572)\n",
            "Test: [ 150/312]  Time: 0.100 (0.099)  Loss:  2.2046 (1.6840)  Acc@1:  0.0000 (36.7964)  Acc@5: 87.5000 (91.8046)\n",
            "Test: [ 200/312]  Time: 0.087 (0.097)  Loss:  0.7259 (1.7023)  Acc@1: 93.7500 (36.1785)  Acc@5: 100.0000 (89.9409)\n",
            "Test: [ 250/312]  Time: 0.087 (0.096)  Loss:  1.5096 (1.5631)  Acc@1: 28.1250 (44.4472)  Acc@5: 90.6250 (91.2600)\n",
            "Test: [ 300/312]  Time: 0.086 (0.096)  Loss:  1.2360 (1.5478)  Acc@1: 75.0000 (43.4178)  Acc@5: 96.8750 (91.5075)\n",
            "Test: [ 312/312]  Time: 0.135 (0.095)  Loss:  1.4865 (1.5494)  Acc@1: 37.5000 (43.3800)  Acc@5: 87.5000 (91.5900)\n",
            "Test (EMA): [   0/312]  Time: 0.920 (0.920)  Loss:  1.9999 (1.9999)  Acc@1: 56.2500 (56.2500)  Acc@5: 90.6250 (90.6250)\n",
            "Test (EMA): [  50/312]  Time: 0.088 (0.113)  Loss:  2.3847 (2.1100)  Acc@1:  0.0000 (46.2623)  Acc@5: 40.6250 (70.6495)\n",
            "Test (EMA): [ 100/312]  Time: 0.087 (0.103)  Loss:  2.1961 (2.1078)  Acc@1:  3.1250 (32.5495)  Acc@5: 90.6250 (77.0111)\n",
            "Test (EMA): [ 150/312]  Time: 0.089 (0.100)  Loss:  2.1028 (2.1223)  Acc@1:  0.0000 (22.2268)  Acc@5: 81.2500 (80.4429)\n",
            "Test (EMA): [ 200/312]  Time: 0.086 (0.098)  Loss:  1.8405 (2.1537)  Acc@1: 65.6250 (21.8128)  Acc@5: 100.0000 (69.7917)\n",
            "Test (EMA): [ 250/312]  Time: 0.091 (0.097)  Loss:  2.2673 (2.1489)  Acc@1:  0.0000 (22.8461)  Acc@5: 81.2500 (72.6594)\n",
            "Test (EMA): [ 300/312]  Time: 0.086 (0.096)  Loss:  2.5347 (2.1819)  Acc@1:  0.0000 (19.0511)  Acc@5:  0.0000 (68.7604)\n",
            "Test (EMA): [ 312/312]  Time: 0.132 (0.096)  Loss:  2.5304 (2.1945)  Acc@1:  0.0000 (18.3500)  Acc@5:  6.2500 (66.3100)\n",
            "Current checkpoints:\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-4.pth.tar', 18.35)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-3.pth.tar', 17.11)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-2.pth.tar', 11.19)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-0.pth.tar', 10.0)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-1.pth.tar', 10.0)\n",
            "\n",
            "Train: 5 [   0/1562 (  0%)]  Loss:  1.830856 (1.8309)  Time: 1.664s,   19.24/s  (1.664s,   19.24/s)  LR: 9.657e-05  Data: 1.193 (1.193)\n",
            "Train: 5 [  50/1562 (  3%)]  Loss:  1.984651 (2.1203)  Time: 0.289s,  110.72/s  (0.320s,   99.90/s)  LR: 9.657e-05  Data: 0.003 (0.028)\n",
            "Train: 5 [ 100/1562 (  6%)]  Loss:  1.890698 (2.0998)  Time: 0.286s,  111.89/s  (0.304s,  105.28/s)  LR: 9.657e-05  Data: 0.004 (0.016)\n",
            "Train: 5 [ 150/1562 ( 10%)]  Loss:  2.164564 (2.1087)  Time: 0.292s,  109.56/s  (0.298s,  107.21/s)  LR: 9.657e-05  Data: 0.004 (0.012)\n",
            "Train: 5 [ 200/1562 ( 13%)]  Loss:  2.043902 (2.0949)  Time: 0.287s,  111.60/s  (0.296s,  108.20/s)  LR: 9.657e-05  Data: 0.004 (0.010)\n",
            "Train: 5 [ 250/1562 ( 16%)]  Loss:  2.058388 (2.0907)  Time: 0.286s,  112.08/s  (0.294s,  108.86/s)  LR: 9.657e-05  Data: 0.004 (0.009)\n",
            "Train: 5 [ 300/1562 ( 19%)]  Loss:  2.328659 (2.0859)  Time: 0.288s,  111.05/s  (0.293s,  109.28/s)  LR: 9.657e-05  Data: 0.004 (0.008)\n",
            "Train: 5 [ 350/1562 ( 22%)]  Loss:  1.984685 (2.0754)  Time: 0.286s,  112.04/s  (0.292s,  109.60/s)  LR: 9.657e-05  Data: 0.004 (0.007)\n",
            "Train: 5 [ 400/1562 ( 26%)]  Loss:  1.998234 (2.0650)  Time: 0.286s,  111.91/s  (0.291s,  109.83/s)  LR: 9.657e-05  Data: 0.004 (0.007)\n",
            "Train: 5 [ 450/1562 ( 29%)]  Loss:  2.161986 (2.0658)  Time: 0.286s,  111.78/s  (0.291s,  110.00/s)  LR: 9.657e-05  Data: 0.004 (0.006)\n",
            "Train: 5 [ 500/1562 ( 32%)]  Loss:  1.944213 (2.0641)  Time: 0.286s,  111.85/s  (0.291s,  110.15/s)  LR: 9.657e-05  Data: 0.004 (0.006)\n",
            "Train: 5 [ 550/1562 ( 35%)]  Loss:  2.019438 (2.0593)  Time: 0.287s,  111.66/s  (0.290s,  110.26/s)  LR: 9.657e-05  Data: 0.004 (0.006)\n",
            "Train: 5 [ 600/1562 ( 38%)]  Loss:  2.205927 (2.0554)  Time: 0.286s,  112.05/s  (0.290s,  110.34/s)  LR: 9.657e-05  Data: 0.004 (0.006)\n",
            "Train: 5 [ 650/1562 ( 42%)]  Loss:  1.899178 (2.0566)  Time: 0.285s,  112.30/s  (0.290s,  110.42/s)  LR: 9.657e-05  Data: 0.004 (0.006)\n",
            "Train: 5 [ 700/1562 ( 45%)]  Loss:  1.941914 (2.0581)  Time: 0.286s,  111.85/s  (0.290s,  110.49/s)  LR: 9.657e-05  Data: 0.004 (0.006)\n",
            "Train: 5 [ 750/1562 ( 48%)]  Loss:  1.883727 (2.0610)  Time: 0.300s,  106.60/s  (0.290s,  110.53/s)  LR: 9.657e-05  Data: 0.004 (0.005)\n",
            "Train: 5 [ 800/1562 ( 51%)]  Loss:  1.989302 (2.0623)  Time: 0.286s,  111.79/s  (0.289s,  110.59/s)  LR: 9.657e-05  Data: 0.004 (0.005)\n",
            "Train: 5 [ 850/1562 ( 54%)]  Loss:  2.135794 (2.0651)  Time: 0.286s,  111.72/s  (0.289s,  110.63/s)  LR: 9.657e-05  Data: 0.004 (0.005)\n",
            "Train: 5 [ 900/1562 ( 58%)]  Loss:  2.138912 (2.0680)  Time: 0.286s,  111.83/s  (0.289s,  110.66/s)  LR: 9.657e-05  Data: 0.004 (0.005)\n",
            "Train: 5 [ 950/1562 ( 61%)]  Loss:  1.863956 (2.0675)  Time: 0.286s,  111.81/s  (0.289s,  110.70/s)  LR: 9.657e-05  Data: 0.004 (0.005)\n",
            "Train: 5 [1000/1562 ( 64%)]  Loss:  2.261181 (2.0674)  Time: 0.286s,  111.73/s  (0.289s,  110.72/s)  LR: 9.657e-05  Data: 0.004 (0.005)\n",
            "Train: 5 [1050/1562 ( 67%)]  Loss:  1.948973 (2.0688)  Time: 0.287s,  111.68/s  (0.289s,  110.76/s)  LR: 9.657e-05  Data: 0.004 (0.005)\n",
            "Train: 5 [1100/1562 ( 70%)]  Loss:  2.222636 (2.0695)  Time: 0.286s,  111.97/s  (0.289s,  110.78/s)  LR: 9.657e-05  Data: 0.004 (0.005)\n",
            "Train: 5 [1150/1562 ( 74%)]  Loss:  2.146399 (2.0727)  Time: 0.286s,  111.77/s  (0.289s,  110.80/s)  LR: 9.657e-05  Data: 0.004 (0.005)\n",
            "Train: 5 [1200/1562 ( 77%)]  Loss:  1.912965 (2.0764)  Time: 0.286s,  111.71/s  (0.289s,  110.83/s)  LR: 9.657e-05  Data: 0.004 (0.005)\n",
            "Train: 5 [1250/1562 ( 80%)]  Loss:  2.242002 (2.0758)  Time: 0.286s,  112.02/s  (0.289s,  110.84/s)  LR: 9.657e-05  Data: 0.004 (0.005)\n",
            "Train: 5 [1300/1562 ( 83%)]  Loss:  1.998914 (2.0775)  Time: 0.286s,  111.76/s  (0.289s,  110.87/s)  LR: 9.657e-05  Data: 0.004 (0.005)\n",
            "Train: 5 [1350/1562 ( 86%)]  Loss:  2.047390 (2.0781)  Time: 0.286s,  111.71/s  (0.289s,  110.89/s)  LR: 9.657e-05  Data: 0.004 (0.005)\n",
            "Train: 5 [1400/1562 ( 90%)]  Loss:  2.135322 (2.0747)  Time: 0.289s,  110.59/s  (0.289s,  110.90/s)  LR: 9.657e-05  Data: 0.004 (0.005)\n",
            "Train: 5 [1450/1562 ( 93%)]  Loss:  2.188689 (2.0759)  Time: 0.286s,  111.97/s  (0.289s,  110.91/s)  LR: 9.657e-05  Data: 0.004 (0.005)\n",
            "Train: 5 [1500/1562 ( 96%)]  Loss:  2.188460 (2.0764)  Time: 0.286s,  111.86/s  (0.288s,  110.93/s)  LR: 9.657e-05  Data: 0.004 (0.005)\n",
            "Train: 5 [1550/1562 ( 99%)]  Loss:  1.915378 (2.0757)  Time: 0.284s,  112.83/s  (0.288s,  110.95/s)  LR: 9.657e-05  Data: 0.004 (0.005)\n",
            "Train: 5 [1561/1562 (100%)]  Loss:  2.153975 (2.0749)  Time: 0.394s,   81.26/s  (0.288s,  110.93/s)  LR: 9.657e-05  Data: 0.088 (0.005)\n",
            "Test: [   0/312]  Time: 0.946 (0.946)  Loss:  1.7639 (1.7639)  Acc@1: 31.2500 (31.2500)  Acc@5: 84.3750 (84.3750)\n",
            "Test: [  50/312]  Time: 0.093 (0.114)  Loss:  1.1144 (1.3110)  Acc@1: 65.6250 (56.9240)  Acc@5: 100.0000 (94.3015)\n",
            "Test: [ 100/312]  Time: 0.094 (0.103)  Loss:  1.8398 (1.5914)  Acc@1:  9.3750 (39.7587)  Acc@5: 96.8750 (92.2339)\n",
            "Test: [ 150/312]  Time: 0.092 (0.100)  Loss:  1.7076 (1.6237)  Acc@1: 28.1250 (36.7343)  Acc@5: 93.7500 (92.7359)\n",
            "Test: [ 200/312]  Time: 0.087 (0.098)  Loss:  0.8008 (1.5989)  Acc@1: 90.6250 (40.2519)  Acc@5: 100.0000 (92.8172)\n",
            "Test: [ 250/312]  Time: 0.087 (0.097)  Loss:  1.3323 (1.4983)  Acc@1: 56.2500 (45.8665)  Acc@5: 90.6250 (92.5797)\n",
            "Test: [ 300/312]  Time: 0.086 (0.096)  Loss:  0.9400 (1.4505)  Acc@1: 87.5000 (48.8372)  Acc@5: 100.0000 (93.0752)\n",
            "Test: [ 312/312]  Time: 0.131 (0.096)  Loss:  1.2394 (1.4402)  Acc@1: 68.7500 (49.3500)  Acc@5: 93.7500 (93.1800)\n",
            "Test (EMA): [   0/312]  Time: 0.914 (0.914)  Loss:  1.9963 (1.9963)  Acc@1: 56.2500 (56.2500)  Acc@5: 87.5000 (87.5000)\n",
            "Test (EMA): [  50/312]  Time: 0.095 (0.114)  Loss:  2.4060 (2.1115)  Acc@1:  0.0000 (46.5074)  Acc@5: 31.2500 (66.9118)\n",
            "Test (EMA): [ 100/312]  Time: 0.095 (0.103)  Loss:  2.1364 (2.1176)  Acc@1:  3.1250 (27.2277)  Acc@5: 93.7500 (74.3502)\n",
            "Test (EMA): [ 150/312]  Time: 0.093 (0.099)  Loss:  2.0260 (2.1053)  Acc@1:  0.0000 (19.1225)  Acc@5: 93.7500 (80.4015)\n",
            "Test (EMA): [ 200/312]  Time: 0.095 (0.098)  Loss:  1.6862 (2.1281)  Acc@1: 87.5000 (20.6623)  Acc@5: 100.0000 (71.8595)\n",
            "Test (EMA): [ 250/312]  Time: 0.087 (0.097)  Loss:  2.2204 (2.1251)  Acc@1:  0.0000 (22.9582)  Acc@5: 81.2500 (72.7341)\n",
            "Test (EMA): [ 300/312]  Time: 0.086 (0.096)  Loss:  2.5612 (2.1589)  Acc@1:  0.0000 (19.1445)  Acc@5:  0.0000 (68.8850)\n",
            "Test (EMA): [ 312/312]  Time: 0.132 (0.096)  Loss:  2.5597 (2.1736)  Acc@1:  0.0000 (18.4400)  Acc@5:  6.2500 (66.3700)\n",
            "Current checkpoints:\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-5.pth.tar', 18.44)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-4.pth.tar', 18.35)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-3.pth.tar', 17.11)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-2.pth.tar', 11.19)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-0.pth.tar', 10.0)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-1.pth.tar', 10.0)\n",
            "\n",
            "Train: 6 [   0/1562 (  0%)]  Loss:  1.976830 (1.9768)  Time: 1.766s,   18.12/s  (1.766s,   18.12/s)  LR: 9.510e-05  Data: 1.248 (1.248)\n",
            "Train: 6 [  50/1562 (  3%)]  Loss:  1.974906 (2.0790)  Time: 0.286s,  111.95/s  (0.322s,   99.37/s)  LR: 9.510e-05  Data: 0.004 (0.029)\n",
            "Train: 6 [ 100/1562 (  6%)]  Loss:  1.895536 (2.0518)  Time: 0.292s,  109.52/s  (0.305s,  104.97/s)  LR: 9.510e-05  Data: 0.004 (0.016)\n",
            "Train: 6 [ 150/1562 ( 10%)]  Loss:  2.171570 (2.0694)  Time: 0.288s,  111.04/s  (0.299s,  107.01/s)  LR: 9.510e-05  Data: 0.004 (0.012)\n",
            "Train: 6 [ 200/1562 ( 13%)]  Loss:  2.233088 (2.0674)  Time: 0.287s,  111.49/s  (0.296s,  108.02/s)  LR: 9.510e-05  Data: 0.004 (0.010)\n",
            "Train: 6 [ 250/1562 ( 16%)]  Loss:  1.994944 (2.0595)  Time: 0.286s,  111.85/s  (0.295s,  108.63/s)  LR: 9.510e-05  Data: 0.004 (0.009)\n",
            "Train: 6 [ 300/1562 ( 19%)]  Loss:  2.163528 (2.0602)  Time: 0.287s,  111.55/s  (0.294s,  108.97/s)  LR: 9.510e-05  Data: 0.004 (0.008)\n",
            "Train: 6 [ 350/1562 ( 22%)]  Loss:  1.882414 (2.0508)  Time: 0.287s,  111.39/s  (0.293s,  109.29/s)  LR: 9.510e-05  Data: 0.004 (0.007)\n",
            "Train: 6 [ 400/1562 ( 26%)]  Loss:  2.010873 (2.0415)  Time: 0.287s,  111.54/s  (0.292s,  109.52/s)  LR: 9.510e-05  Data: 0.004 (0.007)\n",
            "Train: 6 [ 450/1562 ( 29%)]  Loss:  2.164674 (2.0400)  Time: 0.288s,  111.15/s  (0.292s,  109.68/s)  LR: 9.510e-05  Data: 0.005 (0.007)\n",
            "Train: 6 [ 500/1562 ( 32%)]  Loss:  2.143284 (2.0408)  Time: 0.289s,  110.65/s  (0.291s,  109.86/s)  LR: 9.510e-05  Data: 0.004 (0.006)\n",
            "Train: 6 [ 550/1562 ( 35%)]  Loss:  1.954432 (2.0379)  Time: 0.294s,  108.96/s  (0.291s,  109.98/s)  LR: 9.510e-05  Data: 0.004 (0.006)\n",
            "Train: 6 [ 600/1562 ( 38%)]  Loss:  2.211390 (2.0324)  Time: 0.290s,  110.47/s  (0.291s,  110.09/s)  LR: 9.510e-05  Data: 0.004 (0.006)\n",
            "Train: 6 [ 650/1562 ( 42%)]  Loss:  1.835279 (2.0336)  Time: 0.288s,  110.94/s  (0.290s,  110.18/s)  LR: 9.510e-05  Data: 0.004 (0.006)\n",
            "Train: 6 [ 700/1562 ( 45%)]  Loss:  1.977800 (2.0361)  Time: 0.287s,  111.67/s  (0.290s,  110.25/s)  LR: 9.510e-05  Data: 0.004 (0.006)\n",
            "Train: 6 [ 750/1562 ( 48%)]  Loss:  1.894223 (2.0390)  Time: 0.286s,  111.72/s  (0.290s,  110.34/s)  LR: 9.510e-05  Data: 0.004 (0.005)\n",
            "Train: 6 [ 800/1562 ( 51%)]  Loss:  1.936198 (2.0399)  Time: 0.286s,  111.87/s  (0.290s,  110.39/s)  LR: 9.510e-05  Data: 0.004 (0.005)\n",
            "Train: 6 [ 850/1562 ( 54%)]  Loss:  2.297856 (2.0426)  Time: 0.294s,  109.00/s  (0.290s,  110.47/s)  LR: 9.510e-05  Data: 0.004 (0.005)\n",
            "Train: 6 [ 900/1562 ( 58%)]  Loss:  2.049592 (2.0453)  Time: 0.291s,  110.08/s  (0.290s,  110.52/s)  LR: 9.510e-05  Data: 0.004 (0.005)\n",
            "Train: 6 [ 950/1562 ( 61%)]  Loss:  1.704813 (2.0432)  Time: 0.292s,  109.58/s  (0.289s,  110.55/s)  LR: 9.510e-05  Data: 0.004 (0.005)\n",
            "Train: 6 [1000/1562 ( 64%)]  Loss:  1.993012 (2.0458)  Time: 0.289s,  110.82/s  (0.289s,  110.56/s)  LR: 9.510e-05  Data: 0.004 (0.005)\n",
            "Train: 6 [1050/1562 ( 67%)]  Loss:  2.099927 (2.0485)  Time: 0.287s,  111.51/s  (0.289s,  110.60/s)  LR: 9.510e-05  Data: 0.004 (0.005)\n",
            "Train: 6 [1100/1562 ( 70%)]  Loss:  2.172436 (2.0491)  Time: 0.286s,  111.80/s  (0.289s,  110.63/s)  LR: 9.510e-05  Data: 0.004 (0.005)\n",
            "Train: 6 [1150/1562 ( 74%)]  Loss:  2.206636 (2.0537)  Time: 0.289s,  110.84/s  (0.289s,  110.66/s)  LR: 9.510e-05  Data: 0.004 (0.005)\n",
            "Train: 6 [1200/1562 ( 77%)]  Loss:  2.100929 (2.0577)  Time: 0.287s,  111.56/s  (0.289s,  110.69/s)  LR: 9.510e-05  Data: 0.004 (0.005)\n",
            "Train: 6 [1250/1562 ( 80%)]  Loss:  2.036530 (2.0566)  Time: 0.287s,  111.65/s  (0.289s,  110.72/s)  LR: 9.510e-05  Data: 0.004 (0.005)\n",
            "Train: 6 [1300/1562 ( 83%)]  Loss:  2.076268 (2.0572)  Time: 0.286s,  111.81/s  (0.289s,  110.75/s)  LR: 9.510e-05  Data: 0.004 (0.005)\n",
            "Train: 6 [1350/1562 ( 86%)]  Loss:  2.087563 (2.0575)  Time: 0.289s,  110.85/s  (0.289s,  110.77/s)  LR: 9.510e-05  Data: 0.004 (0.005)\n",
            "Train: 6 [1400/1562 ( 90%)]  Loss:  2.148024 (2.0539)  Time: 0.286s,  111.74/s  (0.289s,  110.79/s)  LR: 9.510e-05  Data: 0.004 (0.005)\n",
            "Train: 6 [1450/1562 ( 93%)]  Loss:  2.151496 (2.0545)  Time: 0.286s,  111.70/s  (0.289s,  110.81/s)  LR: 9.510e-05  Data: 0.004 (0.005)\n",
            "Train: 6 [1500/1562 ( 96%)]  Loss:  2.277234 (2.0549)  Time: 0.286s,  111.71/s  (0.289s,  110.83/s)  LR: 9.510e-05  Data: 0.004 (0.005)\n",
            "Train: 6 [1550/1562 ( 99%)]  Loss:  1.880048 (2.0544)  Time: 0.288s,  110.93/s  (0.289s,  110.84/s)  LR: 9.510e-05  Data: 0.003 (0.005)\n",
            "Train: 6 [1561/1562 (100%)]  Loss:  2.122984 (2.0536)  Time: 0.370s,   86.53/s  (0.289s,  110.83/s)  LR: 9.510e-05  Data: 0.089 (0.005)\n",
            "Test: [   0/312]  Time: 0.869 (0.869)  Loss:  1.4253 (1.4253)  Acc@1: 50.0000 (50.0000)  Acc@5: 93.7500 (93.7500)\n",
            "Test: [  50/312]  Time: 0.087 (0.112)  Loss:  1.0227 (1.1151)  Acc@1: 65.6250 (64.9510)  Acc@5: 100.0000 (97.6103)\n",
            "Test: [ 100/312]  Time: 0.087 (0.102)  Loss:  1.8893 (1.4057)  Acc@1: 21.8750 (48.9480)  Acc@5: 93.7500 (95.2661)\n",
            "Test: [ 150/312]  Time: 0.091 (0.099)  Loss:  1.9950 (1.5593)  Acc@1: 15.6250 (41.0182)  Acc@5: 87.5000 (93.3775)\n",
            "Test: [ 200/312]  Time: 0.100 (0.097)  Loss:  0.9304 (1.5613)  Acc@1: 84.3750 (44.0920)  Acc@5: 100.0000 (92.9415)\n",
            "Test: [ 250/312]  Time: 0.093 (0.096)  Loss:  1.3822 (1.4903)  Acc@1: 50.0000 (48.4188)  Acc@5: 93.7500 (92.4178)\n",
            "Test: [ 300/312]  Time: 0.086 (0.096)  Loss:  0.6377 (1.4342)  Acc@1: 87.5000 (50.4568)  Acc@5: 100.0000 (93.2205)\n",
            "Test: [ 312/312]  Time: 0.129 (0.095)  Loss:  0.8694 (1.4110)  Acc@1: 75.0000 (51.5100)  Acc@5: 100.0000 (93.4300)\n",
            "Test (EMA): [   0/312]  Time: 0.883 (0.883)  Loss:  1.9986 (1.9986)  Acc@1: 56.2500 (56.2500)  Acc@5: 87.5000 (87.5000)\n",
            "Test (EMA): [  50/312]  Time: 0.087 (0.112)  Loss:  2.4167 (2.1124)  Acc@1:  0.0000 (45.2819)  Acc@5: 25.0000 (66.6054)\n",
            "Test (EMA): [ 100/312]  Time: 0.087 (0.102)  Loss:  2.0955 (2.1217)  Acc@1:  3.1250 (24.6906)  Acc@5: 96.8750 (74.1027)\n",
            "Test (EMA): [ 150/312]  Time: 0.093 (0.099)  Loss:  1.9640 (2.0896)  Acc@1:  3.1250 (18.6051)  Acc@5: 96.8750 (80.7326)\n",
            "Test (EMA): [ 200/312]  Time: 0.096 (0.097)  Loss:  1.5544 (2.1054)  Acc@1: 96.8750 (20.7400)  Acc@5: 100.0000 (75.7618)\n",
            "Test (EMA): [ 250/312]  Time: 0.100 (0.096)  Loss:  2.1609 (2.1029)  Acc@1:  0.0000 (23.3068)  Acc@5: 84.3750 (75.0249)\n",
            "Test (EMA): [ 300/312]  Time: 0.086 (0.096)  Loss:  2.5606 (2.1345)  Acc@1:  0.0000 (19.4871)  Acc@5:  0.0000 (70.9614)\n",
            "Test (EMA): [ 312/312]  Time: 0.132 (0.095)  Loss:  2.5668 (2.1505)  Acc@1:  0.0000 (18.7700)  Acc@5:  6.2500 (68.3900)\n",
            "Current checkpoints:\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-6.pth.tar', 18.77)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-5.pth.tar', 18.44)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-4.pth.tar', 18.35)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-3.pth.tar', 17.11)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-2.pth.tar', 11.19)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-0.pth.tar', 10.0)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-1.pth.tar', 10.0)\n",
            "\n",
            "Train: 7 [   0/1562 (  0%)]  Loss:  1.792534 (1.7925)  Time: 1.648s,   19.42/s  (1.648s,   19.42/s)  LR: 9.337e-05  Data: 1.130 (1.130)\n",
            "Train: 7 [  50/1562 (  3%)]  Loss:  1.875958 (2.0491)  Time: 0.286s,  111.95/s  (0.319s,  100.17/s)  LR: 9.337e-05  Data: 0.003 (0.026)\n",
            "Train: 7 [ 100/1562 (  6%)]  Loss:  1.744423 (2.0223)  Time: 0.287s,  111.56/s  (0.303s,  105.54/s)  LR: 9.337e-05  Data: 0.004 (0.015)\n",
            "Train: 7 [ 150/1562 ( 10%)]  Loss:  2.240588 (2.0324)  Time: 0.286s,  111.74/s  (0.298s,  107.46/s)  LR: 9.337e-05  Data: 0.003 (0.011)\n",
            "Train: 7 [ 200/1562 ( 13%)]  Loss:  2.194585 (2.0260)  Time: 0.286s,  111.98/s  (0.295s,  108.42/s)  LR: 9.337e-05  Data: 0.004 (0.009)\n",
            "Train: 7 [ 250/1562 ( 16%)]  Loss:  1.792471 (2.0237)  Time: 0.286s,  111.90/s  (0.294s,  109.01/s)  LR: 9.337e-05  Data: 0.004 (0.008)\n",
            "Train: 7 [ 300/1562 ( 19%)]  Loss:  2.070501 (2.0243)  Time: 0.286s,  111.99/s  (0.292s,  109.44/s)  LR: 9.337e-05  Data: 0.004 (0.007)\n",
            "Train: 7 [ 350/1562 ( 22%)]  Loss:  1.884406 (2.0175)  Time: 0.285s,  112.12/s  (0.292s,  109.69/s)  LR: 9.337e-05  Data: 0.004 (0.007)\n",
            "Train: 7 [ 400/1562 ( 26%)]  Loss:  2.038800 (2.0140)  Time: 0.286s,  111.87/s  (0.291s,  109.90/s)  LR: 9.337e-05  Data: 0.004 (0.007)\n",
            "Train: 7 [ 450/1562 ( 29%)]  Loss:  2.161882 (2.0128)  Time: 0.289s,  110.83/s  (0.291s,  110.05/s)  LR: 9.337e-05  Data: 0.004 (0.006)\n",
            "Train: 7 [ 500/1562 ( 32%)]  Loss:  2.033798 (2.0139)  Time: 0.286s,  112.00/s  (0.290s,  110.19/s)  LR: 9.337e-05  Data: 0.004 (0.006)\n",
            "Train: 7 [ 550/1562 ( 35%)]  Loss:  1.983149 (2.0088)  Time: 0.292s,  109.67/s  (0.290s,  110.29/s)  LR: 9.337e-05  Data: 0.004 (0.006)\n",
            "Train: 7 [ 600/1562 ( 38%)]  Loss:  2.219033 (2.0056)  Time: 0.289s,  110.67/s  (0.290s,  110.39/s)  LR: 9.337e-05  Data: 0.004 (0.006)\n",
            "Train: 7 [ 650/1562 ( 42%)]  Loss:  1.850225 (2.0073)  Time: 0.287s,  111.55/s  (0.290s,  110.45/s)  LR: 9.337e-05  Data: 0.004 (0.005)\n",
            "Train: 7 [ 700/1562 ( 45%)]  Loss:  1.861756 (2.0100)  Time: 0.288s,  110.92/s  (0.290s,  110.50/s)  LR: 9.337e-05  Data: 0.004 (0.005)\n",
            "Train: 7 [ 750/1562 ( 48%)]  Loss:  1.898286 (2.0133)  Time: 0.286s,  111.97/s  (0.289s,  110.55/s)  LR: 9.337e-05  Data: 0.004 (0.005)\n",
            "Train: 7 [ 800/1562 ( 51%)]  Loss:  1.990206 (2.0144)  Time: 0.286s,  111.73/s  (0.289s,  110.60/s)  LR: 9.337e-05  Data: 0.004 (0.005)\n",
            "Train: 7 [ 850/1562 ( 54%)]  Loss:  2.117785 (2.0188)  Time: 0.289s,  110.77/s  (0.289s,  110.65/s)  LR: 9.337e-05  Data: 0.004 (0.005)\n",
            "Train: 7 [ 900/1562 ( 58%)]  Loss:  1.961415 (2.0195)  Time: 0.286s,  111.72/s  (0.289s,  110.68/s)  LR: 9.337e-05  Data: 0.004 (0.005)\n",
            "Train: 7 [ 950/1562 ( 61%)]  Loss:  1.857150 (2.0202)  Time: 0.286s,  112.08/s  (0.289s,  110.72/s)  LR: 9.337e-05  Data: 0.004 (0.005)\n",
            "Train: 7 [1000/1562 ( 64%)]  Loss:  2.084407 (2.0220)  Time: 0.294s,  108.86/s  (0.289s,  110.76/s)  LR: 9.337e-05  Data: 0.004 (0.005)\n",
            "Train: 7 [1050/1562 ( 67%)]  Loss:  1.747836 (2.0254)  Time: 0.291s,  109.98/s  (0.289s,  110.78/s)  LR: 9.337e-05  Data: 0.004 (0.005)\n",
            "Train: 7 [1100/1562 ( 70%)]  Loss:  2.180578 (2.0260)  Time: 0.316s,  101.28/s  (0.289s,  110.81/s)  LR: 9.337e-05  Data: 0.004 (0.005)\n",
            "Train: 7 [1150/1562 ( 74%)]  Loss:  2.133764 (2.0314)  Time: 0.287s,  111.68/s  (0.289s,  110.83/s)  LR: 9.337e-05  Data: 0.004 (0.005)\n",
            "Train: 7 [1200/1562 ( 77%)]  Loss:  1.991840 (2.0355)  Time: 0.286s,  111.99/s  (0.289s,  110.84/s)  LR: 9.337e-05  Data: 0.004 (0.005)\n",
            "Train: 7 [1250/1562 ( 80%)]  Loss:  1.980748 (2.0356)  Time: 0.286s,  111.93/s  (0.289s,  110.86/s)  LR: 9.337e-05  Data: 0.004 (0.005)\n",
            "Train: 7 [1300/1562 ( 83%)]  Loss:  2.007733 (2.0375)  Time: 0.286s,  111.78/s  (0.289s,  110.87/s)  LR: 9.337e-05  Data: 0.004 (0.005)\n",
            "Train: 7 [1350/1562 ( 86%)]  Loss:  2.103294 (2.0377)  Time: 0.286s,  111.86/s  (0.289s,  110.89/s)  LR: 9.337e-05  Data: 0.004 (0.005)\n",
            "Train: 7 [1400/1562 ( 90%)]  Loss:  2.009436 (2.0347)  Time: 0.286s,  111.80/s  (0.289s,  110.91/s)  LR: 9.337e-05  Data: 0.004 (0.005)\n",
            "Train: 7 [1450/1562 ( 93%)]  Loss:  2.123710 (2.0357)  Time: 0.289s,  110.85/s  (0.288s,  110.93/s)  LR: 9.337e-05  Data: 0.004 (0.005)\n",
            "Train: 7 [1500/1562 ( 96%)]  Loss:  2.095293 (2.0359)  Time: 0.286s,  111.78/s  (0.288s,  110.94/s)  LR: 9.337e-05  Data: 0.004 (0.005)\n",
            "Train: 7 [1550/1562 ( 99%)]  Loss:  1.856325 (2.0342)  Time: 0.284s,  112.86/s  (0.288s,  110.96/s)  LR: 9.337e-05  Data: 0.003 (0.005)\n",
            "Train: 7 [1561/1562 (100%)]  Loss:  2.075346 (2.0332)  Time: 0.368s,   87.07/s  (0.288s,  110.94/s)  LR: 9.337e-05  Data: 0.088 (0.005)\n",
            "Test: [   0/312]  Time: 0.857 (0.857)  Loss:  1.5701 (1.5701)  Acc@1: 43.7500 (43.7500)  Acc@5: 87.5000 (87.5000)\n",
            "Test: [  50/312]  Time: 0.103 (0.112)  Loss:  1.5636 (1.4105)  Acc@1: 40.6250 (49.2034)  Acc@5: 93.7500 (93.2598)\n",
            "Test: [ 100/312]  Time: 0.098 (0.102)  Loss:  1.6010 (1.5973)  Acc@1: 25.0000 (37.1287)  Acc@5: 96.8750 (93.1621)\n",
            "Test: [ 150/312]  Time: 0.093 (0.099)  Loss:  2.2178 (1.6609)  Acc@1: 12.5000 (31.2293)  Acc@5: 75.0000 (92.5911)\n",
            "Test: [ 200/312]  Time: 0.096 (0.098)  Loss:  0.9955 (1.5664)  Acc@1: 78.1250 (40.6872)  Acc@5: 100.0000 (93.6878)\n",
            "Test: [ 250/312]  Time: 0.091 (0.097)  Loss:  1.0981 (1.4805)  Acc@1: 56.2500 (45.7047)  Acc@5: 93.7500 (93.7251)\n",
            "Test: [ 300/312]  Time: 0.086 (0.096)  Loss:  0.8786 (1.4111)  Acc@1: 81.2500 (49.8131)  Acc@5: 100.0000 (93.9888)\n",
            "Test: [ 312/312]  Time: 0.132 (0.096)  Loss:  1.0355 (1.3986)  Acc@1: 75.0000 (50.5600)  Acc@5: 93.7500 (94.0400)\n",
            "Test (EMA): [   0/312]  Time: 0.933 (0.933)  Loss:  2.0146 (2.0146)  Acc@1: 53.1250 (53.1250)  Acc@5: 87.5000 (87.5000)\n",
            "Test (EMA): [  50/312]  Time: 0.097 (0.113)  Loss:  2.4143 (2.1152)  Acc@1:  0.0000 (43.2598)  Acc@5: 31.2500 (67.5858)\n",
            "Test (EMA): [ 100/312]  Time: 0.089 (0.103)  Loss:  2.0716 (2.1228)  Acc@1:  0.0000 (22.7104)  Acc@5: 96.8750 (75.1547)\n",
            "Test (EMA): [ 150/312]  Time: 0.092 (0.100)  Loss:  1.9110 (2.0759)  Acc@1:  6.2500 (17.7152)  Acc@5: 100.0000 (81.8088)\n",
            "Test (EMA): [ 200/312]  Time: 0.094 (0.098)  Loss:  1.4237 (2.0832)  Acc@1: 96.8750 (20.3047)  Acc@5: 100.0000 (79.7730)\n",
            "Test (EMA): [ 250/312]  Time: 0.090 (0.097)  Loss:  2.1171 (2.0807)  Acc@1:  6.2500 (23.0329)  Acc@5: 84.3750 (77.5149)\n",
            "Test (EMA): [ 300/312]  Time: 0.086 (0.096)  Loss:  2.5350 (2.1105)  Acc@1:  0.0000 (19.7155)  Acc@5:  9.3750 (73.4946)\n",
            "Test (EMA): [ 312/312]  Time: 0.133 (0.096)  Loss:  2.5538 (2.1271)  Acc@1:  0.0000 (18.9900)  Acc@5: 12.5000 (71.0200)\n",
            "Current checkpoints:\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-7.pth.tar', 18.99)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-6.pth.tar', 18.77)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-5.pth.tar', 18.44)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-4.pth.tar', 18.35)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-3.pth.tar', 17.11)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-2.pth.tar', 11.19)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-0.pth.tar', 10.0)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-1.pth.tar', 10.0)\n",
            "\n",
            "Train: 8 [   0/1562 (  0%)]  Loss:  1.967907 (1.9679)  Time: 1.815s,   17.63/s  (1.815s,   17.63/s)  LR: 9.141e-05  Data: 1.341 (1.341)\n",
            "Train: 8 [  50/1562 (  3%)]  Loss:  1.914362 (2.0913)  Time: 0.289s,  110.56/s  (0.323s,   98.98/s)  LR: 9.141e-05  Data: 0.007 (0.031)\n",
            "Train: 8 [ 100/1562 (  6%)]  Loss:  1.800589 (2.0508)  Time: 0.286s,  112.04/s  (0.306s,  104.70/s)  LR: 9.141e-05  Data: 0.004 (0.017)\n",
            "Train: 8 [ 150/1562 ( 10%)]  Loss:  2.083606 (2.0456)  Time: 0.286s,  111.85/s  (0.300s,  106.75/s)  LR: 9.141e-05  Data: 0.004 (0.013)\n",
            "Train: 8 [ 200/1562 ( 13%)]  Loss:  2.054866 (2.0328)  Time: 0.289s,  110.68/s  (0.297s,  107.85/s)  LR: 9.141e-05  Data: 0.004 (0.011)\n",
            "Train: 8 [ 250/1562 ( 16%)]  Loss:  1.908863 (2.0237)  Time: 0.286s,  111.82/s  (0.295s,  108.53/s)  LR: 9.141e-05  Data: 0.004 (0.009)\n",
            "Train: 8 [ 300/1562 ( 19%)]  Loss:  2.085283 (2.0256)  Time: 0.286s,  112.04/s  (0.294s,  108.97/s)  LR: 9.141e-05  Data: 0.004 (0.008)\n",
            "Train: 8 [ 350/1562 ( 22%)]  Loss:  1.757937 (2.0163)  Time: 0.286s,  112.07/s  (0.293s,  109.34/s)  LR: 9.141e-05  Data: 0.004 (0.008)\n",
            "Train: 8 [ 400/1562 ( 26%)]  Loss:  2.149936 (2.0079)  Time: 0.294s,  109.00/s  (0.292s,  109.60/s)  LR: 9.141e-05  Data: 0.004 (0.007)\n",
            "Train: 8 [ 450/1562 ( 29%)]  Loss:  2.049164 (2.0083)  Time: 0.294s,  109.00/s  (0.291s,  109.81/s)  LR: 9.141e-05  Data: 0.004 (0.007)\n",
            "Train: 8 [ 500/1562 ( 32%)]  Loss:  1.751035 (2.0071)  Time: 0.288s,  111.27/s  (0.291s,  109.93/s)  LR: 9.141e-05  Data: 0.004 (0.007)\n",
            "Train: 8 [ 550/1562 ( 35%)]  Loss:  2.113628 (2.0027)  Time: 0.286s,  111.71/s  (0.291s,  110.04/s)  LR: 9.141e-05  Data: 0.004 (0.006)\n",
            "Train: 8 [ 600/1562 ( 38%)]  Loss:  2.208288 (2.0008)  Time: 0.289s,  110.66/s  (0.291s,  110.13/s)  LR: 9.141e-05  Data: 0.004 (0.006)\n",
            "Train: 8 [ 650/1562 ( 42%)]  Loss:  1.795158 (2.0043)  Time: 0.286s,  111.79/s  (0.290s,  110.21/s)  LR: 9.141e-05  Data: 0.004 (0.006)\n",
            "Train: 8 [ 700/1562 ( 45%)]  Loss:  1.857642 (2.0058)  Time: 0.286s,  111.71/s  (0.290s,  110.30/s)  LR: 9.141e-05  Data: 0.004 (0.006)\n",
            "Train: 8 [ 750/1562 ( 48%)]  Loss:  2.019198 (2.0098)  Time: 0.290s,  110.29/s  (0.290s,  110.36/s)  LR: 9.141e-05  Data: 0.004 (0.006)\n",
            "Train: 8 [ 800/1562 ( 51%)]  Loss:  1.803430 (2.0113)  Time: 0.287s,  111.58/s  (0.290s,  110.42/s)  LR: 9.141e-05  Data: 0.004 (0.006)\n",
            "Train: 8 [ 850/1562 ( 54%)]  Loss:  2.329864 (2.0158)  Time: 0.286s,  111.70/s  (0.290s,  110.46/s)  LR: 9.141e-05  Data: 0.004 (0.005)\n",
            "Train: 8 [ 900/1562 ( 58%)]  Loss:  1.967587 (2.0163)  Time: 0.293s,  109.04/s  (0.290s,  110.48/s)  LR: 9.141e-05  Data: 0.004 (0.005)\n",
            "Train: 8 [ 950/1562 ( 61%)]  Loss:  1.878174 (2.0155)  Time: 0.286s,  111.88/s  (0.290s,  110.52/s)  LR: 9.141e-05  Data: 0.004 (0.005)\n",
            "Train: 8 [1000/1562 ( 64%)]  Loss:  2.035436 (2.0161)  Time: 0.286s,  111.75/s  (0.289s,  110.55/s)  LR: 9.141e-05  Data: 0.004 (0.005)\n",
            "Train: 8 [1050/1562 ( 67%)]  Loss:  1.879518 (2.0194)  Time: 0.287s,  111.54/s  (0.289s,  110.58/s)  LR: 9.141e-05  Data: 0.004 (0.005)\n",
            "Train: 8 [1100/1562 ( 70%)]  Loss:  2.076997 (2.0198)  Time: 0.296s,  107.97/s  (0.289s,  110.60/s)  LR: 9.141e-05  Data: 0.009 (0.005)\n",
            "Train: 8 [1150/1562 ( 74%)]  Loss:  2.114928 (2.0247)  Time: 0.286s,  111.85/s  (0.289s,  110.62/s)  LR: 9.141e-05  Data: 0.004 (0.005)\n",
            "Train: 8 [1200/1562 ( 77%)]  Loss:  1.894341 (2.0276)  Time: 0.286s,  111.85/s  (0.289s,  110.65/s)  LR: 9.141e-05  Data: 0.004 (0.005)\n",
            "Train: 8 [1250/1562 ( 80%)]  Loss:  1.990600 (2.0271)  Time: 0.286s,  111.85/s  (0.289s,  110.67/s)  LR: 9.141e-05  Data: 0.004 (0.005)\n",
            "Train: 8 [1300/1562 ( 83%)]  Loss:  1.896969 (2.0287)  Time: 0.287s,  111.69/s  (0.289s,  110.69/s)  LR: 9.141e-05  Data: 0.004 (0.005)\n",
            "Train: 8 [1350/1562 ( 86%)]  Loss:  2.060102 (2.0294)  Time: 0.294s,  109.00/s  (0.289s,  110.71/s)  LR: 9.141e-05  Data: 0.004 (0.005)\n",
            "Train: 8 [1400/1562 ( 90%)]  Loss:  2.237179 (2.0246)  Time: 0.286s,  111.93/s  (0.289s,  110.73/s)  LR: 9.141e-05  Data: 0.004 (0.005)\n",
            "Train: 8 [1450/1562 ( 93%)]  Loss:  2.088384 (2.0254)  Time: 0.286s,  111.97/s  (0.289s,  110.75/s)  LR: 9.141e-05  Data: 0.004 (0.005)\n",
            "Train: 8 [1500/1562 ( 96%)]  Loss:  2.157269 (2.0256)  Time: 0.286s,  111.92/s  (0.289s,  110.77/s)  LR: 9.141e-05  Data: 0.004 (0.005)\n",
            "Train: 8 [1550/1562 ( 99%)]  Loss:  1.721369 (2.0239)  Time: 0.284s,  112.72/s  (0.289s,  110.78/s)  LR: 9.141e-05  Data: 0.003 (0.005)\n",
            "Train: 8 [1561/1562 (100%)]  Loss:  2.016327 (2.0223)  Time: 0.372s,   85.97/s  (0.289s,  110.77/s)  LR: 9.141e-05  Data: 0.092 (0.005)\n",
            "Test: [   0/312]  Time: 0.908 (0.908)  Loss:  1.2919 (1.2919)  Acc@1: 56.2500 (56.2500)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [  50/312]  Time: 0.093 (0.113)  Loss:  1.1186 (1.1030)  Acc@1: 62.5000 (63.8480)  Acc@5: 93.7500 (96.7525)\n",
            "Test: [ 100/312]  Time: 0.091 (0.103)  Loss:  1.6222 (1.4121)  Acc@1: 37.5000 (47.6485)  Acc@5: 96.8750 (94.6782)\n",
            "Test: [ 150/312]  Time: 0.091 (0.100)  Loss:  1.9979 (1.4800)  Acc@1: 21.8750 (45.2608)  Acc@5: 84.3750 (94.4743)\n",
            "Test: [ 200/312]  Time: 0.092 (0.098)  Loss:  0.8385 (1.4879)  Acc@1: 81.2500 (45.7400)  Acc@5: 100.0000 (93.8122)\n",
            "Test: [ 250/312]  Time: 0.093 (0.097)  Loss:  0.9550 (1.3980)  Acc@1: 65.6250 (50.9711)  Acc@5: 100.0000 (93.6006)\n",
            "Test: [ 300/312]  Time: 0.086 (0.096)  Loss:  0.7551 (1.3254)  Acc@1: 84.3750 (54.3501)  Acc@5: 100.0000 (94.1653)\n",
            "Test: [ 312/312]  Time: 0.132 (0.096)  Loss:  0.8223 (1.3105)  Acc@1: 87.5000 (55.1100)  Acc@5: 93.7500 (94.2800)\n",
            "Test (EMA): [   0/312]  Time: 0.966 (0.966)  Loss:  2.0179 (2.0179)  Acc@1: 56.2500 (56.2500)  Acc@5: 87.5000 (87.5000)\n",
            "Test (EMA): [  50/312]  Time: 0.103 (0.114)  Loss:  2.3978 (2.1037)  Acc@1:  0.0000 (41.2377)  Acc@5: 31.2500 (71.8750)\n",
            "Test (EMA): [ 100/312]  Time: 0.087 (0.103)  Loss:  2.0409 (2.1146)  Acc@1:  3.1250 (21.4728)  Acc@5: 100.0000 (78.4963)\n",
            "Test (EMA): [ 150/312]  Time: 0.088 (0.100)  Loss:  1.8836 (2.0588)  Acc@1:  9.3750 (17.2599)  Acc@5: 100.0000 (84.2301)\n",
            "Test (EMA): [ 200/312]  Time: 0.093 (0.098)  Loss:  1.3110 (2.0593)  Acc@1: 96.8750 (20.1493)  Acc@5: 100.0000 (83.1934)\n",
            "Test (EMA): [ 250/312]  Time: 0.095 (0.097)  Loss:  2.0527 (2.0562)  Acc@1: 12.5000 (22.9706)  Acc@5: 84.3750 (80.0548)\n",
            "Test (EMA): [ 300/312]  Time: 0.086 (0.096)  Loss:  2.4825 (2.0812)  Acc@1:  0.0000 (20.5150)  Acc@5: 25.0000 (76.4743)\n",
            "Test (EMA): [ 312/312]  Time: 0.131 (0.096)  Loss:  2.5195 (2.0977)  Acc@1:  0.0000 (19.7600)  Acc@5: 18.7500 (74.2300)\n",
            "Current checkpoints:\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-8.pth.tar', 19.76)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-7.pth.tar', 18.99)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-6.pth.tar', 18.77)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-5.pth.tar', 18.44)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-4.pth.tar', 18.35)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-3.pth.tar', 17.11)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-2.pth.tar', 11.19)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-0.pth.tar', 10.0)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-1.pth.tar', 10.0)\n",
            "\n",
            "Train: 9 [   0/1562 (  0%)]  Loss:  1.914885 (1.9149)  Time: 1.688s,   18.96/s  (1.688s,   18.96/s)  LR: 8.922e-05  Data: 1.171 (1.171)\n",
            "Train: 9 [  50/1562 (  3%)]  Loss:  1.829886 (2.0432)  Time: 0.287s,  111.51/s  (0.322s,   99.43/s)  LR: 8.922e-05  Data: 0.004 (0.028)\n",
            "Train: 9 [ 100/1562 (  6%)]  Loss:  1.713836 (2.0130)  Time: 0.286s,  111.88/s  (0.305s,  104.99/s)  LR: 8.922e-05  Data: 0.004 (0.016)\n",
            "Train: 9 [ 150/1562 ( 10%)]  Loss:  2.146911 (2.0251)  Time: 0.287s,  111.33/s  (0.299s,  107.02/s)  LR: 8.922e-05  Data: 0.004 (0.012)\n",
            "Train: 9 [ 200/1562 ( 13%)]  Loss:  2.256138 (2.0184)  Time: 0.286s,  111.86/s  (0.296s,  108.06/s)  LR: 8.922e-05  Data: 0.004 (0.010)\n",
            "Train: 9 [ 250/1562 ( 16%)]  Loss:  1.861366 (2.0138)  Time: 0.295s,  108.65/s  (0.294s,  108.69/s)  LR: 8.922e-05  Data: 0.004 (0.009)\n",
            "Train: 9 [ 300/1562 ( 19%)]  Loss:  1.975774 (2.0126)  Time: 0.291s,  109.87/s  (0.293s,  109.13/s)  LR: 8.922e-05  Data: 0.004 (0.008)\n",
            "Train: 9 [ 350/1562 ( 22%)]  Loss:  1.985731 (2.0035)  Time: 0.287s,  111.60/s  (0.292s,  109.42/s)  LR: 8.922e-05  Data: 0.004 (0.007)\n",
            "Train: 9 [ 400/1562 ( 26%)]  Loss:  2.075144 (1.9947)  Time: 0.290s,  110.31/s  (0.292s,  109.58/s)  LR: 8.922e-05  Data: 0.004 (0.007)\n",
            "Train: 9 [ 450/1562 ( 29%)]  Loss:  2.203282 (1.9942)  Time: 0.286s,  111.71/s  (0.292s,  109.65/s)  LR: 8.922e-05  Data: 0.004 (0.007)\n",
            "Train: 9 [ 500/1562 ( 32%)]  Loss:  1.879548 (1.9924)  Time: 0.289s,  110.55/s  (0.292s,  109.76/s)  LR: 8.922e-05  Data: 0.004 (0.006)\n",
            "Train: 9 [ 550/1562 ( 35%)]  Loss:  1.901484 (1.9910)  Time: 0.286s,  111.81/s  (0.291s,  109.90/s)  LR: 8.922e-05  Data: 0.004 (0.006)\n",
            "Train: 9 [ 600/1562 ( 38%)]  Loss:  2.182700 (1.9889)  Time: 0.295s,  108.62/s  (0.291s,  110.01/s)  LR: 8.922e-05  Data: 0.004 (0.006)\n",
            "Train: 9 [ 650/1562 ( 42%)]  Loss:  1.773054 (1.9901)  Time: 0.287s,  111.67/s  (0.291s,  110.09/s)  LR: 8.922e-05  Data: 0.004 (0.006)\n",
            "Train: 9 [ 700/1562 ( 45%)]  Loss:  1.725222 (1.9911)  Time: 0.287s,  111.34/s  (0.290s,  110.17/s)  LR: 8.922e-05  Data: 0.004 (0.006)\n",
            "Train: 9 [ 750/1562 ( 48%)]  Loss:  1.836432 (1.9963)  Time: 0.288s,  111.16/s  (0.290s,  110.23/s)  LR: 8.922e-05  Data: 0.004 (0.006)\n",
            "Train: 9 [ 800/1562 ( 51%)]  Loss:  1.879343 (1.9982)  Time: 0.288s,  110.92/s  (0.290s,  110.29/s)  LR: 8.922e-05  Data: 0.004 (0.005)\n",
            "Train: 9 [ 850/1562 ( 54%)]  Loss:  2.221132 (2.0033)  Time: 0.291s,  109.90/s  (0.290s,  110.34/s)  LR: 8.922e-05  Data: 0.004 (0.005)\n",
            "Train: 9 [ 900/1562 ( 58%)]  Loss:  1.953652 (2.0047)  Time: 0.287s,  111.48/s  (0.290s,  110.38/s)  LR: 8.922e-05  Data: 0.004 (0.005)\n",
            "Train: 9 [ 950/1562 ( 61%)]  Loss:  1.823610 (2.0038)  Time: 0.288s,  110.99/s  (0.290s,  110.43/s)  LR: 8.922e-05  Data: 0.004 (0.005)\n",
            "Train: 9 [1000/1562 ( 64%)]  Loss:  2.114371 (2.0054)  Time: 0.289s,  110.58/s  (0.290s,  110.47/s)  LR: 8.922e-05  Data: 0.004 (0.005)\n",
            "Train: 9 [1050/1562 ( 67%)]  Loss:  1.799788 (2.0085)  Time: 0.286s,  111.78/s  (0.290s,  110.50/s)  LR: 8.922e-05  Data: 0.004 (0.005)\n",
            "Train: 9 [1100/1562 ( 70%)]  Loss:  2.096846 (2.0101)  Time: 0.286s,  111.88/s  (0.289s,  110.54/s)  LR: 8.922e-05  Data: 0.004 (0.005)\n",
            "Train: 9 [1150/1562 ( 74%)]  Loss:  2.111508 (2.0157)  Time: 0.288s,  111.00/s  (0.289s,  110.56/s)  LR: 8.922e-05  Data: 0.005 (0.005)\n",
            "Train: 9 [1200/1562 ( 77%)]  Loss:  1.983620 (2.0197)  Time: 0.287s,  111.64/s  (0.289s,  110.59/s)  LR: 8.922e-05  Data: 0.004 (0.005)\n",
            "Train: 9 [1250/1562 ( 80%)]  Loss:  2.140143 (2.0187)  Time: 0.290s,  110.24/s  (0.289s,  110.62/s)  LR: 8.922e-05  Data: 0.004 (0.005)\n",
            "Train: 9 [1300/1562 ( 83%)]  Loss:  1.778914 (2.0212)  Time: 0.288s,  111.17/s  (0.289s,  110.64/s)  LR: 8.922e-05  Data: 0.004 (0.005)\n",
            "Train: 9 [1350/1562 ( 86%)]  Loss:  2.036402 (2.0226)  Time: 0.286s,  111.94/s  (0.289s,  110.66/s)  LR: 8.922e-05  Data: 0.004 (0.005)\n",
            "Train: 9 [1400/1562 ( 90%)]  Loss:  2.165347 (2.0199)  Time: 0.290s,  110.52/s  (0.289s,  110.68/s)  LR: 8.922e-05  Data: 0.004 (0.005)\n",
            "Train: 9 [1450/1562 ( 93%)]  Loss:  2.226574 (2.0219)  Time: 0.287s,  111.43/s  (0.289s,  110.70/s)  LR: 8.922e-05  Data: 0.004 (0.005)\n",
            "Train: 9 [1500/1562 ( 96%)]  Loss:  2.017215 (2.0225)  Time: 0.286s,  111.95/s  (0.289s,  110.71/s)  LR: 8.922e-05  Data: 0.004 (0.005)\n",
            "Train: 9 [1550/1562 ( 99%)]  Loss:  1.667527 (2.0205)  Time: 0.283s,  113.12/s  (0.289s,  110.73/s)  LR: 8.922e-05  Data: 0.003 (0.005)\n",
            "Train: 9 [1561/1562 (100%)]  Loss:  2.078593 (2.0192)  Time: 0.371s,   86.19/s  (0.289s,  110.72/s)  LR: 8.922e-05  Data: 0.091 (0.005)\n",
            "Test: [   0/312]  Time: 0.899 (0.899)  Loss:  1.3644 (1.3644)  Acc@1: 46.8750 (46.8750)  Acc@5: 96.8750 (96.8750)\n",
            "Test: [  50/312]  Time: 0.103 (0.114)  Loss:  1.1431 (1.1501)  Acc@1: 62.5000 (61.9485)  Acc@5: 90.6250 (95.6495)\n",
            "Test: [ 100/312]  Time: 0.087 (0.103)  Loss:  1.6919 (1.5115)  Acc@1: 37.5000 (43.5334)  Acc@5: 96.8750 (92.5124)\n",
            "Test: [ 150/312]  Time: 0.087 (0.100)  Loss:  1.7631 (1.5340)  Acc@1: 28.1250 (41.1838)  Acc@5: 96.8750 (93.3568)\n",
            "Test: [ 200/312]  Time: 0.088 (0.098)  Loss:  0.7882 (1.4805)  Acc@1: 78.1250 (45.1648)  Acc@5: 100.0000 (94.2320)\n",
            "Test: [ 250/312]  Time: 0.087 (0.097)  Loss:  0.9691 (1.3620)  Acc@1: 71.8750 (51.3322)  Acc@5: 96.8750 (94.4846)\n",
            "Test: [ 300/312]  Time: 0.086 (0.097)  Loss:  0.9815 (1.3068)  Acc@1: 71.8750 (54.4954)  Acc@5: 96.8750 (94.7155)\n",
            "Test: [ 312/312]  Time: 0.135 (0.096)  Loss:  0.9630 (1.2997)  Acc@1: 75.0000 (54.8700)  Acc@5: 93.7500 (94.7500)\n",
            "Test (EMA): [   0/312]  Time: 0.872 (0.872)  Loss:  2.0120 (2.0120)  Acc@1: 46.8750 (46.8750)  Acc@5: 87.5000 (87.5000)\n",
            "Test (EMA): [  50/312]  Time: 0.100 (0.113)  Loss:  2.3621 (2.0768)  Acc@1:  3.1250 (39.6446)  Acc@5: 43.7500 (76.1029)\n",
            "Test (EMA): [ 100/312]  Time: 0.099 (0.103)  Loss:  2.0084 (2.0955)  Acc@1:  3.1250 (20.5755)  Acc@5: 100.0000 (81.6832)\n",
            "Test (EMA): [ 150/312]  Time: 0.098 (0.100)  Loss:  1.8687 (2.0364)  Acc@1: 15.6250 (16.9702)  Acc@5: 100.0000 (86.5480)\n",
            "Test (EMA): [ 200/312]  Time: 0.086 (0.098)  Loss:  1.2210 (2.0323)  Acc@1: 96.8750 (19.9938)  Acc@5: 100.0000 (86.1940)\n",
            "Test (EMA): [ 250/312]  Time: 0.093 (0.097)  Loss:  1.9744 (2.0292)  Acc@1: 31.2500 (22.9333)  Acc@5: 87.5000 (82.4079)\n",
            "Test (EMA): [ 300/312]  Time: 0.086 (0.096)  Loss:  2.4012 (2.0468)  Acc@1:  0.0000 (22.0100)  Acc@5: 53.1250 (79.8484)\n",
            "Test (EMA): [ 312/312]  Time: 0.138 (0.096)  Loss:  2.4612 (2.0626)  Acc@1:  0.0000 (21.2000)  Acc@5: 43.7500 (78.1600)\n",
            "Current checkpoints:\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-9.pth.tar', 21.2)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-8.pth.tar', 19.76)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-7.pth.tar', 18.99)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-6.pth.tar', 18.77)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-5.pth.tar', 18.44)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-4.pth.tar', 18.35)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-3.pth.tar', 17.11)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-2.pth.tar', 11.19)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-0.pth.tar', 10.0)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-1.pth.tar', 10.0)\n",
            "\n",
            "Train: 10 [   0/1562 (  0%)]  Loss:  1.956251 (1.9563)  Time: 1.773s,   18.05/s  (1.773s,   18.05/s)  LR: 8.682e-05  Data: 1.292 (1.292)\n",
            "Train: 10 [  50/1562 (  3%)]  Loss:  2.045471 (2.0414)  Time: 0.287s,  111.66/s  (0.321s,   99.57/s)  LR: 8.682e-05  Data: 0.004 (0.030)\n",
            "Train: 10 [ 100/1562 (  6%)]  Loss:  1.786360 (2.0158)  Time: 0.286s,  112.02/s  (0.304s,  105.12/s)  LR: 8.682e-05  Data: 0.004 (0.017)\n",
            "Train: 10 [ 150/1562 ( 10%)]  Loss:  1.954708 (2.0165)  Time: 0.287s,  111.45/s  (0.299s,  107.13/s)  LR: 8.682e-05  Data: 0.004 (0.012)\n",
            "Train: 10 [ 200/1562 ( 13%)]  Loss:  2.018741 (2.0016)  Time: 0.286s,  111.76/s  (0.296s,  108.18/s)  LR: 8.682e-05  Data: 0.004 (0.010)\n",
            "Train: 10 [ 250/1562 ( 16%)]  Loss:  1.787393 (1.9951)  Time: 0.286s,  112.02/s  (0.294s,  108.76/s)  LR: 8.682e-05  Data: 0.004 (0.009)\n",
            "Train: 10 [ 300/1562 ( 19%)]  Loss:  2.090920 (1.9943)  Time: 0.288s,  111.22/s  (0.293s,  109.19/s)  LR: 8.682e-05  Data: 0.004 (0.008)\n",
            "Train: 10 [ 350/1562 ( 22%)]  Loss:  2.091095 (1.9840)  Time: 0.287s,  111.64/s  (0.292s,  109.50/s)  LR: 8.682e-05  Data: 0.004 (0.007)\n",
            "Train: 10 [ 400/1562 ( 26%)]  Loss:  2.236518 (1.9695)  Time: 0.287s,  111.63/s  (0.292s,  109.68/s)  LR: 8.682e-05  Data: 0.004 (0.007)\n",
            "Train: 10 [ 450/1562 ( 29%)]  Loss:  2.135890 (1.9690)  Time: 0.286s,  111.79/s  (0.291s,  109.89/s)  LR: 8.682e-05  Data: 0.004 (0.007)\n",
            "Train: 10 [ 500/1562 ( 32%)]  Loss:  1.891762 (1.9718)  Time: 0.289s,  110.72/s  (0.291s,  110.05/s)  LR: 8.682e-05  Data: 0.006 (0.006)\n",
            "Train: 10 [ 550/1562 ( 35%)]  Loss:  1.909337 (1.9668)  Time: 0.287s,  111.65/s  (0.290s,  110.17/s)  LR: 8.682e-05  Data: 0.004 (0.006)\n",
            "Train: 10 [ 600/1562 ( 38%)]  Loss:  2.170778 (1.9635)  Time: 0.294s,  108.75/s  (0.290s,  110.25/s)  LR: 8.682e-05  Data: 0.004 (0.006)\n",
            "Train: 10 [ 650/1562 ( 42%)]  Loss:  1.752325 (1.9643)  Time: 0.286s,  111.97/s  (0.290s,  110.34/s)  LR: 8.682e-05  Data: 0.004 (0.006)\n",
            "Train: 10 [ 700/1562 ( 45%)]  Loss:  1.736042 (1.9658)  Time: 0.286s,  111.86/s  (0.290s,  110.42/s)  LR: 8.682e-05  Data: 0.004 (0.006)\n",
            "Train: 10 [ 750/1562 ( 48%)]  Loss:  1.957530 (1.9710)  Time: 0.290s,  110.18/s  (0.290s,  110.49/s)  LR: 8.682e-05  Data: 0.004 (0.006)\n",
            "Train: 10 [ 800/1562 ( 51%)]  Loss:  1.685330 (1.9736)  Time: 0.286s,  111.87/s  (0.290s,  110.53/s)  LR: 8.682e-05  Data: 0.004 (0.005)\n",
            "Train: 10 [ 850/1562 ( 54%)]  Loss:  2.188071 (1.9782)  Time: 0.286s,  111.72/s  (0.289s,  110.58/s)  LR: 8.682e-05  Data: 0.004 (0.005)\n",
            "Train: 10 [ 900/1562 ( 58%)]  Loss:  1.997608 (1.9808)  Time: 0.290s,  110.43/s  (0.289s,  110.63/s)  LR: 8.682e-05  Data: 0.004 (0.005)\n",
            "Train: 10 [ 950/1562 ( 61%)]  Loss:  1.634084 (1.9797)  Time: 0.286s,  111.72/s  (0.289s,  110.66/s)  LR: 8.682e-05  Data: 0.004 (0.005)\n",
            "Train: 10 [1000/1562 ( 64%)]  Loss:  2.148036 (1.9812)  Time: 0.292s,  109.41/s  (0.289s,  110.70/s)  LR: 8.682e-05  Data: 0.010 (0.005)\n",
            "Train: 10 [1050/1562 ( 67%)]  Loss:  2.016852 (1.9839)  Time: 0.286s,  111.82/s  (0.289s,  110.72/s)  LR: 8.682e-05  Data: 0.004 (0.005)\n",
            "Train: 10 [1100/1562 ( 70%)]  Loss:  2.116259 (1.9859)  Time: 0.286s,  111.71/s  (0.289s,  110.75/s)  LR: 8.682e-05  Data: 0.004 (0.005)\n",
            "Train: 10 [1150/1562 ( 74%)]  Loss:  2.210585 (1.9917)  Time: 0.287s,  111.33/s  (0.289s,  110.78/s)  LR: 8.682e-05  Data: 0.004 (0.005)\n",
            "Train: 10 [1200/1562 ( 77%)]  Loss:  1.835240 (1.9968)  Time: 0.286s,  111.74/s  (0.289s,  110.80/s)  LR: 8.682e-05  Data: 0.004 (0.005)\n",
            "Train: 10 [1250/1562 ( 80%)]  Loss:  1.970974 (1.9972)  Time: 0.292s,  109.56/s  (0.289s,  110.82/s)  LR: 8.682e-05  Data: 0.004 (0.005)\n",
            "Train: 10 [1300/1562 ( 83%)]  Loss:  2.079925 (1.9998)  Time: 0.287s,  111.40/s  (0.289s,  110.84/s)  LR: 8.682e-05  Data: 0.005 (0.005)\n",
            "Train: 10 [1350/1562 ( 86%)]  Loss:  2.038357 (2.0002)  Time: 0.286s,  111.71/s  (0.289s,  110.85/s)  LR: 8.682e-05  Data: 0.004 (0.005)\n",
            "Train: 10 [1400/1562 ( 90%)]  Loss:  2.115798 (1.9956)  Time: 0.286s,  111.89/s  (0.289s,  110.87/s)  LR: 8.682e-05  Data: 0.004 (0.005)\n",
            "Train: 10 [1450/1562 ( 93%)]  Loss:  2.049973 (1.9968)  Time: 0.286s,  111.72/s  (0.289s,  110.89/s)  LR: 8.682e-05  Data: 0.004 (0.005)\n",
            "Train: 10 [1500/1562 ( 96%)]  Loss:  2.246094 (1.9985)  Time: 0.286s,  111.80/s  (0.289s,  110.90/s)  LR: 8.682e-05  Data: 0.004 (0.005)\n",
            "Train: 10 [1550/1562 ( 99%)]  Loss:  1.713148 (1.9977)  Time: 0.284s,  112.49/s  (0.288s,  110.92/s)  LR: 8.682e-05  Data: 0.004 (0.005)\n",
            "Train: 10 [1561/1562 (100%)]  Loss:  1.998561 (1.9966)  Time: 0.371s,   86.20/s  (0.289s,  110.91/s)  LR: 8.682e-05  Data: 0.091 (0.005)\n",
            "Test: [   0/312]  Time: 0.925 (0.925)  Loss:  1.5204 (1.5204)  Acc@1: 46.8750 (46.8750)  Acc@5: 96.8750 (96.8750)\n",
            "Test: [  50/312]  Time: 0.087 (0.112)  Loss:  0.8387 (1.0424)  Acc@1: 81.2500 (67.3407)  Acc@5: 96.8750 (96.3235)\n",
            "Test: [ 100/312]  Time: 0.093 (0.103)  Loss:  1.6207 (1.2531)  Acc@1: 43.7500 (57.3948)  Acc@5: 96.8750 (95.5136)\n",
            "Test: [ 150/312]  Time: 0.094 (0.099)  Loss:  2.0120 (1.3951)  Acc@1: 12.5000 (49.7310)  Acc@5: 93.7500 (94.9710)\n",
            "Test: [ 200/312]  Time: 0.088 (0.097)  Loss:  0.9869 (1.4279)  Acc@1: 75.0000 (48.5541)  Acc@5: 100.0000 (94.8072)\n",
            "Test: [ 250/312]  Time: 0.093 (0.096)  Loss:  1.2043 (1.3126)  Acc@1: 65.6250 (54.3825)  Acc@5: 93.7500 (95.1693)\n",
            "Test: [ 300/312]  Time: 0.086 (0.096)  Loss:  0.8151 (1.2800)  Acc@1: 78.1250 (56.3953)  Acc@5: 96.8750 (95.2865)\n",
            "Test: [ 312/312]  Time: 0.142 (0.095)  Loss:  0.8815 (1.2678)  Acc@1: 68.7500 (57.1200)  Acc@5: 100.0000 (95.3400)\n",
            "Test (EMA): [   0/312]  Time: 0.907 (0.907)  Loss:  2.0007 (2.0007)  Acc@1: 43.7500 (43.7500)  Acc@5: 84.3750 (84.3750)\n",
            "Test (EMA): [  50/312]  Time: 0.086 (0.113)  Loss:  2.3143 (2.0380)  Acc@1:  3.1250 (37.9289)  Acc@5: 53.1250 (79.5956)\n",
            "Test (EMA): [ 100/312]  Time: 0.088 (0.103)  Loss:  1.9748 (2.0701)  Acc@1:  3.1250 (20.2042)  Acc@5: 96.8750 (84.1894)\n",
            "Test (EMA): [ 150/312]  Time: 0.093 (0.100)  Loss:  1.8512 (2.0087)  Acc@1: 18.7500 (17.4462)  Acc@5: 100.0000 (88.3071)\n",
            "Test (EMA): [ 200/312]  Time: 0.090 (0.098)  Loss:  1.1487 (2.0024)  Acc@1: 96.8750 (20.3825)  Acc@5: 100.0000 (88.0908)\n",
            "Test (EMA): [ 250/312]  Time: 0.103 (0.097)  Loss:  1.8880 (1.9972)  Acc@1: 50.0000 (23.3317)  Acc@5: 90.6250 (84.3501)\n",
            "Test (EMA): [ 300/312]  Time: 0.086 (0.096)  Loss:  2.2908 (2.0059)  Acc@1:  3.1250 (23.8061)  Acc@5: 75.0000 (83.1914)\n",
            "Test (EMA): [ 312/312]  Time: 0.132 (0.096)  Loss:  2.3796 (2.0201)  Acc@1:  0.0000 (22.9900)  Acc@5: 62.5000 (82.2500)\n",
            "Current checkpoints:\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-10.pth.tar', 22.99)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-9.pth.tar', 21.2)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-8.pth.tar', 19.76)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-7.pth.tar', 18.99)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-6.pth.tar', 18.77)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-5.pth.tar', 18.44)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-4.pth.tar', 18.35)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-3.pth.tar', 17.11)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-2.pth.tar', 11.19)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-0.pth.tar', 10.0)\n",
            "\n",
            "Train: 11 [   0/1562 (  0%)]  Loss:  1.844157 (1.8442)  Time: 1.665s,   19.22/s  (1.665s,   19.22/s)  LR: 8.423e-05  Data: 1.193 (1.193)\n",
            "Train: 11 [  50/1562 (  3%)]  Loss:  1.724482 (2.0337)  Time: 0.288s,  111.24/s  (0.319s,  100.28/s)  LR: 8.423e-05  Data: 0.004 (0.027)\n",
            "Train: 11 [ 100/1562 (  6%)]  Loss:  1.719897 (1.9976)  Time: 0.285s,  112.11/s  (0.303s,  105.46/s)  LR: 8.423e-05  Data: 0.003 (0.016)\n",
            "Train: 11 [ 150/1562 ( 10%)]  Loss:  2.211760 (2.0134)  Time: 0.286s,  111.92/s  (0.298s,  107.22/s)  LR: 8.423e-05  Data: 0.004 (0.012)\n",
            "Train: 11 [ 200/1562 ( 13%)]  Loss:  1.946680 (1.9995)  Time: 0.286s,  111.86/s  (0.296s,  108.29/s)  LR: 8.423e-05  Data: 0.004 (0.010)\n",
            "Train: 11 [ 250/1562 ( 16%)]  Loss:  1.805924 (1.9966)  Time: 0.286s,  111.95/s  (0.294s,  108.88/s)  LR: 8.423e-05  Data: 0.004 (0.009)\n",
            "Train: 11 [ 300/1562 ( 19%)]  Loss:  2.224255 (1.9999)  Time: 0.286s,  111.96/s  (0.293s,  109.32/s)  LR: 8.423e-05  Data: 0.004 (0.008)\n",
            "Train: 11 [ 350/1562 ( 22%)]  Loss:  1.948562 (1.9808)  Time: 0.286s,  111.98/s  (0.292s,  109.63/s)  LR: 8.423e-05  Data: 0.004 (0.007)\n",
            "Train: 11 [ 400/1562 ( 26%)]  Loss:  2.402705 (1.9717)  Time: 0.286s,  111.81/s  (0.291s,  109.84/s)  LR: 8.423e-05  Data: 0.004 (0.007)\n",
            "Train: 11 [ 450/1562 ( 29%)]  Loss:  2.331814 (1.9705)  Time: 0.286s,  111.89/s  (0.291s,  110.00/s)  LR: 8.423e-05  Data: 0.004 (0.006)\n",
            "Train: 11 [ 500/1562 ( 32%)]  Loss:  1.602924 (1.9701)  Time: 0.286s,  111.75/s  (0.291s,  110.13/s)  LR: 8.423e-05  Data: 0.004 (0.006)\n",
            "Train: 11 [ 550/1562 ( 35%)]  Loss:  2.009889 (1.9638)  Time: 0.286s,  111.85/s  (0.290s,  110.25/s)  LR: 8.423e-05  Data: 0.004 (0.006)\n",
            "Train: 11 [ 600/1562 ( 38%)]  Loss:  2.207739 (1.9588)  Time: 0.287s,  111.67/s  (0.290s,  110.34/s)  LR: 8.423e-05  Data: 0.004 (0.006)\n",
            "Train: 11 [ 650/1562 ( 42%)]  Loss:  1.856574 (1.9580)  Time: 0.287s,  111.51/s  (0.290s,  110.42/s)  LR: 8.423e-05  Data: 0.004 (0.006)\n",
            "Train: 11 [ 700/1562 ( 45%)]  Loss:  1.765764 (1.9596)  Time: 0.290s,  110.48/s  (0.290s,  110.49/s)  LR: 8.423e-05  Data: 0.004 (0.005)\n",
            "Train: 11 [ 750/1562 ( 48%)]  Loss:  1.796029 (1.9634)  Time: 0.286s,  111.91/s  (0.289s,  110.55/s)  LR: 8.423e-05  Data: 0.004 (0.005)\n",
            "Train: 11 [ 800/1562 ( 51%)]  Loss:  1.915634 (1.9648)  Time: 0.286s,  111.88/s  (0.289s,  110.61/s)  LR: 8.423e-05  Data: 0.004 (0.005)\n",
            "Train: 11 [ 850/1562 ( 54%)]  Loss:  2.129998 (1.9702)  Time: 0.286s,  111.80/s  (0.289s,  110.65/s)  LR: 8.423e-05  Data: 0.004 (0.005)\n",
            "Train: 11 [ 900/1562 ( 58%)]  Loss:  1.924768 (1.9737)  Time: 0.293s,  109.03/s  (0.289s,  110.68/s)  LR: 8.423e-05  Data: 0.004 (0.005)\n",
            "Train: 11 [ 950/1562 ( 61%)]  Loss:  1.859920 (1.9729)  Time: 0.292s,  109.45/s  (0.289s,  110.71/s)  LR: 8.423e-05  Data: 0.004 (0.005)\n",
            "Train: 11 [1000/1562 ( 64%)]  Loss:  2.082404 (1.9739)  Time: 0.286s,  111.88/s  (0.289s,  110.75/s)  LR: 8.423e-05  Data: 0.004 (0.005)\n",
            "Train: 11 [1050/1562 ( 67%)]  Loss:  1.869092 (1.9775)  Time: 0.289s,  110.70/s  (0.289s,  110.78/s)  LR: 8.423e-05  Data: 0.006 (0.005)\n",
            "Train: 11 [1100/1562 ( 70%)]  Loss:  2.005878 (1.9778)  Time: 0.286s,  111.85/s  (0.289s,  110.81/s)  LR: 8.423e-05  Data: 0.004 (0.005)\n",
            "Train: 11 [1150/1562 ( 74%)]  Loss:  2.113243 (1.9839)  Time: 0.286s,  111.83/s  (0.289s,  110.83/s)  LR: 8.423e-05  Data: 0.004 (0.005)\n",
            "Train: 11 [1200/1562 ( 77%)]  Loss:  1.861627 (1.9892)  Time: 0.296s,  108.16/s  (0.289s,  110.85/s)  LR: 8.423e-05  Data: 0.004 (0.005)\n",
            "Train: 11 [1250/1562 ( 80%)]  Loss:  2.282753 (1.9892)  Time: 0.286s,  111.77/s  (0.289s,  110.87/s)  LR: 8.423e-05  Data: 0.004 (0.005)\n",
            "Train: 11 [1300/1562 ( 83%)]  Loss:  1.977780 (1.9910)  Time: 0.286s,  111.92/s  (0.289s,  110.89/s)  LR: 8.423e-05  Data: 0.004 (0.005)\n",
            "Train: 11 [1350/1562 ( 86%)]  Loss:  2.034064 (1.9922)  Time: 0.287s,  111.42/s  (0.289s,  110.91/s)  LR: 8.423e-05  Data: 0.004 (0.005)\n",
            "Train: 11 [1400/1562 ( 90%)]  Loss:  2.113575 (1.9885)  Time: 0.287s,  111.69/s  (0.288s,  110.93/s)  LR: 8.423e-05  Data: 0.004 (0.005)\n",
            "Train: 11 [1450/1562 ( 93%)]  Loss:  2.166727 (1.9907)  Time: 0.285s,  112.09/s  (0.288s,  110.95/s)  LR: 8.423e-05  Data: 0.004 (0.005)\n",
            "Train: 11 [1500/1562 ( 96%)]  Loss:  2.098966 (1.9917)  Time: 0.313s,  102.13/s  (0.288s,  110.96/s)  LR: 8.423e-05  Data: 0.004 (0.005)\n",
            "Train: 11 [1550/1562 ( 99%)]  Loss:  1.960095 (1.9911)  Time: 0.284s,  112.73/s  (0.288s,  110.98/s)  LR: 8.423e-05  Data: 0.003 (0.005)\n",
            "Train: 11 [1561/1562 (100%)]  Loss:  1.786565 (1.9901)  Time: 0.374s,   85.59/s  (0.288s,  110.97/s)  LR: 8.423e-05  Data: 0.088 (0.005)\n",
            "Test: [   0/312]  Time: 0.942 (0.942)  Loss:  1.0882 (1.0882)  Acc@1: 68.7500 (68.7500)  Acc@5: 96.8750 (96.8750)\n",
            "Test: [  50/312]  Time: 0.096 (0.112)  Loss:  1.0771 (0.9820)  Acc@1: 68.7500 (70.4657)  Acc@5: 100.0000 (98.0392)\n",
            "Test: [ 100/312]  Time: 0.087 (0.102)  Loss:  1.6365 (1.3154)  Acc@1: 34.3750 (54.2389)  Acc@5: 100.0000 (95.5136)\n",
            "Test: [ 150/312]  Time: 0.091 (0.099)  Loss:  1.8568 (1.4017)  Acc@1: 28.1250 (51.4280)  Acc@5: 87.5000 (94.8262)\n",
            "Test: [ 200/312]  Time: 0.093 (0.097)  Loss:  0.9426 (1.4289)  Acc@1: 75.0000 (50.0311)  Acc@5: 100.0000 (94.5429)\n",
            "Test: [ 250/312]  Time: 0.093 (0.096)  Loss:  0.7870 (1.3791)  Acc@1: 75.0000 (52.9756)  Acc@5: 96.8750 (93.6628)\n",
            "Test: [ 300/312]  Time: 0.086 (0.096)  Loss:  0.6527 (1.2996)  Acc@1: 90.6250 (56.6964)  Acc@5: 100.0000 (94.4767)\n",
            "Test: [ 312/312]  Time: 0.130 (0.095)  Loss:  0.9987 (1.2856)  Acc@1: 75.0000 (57.4300)  Acc@5: 93.7500 (94.6400)\n",
            "Test (EMA): [   0/312]  Time: 0.853 (0.853)  Loss:  1.9809 (1.9809)  Acc@1: 40.6250 (40.6250)  Acc@5: 84.3750 (84.3750)\n",
            "Test (EMA): [  50/312]  Time: 0.087 (0.111)  Loss:  2.2546 (1.9889)  Acc@1:  9.3750 (38.7255)  Acc@5: 59.3750 (83.3333)\n",
            "Test (EMA): [ 100/312]  Time: 0.098 (0.102)  Loss:  1.9396 (2.0356)  Acc@1:  3.1250 (21.2562)  Acc@5: 96.8750 (86.6027)\n",
            "Test (EMA): [ 150/312]  Time: 0.099 (0.099)  Loss:  1.8364 (1.9752)  Acc@1: 18.7500 (19.1225)  Acc@5: 96.8750 (89.8593)\n",
            "Test (EMA): [ 200/312]  Time: 0.087 (0.097)  Loss:  1.0873 (1.9689)  Acc@1: 96.8750 (21.7662)  Acc@5: 100.0000 (89.5678)\n",
            "Test (EMA): [ 250/312]  Time: 0.087 (0.096)  Loss:  1.8037 (1.9613)  Acc@1: 56.2500 (24.5393)  Acc@5: 90.6250 (86.0931)\n",
            "Test (EMA): [ 300/312]  Time: 0.086 (0.095)  Loss:  2.1734 (1.9614)  Acc@1: 21.8750 (26.1939)  Acc@5: 84.3750 (85.7247)\n",
            "Test (EMA): [ 312/312]  Time: 0.132 (0.095)  Loss:  2.2919 (1.9741)  Acc@1:  6.2500 (25.4300)  Acc@5: 81.2500 (85.1900)\n",
            "Current checkpoints:\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-11.pth.tar', 25.43)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-10.pth.tar', 22.99)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-9.pth.tar', 21.2)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-8.pth.tar', 19.76)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-7.pth.tar', 18.99)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-6.pth.tar', 18.77)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-5.pth.tar', 18.44)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-4.pth.tar', 18.35)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-3.pth.tar', 17.11)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-2.pth.tar', 11.19)\n",
            "\n",
            "Train: 12 [   0/1562 (  0%)]  Loss:  1.805569 (1.8056)  Time: 1.478s,   21.65/s  (1.478s,   21.65/s)  LR: 8.145e-05  Data: 0.997 (0.997)\n",
            "Train: 12 [  50/1562 (  3%)]  Loss:  1.839442 (2.0552)  Time: 0.286s,  111.84/s  (0.317s,  101.01/s)  LR: 8.145e-05  Data: 0.004 (0.024)\n",
            "Train: 12 [ 100/1562 (  6%)]  Loss:  1.659379 (1.9925)  Time: 0.286s,  111.82/s  (0.303s,  105.78/s)  LR: 8.145e-05  Data: 0.004 (0.014)\n",
            "Train: 12 [ 150/1562 ( 10%)]  Loss:  2.059582 (1.9998)  Time: 0.288s,  111.15/s  (0.298s,  107.50/s)  LR: 8.145e-05  Data: 0.004 (0.011)\n",
            "Train: 12 [ 200/1562 ( 13%)]  Loss:  2.010448 (1.9893)  Time: 0.291s,  110.08/s  (0.295s,  108.38/s)  LR: 8.145e-05  Data: 0.004 (0.009)\n",
            "Train: 12 [ 250/1562 ( 16%)]  Loss:  1.752836 (1.9788)  Time: 0.288s,  111.25/s  (0.294s,  108.99/s)  LR: 8.145e-05  Data: 0.005 (0.008)\n",
            "Train: 12 [ 300/1562 ( 19%)]  Loss:  2.086821 (1.9752)  Time: 0.286s,  111.94/s  (0.293s,  109.37/s)  LR: 8.145e-05  Data: 0.004 (0.007)\n",
            "Train: 12 [ 350/1562 ( 22%)]  Loss:  1.857921 (1.9636)  Time: 0.287s,  111.63/s  (0.292s,  109.65/s)  LR: 8.145e-05  Data: 0.004 (0.007)\n",
            "Train: 12 [ 400/1562 ( 26%)]  Loss:  2.290092 (1.9490)  Time: 0.287s,  111.44/s  (0.291s,  109.83/s)  LR: 8.145e-05  Data: 0.004 (0.006)\n",
            "Train: 12 [ 450/1562 ( 29%)]  Loss:  2.298887 (1.9445)  Time: 0.286s,  111.96/s  (0.291s,  109.95/s)  LR: 8.145e-05  Data: 0.004 (0.006)\n",
            "Train: 12 [ 500/1562 ( 32%)]  Loss:  1.958774 (1.9457)  Time: 0.286s,  111.70/s  (0.291s,  110.07/s)  LR: 8.145e-05  Data: 0.004 (0.006)\n",
            "Train: 12 [ 550/1562 ( 35%)]  Loss:  1.766595 (1.9423)  Time: 0.287s,  111.60/s  (0.290s,  110.20/s)  LR: 8.145e-05  Data: 0.004 (0.006)\n",
            "Train: 12 [ 600/1562 ( 38%)]  Loss:  2.037690 (1.9376)  Time: 0.287s,  111.67/s  (0.290s,  110.31/s)  LR: 8.145e-05  Data: 0.004 (0.006)\n",
            "Train: 12 [ 650/1562 ( 42%)]  Loss:  1.814804 (1.9401)  Time: 0.289s,  110.78/s  (0.290s,  110.36/s)  LR: 8.145e-05  Data: 0.004 (0.005)\n",
            "Train: 12 [ 700/1562 ( 45%)]  Loss:  1.675337 (1.9407)  Time: 0.287s,  111.54/s  (0.290s,  110.44/s)  LR: 8.145e-05  Data: 0.004 (0.005)\n",
            "Train: 12 [ 750/1562 ( 48%)]  Loss:  1.981994 (1.9444)  Time: 0.288s,  111.28/s  (0.290s,  110.49/s)  LR: 8.145e-05  Data: 0.004 (0.005)\n",
            "Train: 12 [ 800/1562 ( 51%)]  Loss:  1.767271 (1.9468)  Time: 0.286s,  111.86/s  (0.290s,  110.53/s)  LR: 8.145e-05  Data: 0.004 (0.005)\n",
            "Train: 12 [ 850/1562 ( 54%)]  Loss:  2.096574 (1.9527)  Time: 0.286s,  111.92/s  (0.289s,  110.57/s)  LR: 8.145e-05  Data: 0.004 (0.005)\n",
            "Train: 12 [ 900/1562 ( 58%)]  Loss:  1.909526 (1.9560)  Time: 0.287s,  111.49/s  (0.289s,  110.61/s)  LR: 8.145e-05  Data: 0.004 (0.005)\n",
            "Train: 12 [ 950/1562 ( 61%)]  Loss:  1.740355 (1.9557)  Time: 0.286s,  111.72/s  (0.289s,  110.65/s)  LR: 8.145e-05  Data: 0.004 (0.005)\n",
            "Train: 12 [1000/1562 ( 64%)]  Loss:  1.949990 (1.9578)  Time: 0.286s,  111.98/s  (0.289s,  110.69/s)  LR: 8.145e-05  Data: 0.004 (0.005)\n",
            "Train: 12 [1050/1562 ( 67%)]  Loss:  1.692977 (1.9623)  Time: 0.286s,  111.84/s  (0.289s,  110.71/s)  LR: 8.145e-05  Data: 0.004 (0.005)\n",
            "Train: 12 [1100/1562 ( 70%)]  Loss:  2.218306 (1.9638)  Time: 0.287s,  111.57/s  (0.289s,  110.73/s)  LR: 8.145e-05  Data: 0.004 (0.005)\n",
            "Train: 12 [1150/1562 ( 74%)]  Loss:  1.991651 (1.9704)  Time: 0.286s,  111.84/s  (0.289s,  110.77/s)  LR: 8.145e-05  Data: 0.004 (0.005)\n",
            "Train: 12 [1200/1562 ( 77%)]  Loss:  1.831405 (1.9749)  Time: 0.289s,  110.66/s  (0.289s,  110.79/s)  LR: 8.145e-05  Data: 0.004 (0.005)\n",
            "Train: 12 [1250/1562 ( 80%)]  Loss:  2.065051 (1.9757)  Time: 0.288s,  111.14/s  (0.289s,  110.81/s)  LR: 8.145e-05  Data: 0.004 (0.005)\n",
            "Train: 12 [1300/1562 ( 83%)]  Loss:  1.767956 (1.9780)  Time: 0.293s,  109.10/s  (0.289s,  110.82/s)  LR: 8.145e-05  Data: 0.004 (0.005)\n",
            "Train: 12 [1350/1562 ( 86%)]  Loss:  2.063934 (1.9791)  Time: 0.292s,  109.65/s  (0.289s,  110.84/s)  LR: 8.145e-05  Data: 0.004 (0.005)\n",
            "Train: 12 [1400/1562 ( 90%)]  Loss:  2.091302 (1.9746)  Time: 0.294s,  108.75/s  (0.289s,  110.86/s)  LR: 8.145e-05  Data: 0.004 (0.005)\n",
            "Train: 12 [1450/1562 ( 93%)]  Loss:  2.280712 (1.9767)  Time: 0.286s,  111.75/s  (0.289s,  110.87/s)  LR: 8.145e-05  Data: 0.004 (0.005)\n",
            "Train: 12 [1500/1562 ( 96%)]  Loss:  2.222143 (1.9782)  Time: 0.286s,  111.71/s  (0.289s,  110.89/s)  LR: 8.145e-05  Data: 0.004 (0.005)\n",
            "Train: 12 [1550/1562 ( 99%)]  Loss:  1.690062 (1.9775)  Time: 0.284s,  112.68/s  (0.289s,  110.90/s)  LR: 8.145e-05  Data: 0.003 (0.005)\n",
            "Train: 12 [1561/1562 (100%)]  Loss:  1.978942 (1.9759)  Time: 0.369s,   86.75/s  (0.289s,  110.89/s)  LR: 8.145e-05  Data: 0.089 (0.005)\n",
            "Test: [   0/312]  Time: 0.891 (0.891)  Loss:  1.3210 (1.3210)  Acc@1: 53.1250 (53.1250)  Acc@5: 96.8750 (96.8750)\n",
            "Test: [  50/312]  Time: 0.093 (0.112)  Loss:  1.1037 (1.1553)  Acc@1: 62.5000 (58.1495)  Acc@5: 93.7500 (95.0980)\n",
            "Test: [ 100/312]  Time: 0.093 (0.102)  Loss:  1.5427 (1.5141)  Acc@1: 43.7500 (43.2240)  Acc@5: 96.8750 (91.2129)\n",
            "Test: [ 150/312]  Time: 0.087 (0.099)  Loss:  1.3992 (1.4650)  Acc@1: 40.6250 (46.1300)  Acc@5: 100.0000 (92.7773)\n",
            "Test: [ 200/312]  Time: 0.087 (0.097)  Loss:  0.8572 (1.4372)  Acc@1: 78.1250 (48.6318)  Acc@5: 100.0000 (93.1748)\n",
            "Test: [ 250/312]  Time: 0.102 (0.096)  Loss:  0.8403 (1.3389)  Acc@1: 84.3750 (53.1997)  Acc@5: 96.8750 (93.8372)\n",
            "Test: [ 300/312]  Time: 0.086 (0.096)  Loss:  0.4502 (1.2463)  Acc@1: 90.6250 (57.5374)  Acc@5: 100.0000 (94.5702)\n",
            "Test: [ 312/312]  Time: 0.130 (0.096)  Loss:  0.5133 (1.2227)  Acc@1: 87.5000 (58.6300)  Acc@5: 100.0000 (94.7100)\n",
            "Test (EMA): [   0/312]  Time: 0.759 (0.759)  Loss:  1.9547 (1.9547)  Acc@1: 40.6250 (40.6250)  Acc@5: 81.2500 (81.2500)\n",
            "Test (EMA): [  50/312]  Time: 0.102 (0.112)  Loss:  2.1888 (1.9337)  Acc@1: 18.7500 (40.6863)  Acc@5: 65.6250 (86.0907)\n",
            "Test (EMA): [ 100/312]  Time: 0.087 (0.102)  Loss:  1.9069 (1.9938)  Acc@1:  3.1250 (23.7933)  Acc@5: 96.8750 (88.2426)\n",
            "Test (EMA): [ 150/312]  Time: 0.087 (0.099)  Loss:  1.8128 (1.9354)  Acc@1: 21.8750 (22.1440)  Acc@5: 96.8750 (90.9975)\n",
            "Test (EMA): [ 200/312]  Time: 0.096 (0.097)  Loss:  1.0415 (1.9305)  Acc@1: 96.8750 (24.0827)  Acc@5: 100.0000 (90.7027)\n",
            "Test (EMA): [ 250/312]  Time: 0.094 (0.096)  Loss:  1.7306 (1.9213)  Acc@1: 56.2500 (26.4816)  Acc@5: 90.6250 (87.3630)\n",
            "Test (EMA): [ 300/312]  Time: 0.086 (0.096)  Loss:  2.0507 (1.9145)  Acc@1: 34.3750 (28.8310)  Acc@5: 84.3750 (87.4792)\n",
            "Test (EMA): [ 312/312]  Time: 0.131 (0.095)  Loss:  2.1995 (1.9254)  Acc@1:  6.2500 (28.3200)  Acc@5: 87.5000 (87.1900)\n",
            "Current checkpoints:\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-12.pth.tar', 28.32)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-11.pth.tar', 25.43)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-10.pth.tar', 22.99)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-9.pth.tar', 21.2)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-8.pth.tar', 19.76)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-7.pth.tar', 18.99)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-6.pth.tar', 18.77)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-5.pth.tar', 18.44)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-4.pth.tar', 18.35)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-3.pth.tar', 17.11)\n",
            "\n",
            "Train: 13 [   0/1562 (  0%)]  Loss:  1.666483 (1.6665)  Time: 1.739s,   18.40/s  (1.739s,   18.40/s)  LR: 7.851e-05  Data: 1.237 (1.237)\n",
            "Train: 13 [  50/1562 (  3%)]  Loss:  1.847551 (1.9931)  Time: 0.289s,  110.69/s  (0.318s,  100.54/s)  LR: 7.851e-05  Data: 0.004 (0.028)\n",
            "Train: 13 [ 100/1562 (  6%)]  Loss:  1.669289 (1.9571)  Time: 0.288s,  111.23/s  (0.303s,  105.55/s)  LR: 7.851e-05  Data: 0.004 (0.016)\n",
            "Train: 13 [ 150/1562 ( 10%)]  Loss:  1.923754 (1.9683)  Time: 0.286s,  111.95/s  (0.298s,  107.33/s)  LR: 7.851e-05  Data: 0.004 (0.012)\n",
            "Train: 13 [ 200/1562 ( 13%)]  Loss:  2.153874 (1.9589)  Time: 0.286s,  111.71/s  (0.295s,  108.29/s)  LR: 7.851e-05  Data: 0.004 (0.010)\n",
            "Train: 13 [ 250/1562 ( 16%)]  Loss:  1.806094 (1.9553)  Time: 0.286s,  111.92/s  (0.294s,  108.93/s)  LR: 7.851e-05  Data: 0.004 (0.009)\n",
            "Train: 13 [ 300/1562 ( 19%)]  Loss:  2.147068 (1.9664)  Time: 0.286s,  111.74/s  (0.293s,  109.35/s)  LR: 7.851e-05  Data: 0.004 (0.008)\n",
            "Train: 13 [ 350/1562 ( 22%)]  Loss:  1.870277 (1.9527)  Time: 0.288s,  111.12/s  (0.292s,  109.58/s)  LR: 7.851e-05  Data: 0.004 (0.007)\n",
            "Train: 13 [ 400/1562 ( 26%)]  Loss:  2.198207 (1.9431)  Time: 0.288s,  111.24/s  (0.292s,  109.78/s)  LR: 7.851e-05  Data: 0.004 (0.007)\n",
            "Train: 13 [ 450/1562 ( 29%)]  Loss:  1.939111 (1.9425)  Time: 0.286s,  111.84/s  (0.291s,  109.95/s)  LR: 7.851e-05  Data: 0.004 (0.006)\n",
            "Train: 13 [ 500/1562 ( 32%)]  Loss:  1.711088 (1.9429)  Time: 0.286s,  111.85/s  (0.291s,  110.10/s)  LR: 7.851e-05  Data: 0.004 (0.006)\n",
            "Train: 13 [ 550/1562 ( 35%)]  Loss:  1.914664 (1.9395)  Time: 0.286s,  111.81/s  (0.290s,  110.23/s)  LR: 7.851e-05  Data: 0.004 (0.006)\n",
            "Train: 13 [ 600/1562 ( 38%)]  Loss:  2.030990 (1.9353)  Time: 0.286s,  111.95/s  (0.290s,  110.33/s)  LR: 7.851e-05  Data: 0.004 (0.006)\n",
            "Train: 13 [ 650/1562 ( 42%)]  Loss:  1.626851 (1.9352)  Time: 0.287s,  111.48/s  (0.290s,  110.41/s)  LR: 7.851e-05  Data: 0.004 (0.006)\n",
            "Train: 13 [ 700/1562 ( 45%)]  Loss:  1.785698 (1.9362)  Time: 0.286s,  111.90/s  (0.290s,  110.48/s)  LR: 7.851e-05  Data: 0.004 (0.006)\n",
            "Train: 13 [ 750/1562 ( 48%)]  Loss:  1.798390 (1.9429)  Time: 0.289s,  110.71/s  (0.290s,  110.53/s)  LR: 7.851e-05  Data: 0.004 (0.005)\n",
            "Train: 13 [ 800/1562 ( 51%)]  Loss:  1.767804 (1.9459)  Time: 0.292s,  109.55/s  (0.289s,  110.55/s)  LR: 7.851e-05  Data: 0.004 (0.005)\n",
            "Train: 13 [ 850/1562 ( 54%)]  Loss:  2.035211 (1.9510)  Time: 0.291s,  110.13/s  (0.289s,  110.58/s)  LR: 7.851e-05  Data: 0.004 (0.005)\n",
            "Train: 13 [ 900/1562 ( 58%)]  Loss:  1.830577 (1.9543)  Time: 0.286s,  111.86/s  (0.289s,  110.63/s)  LR: 7.851e-05  Data: 0.004 (0.005)\n",
            "Train: 13 [ 950/1562 ( 61%)]  Loss:  1.810577 (1.9535)  Time: 0.286s,  111.70/s  (0.289s,  110.66/s)  LR: 7.851e-05  Data: 0.004 (0.005)\n",
            "Train: 13 [1000/1562 ( 64%)]  Loss:  2.105523 (1.9558)  Time: 0.286s,  111.84/s  (0.289s,  110.70/s)  LR: 7.851e-05  Data: 0.004 (0.005)\n",
            "Train: 13 [1050/1562 ( 67%)]  Loss:  1.874432 (1.9603)  Time: 0.286s,  111.94/s  (0.289s,  110.73/s)  LR: 7.851e-05  Data: 0.004 (0.005)\n",
            "Train: 13 [1100/1562 ( 70%)]  Loss:  2.180223 (1.9619)  Time: 0.293s,  109.29/s  (0.289s,  110.74/s)  LR: 7.851e-05  Data: 0.004 (0.005)\n",
            "Train: 13 [1150/1562 ( 74%)]  Loss:  2.034879 (1.9693)  Time: 0.287s,  111.45/s  (0.289s,  110.78/s)  LR: 7.851e-05  Data: 0.004 (0.005)\n",
            "Train: 13 [1200/1562 ( 77%)]  Loss:  1.866227 (1.9739)  Time: 0.286s,  111.75/s  (0.289s,  110.79/s)  LR: 7.851e-05  Data: 0.004 (0.005)\n",
            "Train: 13 [1250/1562 ( 80%)]  Loss:  1.988513 (1.9750)  Time: 0.287s,  111.37/s  (0.289s,  110.82/s)  LR: 7.851e-05  Data: 0.004 (0.005)\n",
            "Train: 13 [1300/1562 ( 83%)]  Loss:  1.867046 (1.9769)  Time: 0.286s,  111.91/s  (0.289s,  110.84/s)  LR: 7.851e-05  Data: 0.004 (0.005)\n",
            "Train: 13 [1350/1562 ( 86%)]  Loss:  1.976199 (1.9780)  Time: 0.286s,  111.94/s  (0.289s,  110.87/s)  LR: 7.851e-05  Data: 0.004 (0.005)\n",
            "Train: 13 [1400/1562 ( 90%)]  Loss:  2.002975 (1.9729)  Time: 0.286s,  111.81/s  (0.289s,  110.88/s)  LR: 7.851e-05  Data: 0.004 (0.005)\n",
            "Train: 13 [1450/1562 ( 93%)]  Loss:  2.182394 (1.9757)  Time: 0.286s,  111.72/s  (0.289s,  110.89/s)  LR: 7.851e-05  Data: 0.004 (0.005)\n",
            "Train: 13 [1500/1562 ( 96%)]  Loss:  2.249339 (1.9769)  Time: 0.287s,  111.33/s  (0.289s,  110.92/s)  LR: 7.851e-05  Data: 0.004 (0.005)\n",
            "Train: 13 [1550/1562 ( 99%)]  Loss:  1.738387 (1.9751)  Time: 0.283s,  113.01/s  (0.288s,  110.93/s)  LR: 7.851e-05  Data: 0.003 (0.005)\n",
            "Train: 13 [1561/1562 (100%)]  Loss:  1.963631 (1.9741)  Time: 0.367s,   87.09/s  (0.288s,  110.92/s)  LR: 7.851e-05  Data: 0.087 (0.005)\n",
            "Test: [   0/312]  Time: 0.857 (0.857)  Loss:  1.3928 (1.3928)  Acc@1: 53.1250 (53.1250)  Acc@5: 93.7500 (93.7500)\n",
            "Test: [  50/312]  Time: 0.097 (0.112)  Loss:  0.6532 (0.9634)  Acc@1: 84.3750 (70.8946)  Acc@5: 96.8750 (95.8946)\n",
            "Test: [ 100/312]  Time: 0.086 (0.102)  Loss:  1.5618 (1.2281)  Acc@1: 46.8750 (58.1374)  Acc@5: 100.0000 (95.2042)\n",
            "Test: [ 150/312]  Time: 0.089 (0.099)  Loss:  1.5109 (1.2956)  Acc@1: 25.0000 (55.5050)  Acc@5: 96.8750 (95.3022)\n",
            "Test: [ 200/312]  Time: 0.090 (0.097)  Loss:  1.0891 (1.3423)  Acc@1: 75.0000 (53.4359)  Acc@5: 93.7500 (95.0404)\n",
            "Test: [ 250/312]  Time: 0.087 (0.096)  Loss:  0.8211 (1.2623)  Acc@1: 78.1250 (57.4203)  Acc@5: 100.0000 (95.2067)\n",
            "Test: [ 300/312]  Time: 0.086 (0.096)  Loss:  0.8836 (1.2326)  Acc@1: 78.1250 (58.7521)  Acc@5: 93.7500 (95.3800)\n",
            "Test: [ 312/312]  Time: 0.130 (0.095)  Loss:  1.3604 (1.2316)  Acc@1: 37.5000 (58.6700)  Acc@5: 100.0000 (95.3400)\n",
            "Test (EMA): [   0/312]  Time: 0.942 (0.942)  Loss:  1.9135 (1.9135)  Acc@1: 40.6250 (40.6250)  Acc@5: 84.3750 (84.3750)\n",
            "Test (EMA): [  50/312]  Time: 0.094 (0.112)  Loss:  2.1140 (1.8683)  Acc@1: 34.3750 (43.1373)  Acc@5: 75.0000 (88.6029)\n",
            "Test (EMA): [ 100/312]  Time: 0.100 (0.102)  Loss:  1.8780 (1.9443)  Acc@1:  6.2500 (26.4851)  Acc@5: 96.8750 (90.2228)\n",
            "Test (EMA): [ 150/312]  Time: 0.087 (0.099)  Loss:  1.7904 (1.8916)  Acc@1: 21.8750 (25.3104)  Acc@5: 96.8750 (92.3013)\n",
            "Test (EMA): [ 200/312]  Time: 0.088 (0.098)  Loss:  1.0092 (1.8896)  Acc@1: 96.8750 (26.5703)  Acc@5: 100.0000 (91.8999)\n",
            "Test (EMA): [ 250/312]  Time: 0.101 (0.097)  Loss:  1.6523 (1.8778)  Acc@1: 62.5000 (28.7475)  Acc@5: 90.6250 (88.7326)\n",
            "Test (EMA): [ 300/312]  Time: 0.086 (0.096)  Loss:  1.9363 (1.8647)  Acc@1: 40.6250 (31.8210)  Acc@5: 93.7500 (89.0158)\n",
            "Test (EMA): [ 312/312]  Time: 0.130 (0.096)  Loss:  2.1146 (1.8742)  Acc@1: 12.5000 (31.4800)  Acc@5: 87.5000 (88.8200)\n",
            "Current checkpoints:\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-13.pth.tar', 31.48)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-12.pth.tar', 28.32)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-11.pth.tar', 25.43)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-10.pth.tar', 22.99)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-9.pth.tar', 21.2)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-8.pth.tar', 19.76)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-7.pth.tar', 18.99)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-6.pth.tar', 18.77)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-5.pth.tar', 18.44)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-4.pth.tar', 18.35)\n",
            "\n",
            "Train: 14 [   0/1562 (  0%)]  Loss:  1.950386 (1.9504)  Time: 1.628s,   19.66/s  (1.628s,   19.66/s)  LR: 7.543e-05  Data: 1.182 (1.182)\n",
            "Train: 14 [  50/1562 (  3%)]  Loss:  1.736878 (1.9910)  Time: 0.287s,  111.31/s  (0.317s,  100.91/s)  LR: 7.543e-05  Data: 0.005 (0.027)\n",
            "Train: 14 [ 100/1562 (  6%)]  Loss:  1.701217 (1.9724)  Time: 0.286s,  111.88/s  (0.303s,  105.64/s)  LR: 7.543e-05  Data: 0.004 (0.016)\n",
            "Train: 14 [ 150/1562 ( 10%)]  Loss:  2.072703 (1.9878)  Time: 0.289s,  110.79/s  (0.298s,  107.52/s)  LR: 7.543e-05  Data: 0.004 (0.012)\n",
            "Train: 14 [ 200/1562 ( 13%)]  Loss:  2.232948 (1.9712)  Time: 0.286s,  112.01/s  (0.295s,  108.48/s)  LR: 7.543e-05  Data: 0.004 (0.010)\n",
            "Train: 14 [ 250/1562 ( 16%)]  Loss:  1.860502 (1.9657)  Time: 0.287s,  111.36/s  (0.293s,  109.06/s)  LR: 7.543e-05  Data: 0.004 (0.009)\n",
            "Train: 14 [ 300/1562 ( 19%)]  Loss:  2.029592 (1.9635)  Time: 0.294s,  109.00/s  (0.292s,  109.41/s)  LR: 7.543e-05  Data: 0.004 (0.008)\n",
            "Train: 14 [ 350/1562 ( 22%)]  Loss:  2.030078 (1.9423)  Time: 0.287s,  111.64/s  (0.292s,  109.72/s)  LR: 7.543e-05  Data: 0.004 (0.007)\n",
            "Train: 14 [ 400/1562 ( 26%)]  Loss:  1.963314 (1.9312)  Time: 0.296s,  108.19/s  (0.291s,  109.91/s)  LR: 7.543e-05  Data: 0.004 (0.007)\n",
            "Train: 14 [ 450/1562 ( 29%)]  Loss:  1.970218 (1.9280)  Time: 0.286s,  111.74/s  (0.291s,  110.06/s)  LR: 7.543e-05  Data: 0.004 (0.006)\n",
            "Train: 14 [ 500/1562 ( 32%)]  Loss:  1.679399 (1.9283)  Time: 0.286s,  111.96/s  (0.290s,  110.20/s)  LR: 7.543e-05  Data: 0.004 (0.006)\n",
            "Train: 14 [ 550/1562 ( 35%)]  Loss:  1.704572 (1.9221)  Time: 0.286s,  111.73/s  (0.290s,  110.30/s)  LR: 7.543e-05  Data: 0.004 (0.006)\n",
            "Train: 14 [ 600/1562 ( 38%)]  Loss:  2.133447 (1.9184)  Time: 0.286s,  111.87/s  (0.290s,  110.38/s)  LR: 7.543e-05  Data: 0.004 (0.006)\n",
            "Train: 14 [ 650/1562 ( 42%)]  Loss:  1.766774 (1.9185)  Time: 0.286s,  111.84/s  (0.290s,  110.44/s)  LR: 7.543e-05  Data: 0.004 (0.006)\n",
            "Train: 14 [ 700/1562 ( 45%)]  Loss:  1.543805 (1.9212)  Time: 0.289s,  110.66/s  (0.290s,  110.48/s)  LR: 7.543e-05  Data: 0.004 (0.006)\n",
            "Train: 14 [ 750/1562 ( 48%)]  Loss:  1.832392 (1.9274)  Time: 0.286s,  111.90/s  (0.289s,  110.55/s)  LR: 7.543e-05  Data: 0.004 (0.005)\n",
            "Train: 14 [ 800/1562 ( 51%)]  Loss:  1.833908 (1.9296)  Time: 0.294s,  108.98/s  (0.289s,  110.59/s)  LR: 7.543e-05  Data: 0.004 (0.005)\n",
            "Train: 14 [ 850/1562 ( 54%)]  Loss:  2.246302 (1.9361)  Time: 0.286s,  111.77/s  (0.289s,  110.63/s)  LR: 7.543e-05  Data: 0.004 (0.005)\n",
            "Train: 14 [ 900/1562 ( 58%)]  Loss:  1.686648 (1.9394)  Time: 0.287s,  111.38/s  (0.289s,  110.67/s)  LR: 7.543e-05  Data: 0.004 (0.005)\n",
            "Train: 14 [ 950/1562 ( 61%)]  Loss:  1.861167 (1.9390)  Time: 0.286s,  111.87/s  (0.289s,  110.71/s)  LR: 7.543e-05  Data: 0.004 (0.005)\n",
            "Train: 14 [1000/1562 ( 64%)]  Loss:  1.995758 (1.9411)  Time: 0.286s,  111.76/s  (0.289s,  110.74/s)  LR: 7.543e-05  Data: 0.004 (0.005)\n",
            "Train: 14 [1050/1562 ( 67%)]  Loss:  1.756538 (1.9445)  Time: 0.286s,  111.90/s  (0.289s,  110.78/s)  LR: 7.543e-05  Data: 0.004 (0.005)\n",
            "Train: 14 [1100/1562 ( 70%)]  Loss:  1.991433 (1.9468)  Time: 0.289s,  110.59/s  (0.289s,  110.81/s)  LR: 7.543e-05  Data: 0.004 (0.005)\n",
            "Train: 14 [1150/1562 ( 74%)]  Loss:  2.275655 (1.9540)  Time: 0.286s,  111.98/s  (0.289s,  110.83/s)  LR: 7.543e-05  Data: 0.004 (0.005)\n",
            "Train: 14 [1200/1562 ( 77%)]  Loss:  2.004505 (1.9591)  Time: 0.287s,  111.32/s  (0.289s,  110.85/s)  LR: 7.543e-05  Data: 0.004 (0.005)\n",
            "Train: 14 [1250/1562 ( 80%)]  Loss:  2.086632 (1.9583)  Time: 0.288s,  111.25/s  (0.289s,  110.87/s)  LR: 7.543e-05  Data: 0.005 (0.005)\n",
            "Train: 14 [1300/1562 ( 83%)]  Loss:  2.041079 (1.9610)  Time: 0.286s,  111.76/s  (0.289s,  110.88/s)  LR: 7.543e-05  Data: 0.004 (0.005)\n",
            "Train: 14 [1350/1562 ( 86%)]  Loss:  2.052433 (1.9629)  Time: 0.290s,  110.51/s  (0.289s,  110.89/s)  LR: 7.543e-05  Data: 0.004 (0.005)\n",
            "Train: 14 [1400/1562 ( 90%)]  Loss:  2.188713 (1.9602)  Time: 0.287s,  111.63/s  (0.289s,  110.89/s)  LR: 7.543e-05  Data: 0.004 (0.005)\n",
            "Train: 14 [1450/1562 ( 93%)]  Loss:  2.067589 (1.9617)  Time: 0.290s,  110.44/s  (0.289s,  110.90/s)  LR: 7.543e-05  Data: 0.004 (0.005)\n",
            "Train: 14 [1500/1562 ( 96%)]  Loss:  2.127609 (1.9632)  Time: 0.287s,  111.53/s  (0.289s,  110.91/s)  LR: 7.543e-05  Data: 0.004 (0.005)\n",
            "Train: 14 [1550/1562 ( 99%)]  Loss:  1.516792 (1.9621)  Time: 0.286s,  111.71/s  (0.288s,  110.92/s)  LR: 7.543e-05  Data: 0.003 (0.005)\n",
            "Train: 14 [1561/1562 (100%)]  Loss:  2.170821 (1.9609)  Time: 0.377s,   84.81/s  (0.289s,  110.90/s)  LR: 7.543e-05  Data: 0.089 (0.005)\n",
            "Test: [   0/312]  Time: 0.918 (0.918)  Loss:  1.5521 (1.5521)  Acc@1: 43.7500 (43.7500)  Acc@5: 90.6250 (90.6250)\n",
            "Test: [  50/312]  Time: 0.086 (0.112)  Loss:  0.5494 (0.9735)  Acc@1: 87.5000 (69.0564)  Acc@5: 96.8750 (96.3235)\n",
            "Test: [ 100/312]  Time: 0.087 (0.102)  Loss:  1.6595 (1.1807)  Acc@1: 21.8750 (58.3230)  Acc@5: 96.8750 (96.0705)\n",
            "Test: [ 150/312]  Time: 0.094 (0.099)  Loss:  1.9707 (1.3628)  Acc@1: 18.7500 (48.5720)  Acc@5: 93.7500 (94.8675)\n",
            "Test: [ 200/312]  Time: 0.087 (0.097)  Loss:  0.8154 (1.3372)  Acc@1: 75.0000 (51.6636)  Acc@5: 100.0000 (95.2581)\n",
            "Test: [ 250/312]  Time: 0.102 (0.097)  Loss:  0.8525 (1.2251)  Acc@1: 81.2500 (57.4950)  Acc@5: 100.0000 (95.6922)\n",
            "Test: [ 300/312]  Time: 0.086 (0.096)  Loss:  0.7741 (1.1835)  Acc@1: 78.1250 (59.6242)  Acc@5: 93.7500 (95.8160)\n",
            "Test: [ 312/312]  Time: 0.132 (0.096)  Loss:  0.8428 (1.1760)  Acc@1: 75.0000 (59.8300)  Acc@5: 100.0000 (95.8400)\n",
            "Test (EMA): [   0/312]  Time: 0.894 (0.894)  Loss:  1.8748 (1.8748)  Acc@1: 46.8750 (46.8750)  Acc@5: 84.3750 (84.3750)\n",
            "Test (EMA): [  50/312]  Time: 0.087 (0.113)  Loss:  2.0388 (1.8059)  Acc@1: 34.3750 (46.6912)  Acc@5: 81.2500 (90.3186)\n",
            "Test (EMA): [ 100/312]  Time: 0.102 (0.103)  Loss:  1.8408 (1.8959)  Acc@1:  9.3750 (29.5792)  Acc@5: 96.8750 (91.4604)\n",
            "Test (EMA): [ 150/312]  Time: 0.093 (0.100)  Loss:  1.7721 (1.8481)  Acc@1: 21.8750 (28.5803)  Acc@5: 96.8750 (93.0877)\n",
            "Test (EMA): [ 200/312]  Time: 0.108 (0.098)  Loss:  0.9846 (1.8480)  Acc@1: 96.8750 (29.1045)  Acc@5: 100.0000 (92.6772)\n",
            "Test (EMA): [ 250/312]  Time: 0.093 (0.097)  Loss:  1.5807 (1.8336)  Acc@1: 65.6250 (31.3123)  Acc@5: 90.6250 (89.7410)\n",
            "Test (EMA): [ 300/312]  Time: 0.086 (0.096)  Loss:  1.8122 (1.8145)  Acc@1: 53.1250 (34.8733)  Acc@5: 96.8750 (90.1474)\n",
            "Test (EMA): [ 312/312]  Time: 0.128 (0.096)  Loss:  2.0170 (1.8221)  Acc@1: 25.0000 (34.7700)  Acc@5: 87.5000 (90.0600)\n",
            "Current checkpoints:\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-14.pth.tar', 34.77)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-13.pth.tar', 31.48)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-12.pth.tar', 28.32)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-11.pth.tar', 25.43)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-10.pth.tar', 22.99)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-9.pth.tar', 21.2)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-8.pth.tar', 19.76)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-7.pth.tar', 18.99)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-6.pth.tar', 18.77)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-5.pth.tar', 18.44)\n",
            "\n",
            "Train: 15 [   0/1562 (  0%)]  Loss:  1.745577 (1.7456)  Time: 1.693s,   18.90/s  (1.693s,   18.90/s)  LR: 7.222e-05  Data: 1.200 (1.200)\n",
            "Train: 15 [  50/1562 (  3%)]  Loss:  1.852936 (2.0000)  Time: 0.286s,  111.71/s  (0.318s,  100.57/s)  LR: 7.222e-05  Data: 0.004 (0.028)\n",
            "Train: 15 [ 100/1562 (  6%)]  Loss:  1.678937 (1.9642)  Time: 0.286s,  111.96/s  (0.303s,  105.63/s)  LR: 7.222e-05  Data: 0.004 (0.016)\n",
            "Train: 15 [ 150/1562 ( 10%)]  Loss:  2.070575 (1.9691)  Time: 0.287s,  111.62/s  (0.298s,  107.41/s)  LR: 7.222e-05  Data: 0.004 (0.012)\n",
            "Train: 15 [ 200/1562 ( 13%)]  Loss:  2.103664 (1.9541)  Time: 0.286s,  111.73/s  (0.295s,  108.36/s)  LR: 7.222e-05  Data: 0.004 (0.010)\n",
            "Train: 15 [ 250/1562 ( 16%)]  Loss:  1.898189 (1.9487)  Time: 0.286s,  111.72/s  (0.294s,  108.92/s)  LR: 7.222e-05  Data: 0.004 (0.009)\n",
            "Train: 15 [ 300/1562 ( 19%)]  Loss:  2.138117 (1.9535)  Time: 0.289s,  110.60/s  (0.293s,  109.33/s)  LR: 7.222e-05  Data: 0.004 (0.008)\n",
            "Train: 15 [ 350/1562 ( 22%)]  Loss:  1.861945 (1.9384)  Time: 0.286s,  111.79/s  (0.292s,  109.60/s)  LR: 7.222e-05  Data: 0.004 (0.007)\n",
            "Train: 15 [ 400/1562 ( 26%)]  Loss:  1.956492 (1.9260)  Time: 0.286s,  111.72/s  (0.291s,  109.81/s)  LR: 7.222e-05  Data: 0.004 (0.007)\n",
            "Train: 15 [ 450/1562 ( 29%)]  Loss:  2.071340 (1.9233)  Time: 0.286s,  111.90/s  (0.291s,  109.97/s)  LR: 7.222e-05  Data: 0.004 (0.007)\n",
            "Train: 15 [ 500/1562 ( 32%)]  Loss:  1.696992 (1.9226)  Time: 0.288s,  111.23/s  (0.291s,  110.08/s)  LR: 7.222e-05  Data: 0.004 (0.006)\n",
            "Train: 15 [ 550/1562 ( 35%)]  Loss:  1.602947 (1.9191)  Time: 0.289s,  110.54/s  (0.290s,  110.18/s)  LR: 7.222e-05  Data: 0.004 (0.006)\n",
            "Train: 15 [ 600/1562 ( 38%)]  Loss:  2.121361 (1.9137)  Time: 0.291s,  110.05/s  (0.290s,  110.27/s)  LR: 7.222e-05  Data: 0.004 (0.006)\n",
            "Train: 15 [ 650/1562 ( 42%)]  Loss:  1.935771 (1.9145)  Time: 0.287s,  111.69/s  (0.290s,  110.36/s)  LR: 7.222e-05  Data: 0.004 (0.006)\n",
            "Train: 15 [ 700/1562 ( 45%)]  Loss:  1.667458 (1.9159)  Time: 0.286s,  111.73/s  (0.290s,  110.41/s)  LR: 7.222e-05  Data: 0.004 (0.006)\n",
            "Train: 15 [ 750/1562 ( 48%)]  Loss:  1.849748 (1.9195)  Time: 0.286s,  111.83/s  (0.290s,  110.45/s)  LR: 7.222e-05  Data: 0.004 (0.006)\n",
            "Train: 15 [ 800/1562 ( 51%)]  Loss:  1.703112 (1.9220)  Time: 0.286s,  111.85/s  (0.290s,  110.49/s)  LR: 7.222e-05  Data: 0.004 (0.005)\n",
            "Train: 15 [ 850/1562 ( 54%)]  Loss:  2.098029 (1.9278)  Time: 0.286s,  111.78/s  (0.289s,  110.54/s)  LR: 7.222e-05  Data: 0.004 (0.005)\n",
            "Train: 15 [ 900/1562 ( 58%)]  Loss:  1.971044 (1.9314)  Time: 0.287s,  111.59/s  (0.289s,  110.58/s)  LR: 7.222e-05  Data: 0.004 (0.005)\n",
            "Train: 15 [ 950/1562 ( 61%)]  Loss:  1.792865 (1.9303)  Time: 0.289s,  110.86/s  (0.289s,  110.61/s)  LR: 7.222e-05  Data: 0.004 (0.005)\n",
            "Train: 15 [1000/1562 ( 64%)]  Loss:  2.218281 (1.9326)  Time: 0.286s,  111.80/s  (0.289s,  110.65/s)  LR: 7.222e-05  Data: 0.004 (0.005)\n",
            "Train: 15 [1050/1562 ( 67%)]  Loss:  1.667126 (1.9365)  Time: 0.294s,  108.81/s  (0.289s,  110.67/s)  LR: 7.222e-05  Data: 0.004 (0.005)\n",
            "Train: 15 [1100/1562 ( 70%)]  Loss:  2.181940 (1.9393)  Time: 0.286s,  111.84/s  (0.289s,  110.69/s)  LR: 7.222e-05  Data: 0.004 (0.005)\n",
            "Train: 15 [1150/1562 ( 74%)]  Loss:  2.082401 (1.9467)  Time: 0.286s,  111.92/s  (0.289s,  110.73/s)  LR: 7.222e-05  Data: 0.004 (0.005)\n",
            "Train: 15 [1200/1562 ( 77%)]  Loss:  1.715554 (1.9513)  Time: 0.287s,  111.58/s  (0.289s,  110.75/s)  LR: 7.222e-05  Data: 0.004 (0.005)\n",
            "Train: 15 [1250/1562 ( 80%)]  Loss:  2.110807 (1.9511)  Time: 0.288s,  110.97/s  (0.289s,  110.77/s)  LR: 7.222e-05  Data: 0.004 (0.005)\n",
            "Train: 15 [1300/1562 ( 83%)]  Loss:  2.015831 (1.9533)  Time: 0.290s,  110.21/s  (0.289s,  110.78/s)  LR: 7.222e-05  Data: 0.004 (0.005)\n",
            "Train: 15 [1350/1562 ( 86%)]  Loss:  1.932255 (1.9548)  Time: 0.286s,  111.89/s  (0.289s,  110.80/s)  LR: 7.222e-05  Data: 0.004 (0.005)\n",
            "Train: 15 [1400/1562 ( 90%)]  Loss:  1.889495 (1.9495)  Time: 0.286s,  111.72/s  (0.289s,  110.82/s)  LR: 7.222e-05  Data: 0.004 (0.005)\n",
            "Train: 15 [1450/1562 ( 93%)]  Loss:  1.881063 (1.9515)  Time: 0.286s,  111.73/s  (0.289s,  110.84/s)  LR: 7.222e-05  Data: 0.004 (0.005)\n",
            "Train: 15 [1500/1562 ( 96%)]  Loss:  1.862389 (1.9533)  Time: 0.292s,  109.49/s  (0.289s,  110.85/s)  LR: 7.222e-05  Data: 0.004 (0.005)\n",
            "Train: 15 [1550/1562 ( 99%)]  Loss:  1.591189 (1.9503)  Time: 0.285s,  112.24/s  (0.289s,  110.88/s)  LR: 7.222e-05  Data: 0.003 (0.005)\n",
            "Train: 15 [1561/1562 (100%)]  Loss:  2.073879 (1.9490)  Time: 0.385s,   83.11/s  (0.289s,  110.86/s)  LR: 7.222e-05  Data: 0.097 (0.005)\n",
            "Test: [   0/312]  Time: 0.961 (0.961)  Loss:  1.0783 (1.0783)  Acc@1: 62.5000 (62.5000)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [  50/312]  Time: 0.093 (0.114)  Loss:  0.6741 (0.8511)  Acc@1: 81.2500 (74.5711)  Acc@5: 96.8750 (97.1814)\n",
            "Test: [ 100/312]  Time: 0.093 (0.103)  Loss:  1.6949 (1.0881)  Acc@1: 31.2500 (63.2426)  Acc@5: 96.8750 (96.7203)\n",
            "Test: [ 150/312]  Time: 0.092 (0.100)  Loss:  1.7132 (1.2408)  Acc@1: 18.7500 (55.5257)  Acc@5: 100.0000 (95.9851)\n",
            "Test: [ 200/312]  Time: 0.093 (0.098)  Loss:  1.0332 (1.2488)  Acc@1: 62.5000 (56.1412)  Acc@5: 96.8750 (96.1132)\n",
            "Test: [ 250/312]  Time: 0.086 (0.097)  Loss:  1.1678 (1.1646)  Acc@1: 68.7500 (60.3461)  Acc@5: 96.8750 (96.2898)\n",
            "Test: [ 300/312]  Time: 0.086 (0.096)  Loss:  0.6430 (1.1580)  Acc@1: 84.3750 (60.9427)  Acc@5: 96.8750 (95.9510)\n",
            "Test: [ 312/312]  Time: 0.132 (0.096)  Loss:  0.8254 (1.1431)  Acc@1: 62.5000 (61.5900)  Acc@5: 100.0000 (96.0300)\n",
            "Test (EMA): [   0/312]  Time: 0.980 (0.980)  Loss:  1.8401 (1.8401)  Acc@1: 43.7500 (43.7500)  Acc@5: 87.5000 (87.5000)\n",
            "Test (EMA): [  50/312]  Time: 0.091 (0.114)  Loss:  1.9566 (1.7432)  Acc@1: 37.5000 (49.0809)  Acc@5: 93.7500 (91.4216)\n",
            "Test (EMA): [ 100/312]  Time: 0.093 (0.103)  Loss:  1.7977 (1.8466)  Acc@1: 18.7500 (32.2710)  Acc@5: 96.8750 (92.1720)\n",
            "Test (EMA): [ 150/312]  Time: 0.095 (0.100)  Loss:  1.7578 (1.8034)  Acc@1: 21.8750 (32.0364)  Acc@5: 100.0000 (93.4810)\n",
            "Test (EMA): [ 200/312]  Time: 0.093 (0.098)  Loss:  0.9666 (1.8040)  Acc@1: 96.8750 (31.8252)  Acc@5: 100.0000 (93.1592)\n",
            "Test (EMA): [ 250/312]  Time: 0.095 (0.097)  Loss:  1.5139 (1.7865)  Acc@1: 65.6250 (34.1633)  Acc@5: 90.6250 (90.6624)\n",
            "Test (EMA): [ 300/312]  Time: 0.086 (0.096)  Loss:  1.6822 (1.7618)  Acc@1: 65.6250 (37.9672)  Acc@5: 96.8750 (91.0195)\n",
            "Test (EMA): [ 312/312]  Time: 0.127 (0.096)  Loss:  1.9111 (1.7673)  Acc@1: 25.0000 (38.0100)  Acc@5: 87.5000 (91.0100)\n",
            "Current checkpoints:\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-15.pth.tar', 38.01)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-14.pth.tar', 34.77)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-13.pth.tar', 31.48)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-12.pth.tar', 28.32)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-11.pth.tar', 25.43)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-10.pth.tar', 22.99)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-9.pth.tar', 21.2)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-8.pth.tar', 19.76)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-7.pth.tar', 18.99)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-6.pth.tar', 18.77)\n",
            "\n",
            "Train: 16 [   0/1562 (  0%)]  Loss:  1.617509 (1.6175)  Time: 1.505s,   21.27/s  (1.505s,   21.27/s)  LR: 6.891e-05  Data: 1.009 (1.009)\n",
            "Train: 16 [  50/1562 (  3%)]  Loss:  1.703344 (1.9726)  Time: 0.286s,  111.70/s  (0.317s,  100.87/s)  LR: 6.891e-05  Data: 0.004 (0.025)\n",
            "Train: 16 [ 100/1562 (  6%)]  Loss:  1.453878 (1.9222)  Time: 0.286s,  111.85/s  (0.303s,  105.74/s)  LR: 6.891e-05  Data: 0.004 (0.014)\n",
            "Train: 16 [ 150/1562 ( 10%)]  Loss:  2.095168 (1.9388)  Time: 0.286s,  111.77/s  (0.297s,  107.57/s)  LR: 6.891e-05  Data: 0.004 (0.011)\n",
            "Train: 16 [ 200/1562 ( 13%)]  Loss:  1.993130 (1.9326)  Time: 0.293s,  109.16/s  (0.295s,  108.50/s)  LR: 6.891e-05  Data: 0.004 (0.009)\n",
            "Train: 16 [ 250/1562 ( 16%)]  Loss:  1.978651 (1.9284)  Time: 0.288s,  111.15/s  (0.293s,  109.08/s)  LR: 6.891e-05  Data: 0.004 (0.008)\n",
            "Train: 16 [ 300/1562 ( 19%)]  Loss:  1.986514 (1.9353)  Time: 0.286s,  111.84/s  (0.292s,  109.45/s)  LR: 6.891e-05  Data: 0.003 (0.007)\n",
            "Train: 16 [ 350/1562 ( 22%)]  Loss:  1.890071 (1.9214)  Time: 0.288s,  111.17/s  (0.292s,  109.71/s)  LR: 6.891e-05  Data: 0.004 (0.007)\n",
            "Train: 16 [ 400/1562 ( 26%)]  Loss:  2.128213 (1.9072)  Time: 0.286s,  111.86/s  (0.291s,  109.90/s)  LR: 6.891e-05  Data: 0.004 (0.006)\n",
            "Train: 16 [ 450/1562 ( 29%)]  Loss:  2.076530 (1.9061)  Time: 0.294s,  108.96/s  (0.291s,  110.03/s)  LR: 6.891e-05  Data: 0.004 (0.006)\n",
            "Train: 16 [ 500/1562 ( 32%)]  Loss:  1.834775 (1.9049)  Time: 0.286s,  111.75/s  (0.290s,  110.17/s)  LR: 6.891e-05  Data: 0.004 (0.006)\n",
            "Train: 16 [ 550/1562 ( 35%)]  Loss:  1.999246 (1.9036)  Time: 0.293s,  109.20/s  (0.290s,  110.27/s)  LR: 6.891e-05  Data: 0.004 (0.006)\n",
            "Train: 16 [ 600/1562 ( 38%)]  Loss:  2.102623 (1.9005)  Time: 0.290s,  110.32/s  (0.290s,  110.36/s)  LR: 6.891e-05  Data: 0.004 (0.006)\n",
            "Train: 16 [ 650/1562 ( 42%)]  Loss:  1.761308 (1.9032)  Time: 0.287s,  111.57/s  (0.290s,  110.42/s)  LR: 6.891e-05  Data: 0.004 (0.005)\n",
            "Train: 16 [ 700/1562 ( 45%)]  Loss:  1.972707 (1.9045)  Time: 0.289s,  110.69/s  (0.290s,  110.49/s)  LR: 6.891e-05  Data: 0.004 (0.005)\n",
            "Train: 16 [ 750/1562 ( 48%)]  Loss:  2.020385 (1.9113)  Time: 0.287s,  111.59/s  (0.289s,  110.55/s)  LR: 6.891e-05  Data: 0.004 (0.005)\n",
            "Train: 16 [ 800/1562 ( 51%)]  Loss:  1.626290 (1.9121)  Time: 0.287s,  111.69/s  (0.289s,  110.60/s)  LR: 6.891e-05  Data: 0.004 (0.005)\n",
            "Train: 16 [ 850/1562 ( 54%)]  Loss:  2.078160 (1.9183)  Time: 0.295s,  108.49/s  (0.289s,  110.64/s)  LR: 6.891e-05  Data: 0.004 (0.005)\n",
            "Train: 16 [ 900/1562 ( 58%)]  Loss:  2.146367 (1.9230)  Time: 0.286s,  111.73/s  (0.289s,  110.67/s)  LR: 6.891e-05  Data: 0.004 (0.005)\n",
            "Train: 16 [ 950/1562 ( 61%)]  Loss:  1.854367 (1.9222)  Time: 0.286s,  111.74/s  (0.289s,  110.71/s)  LR: 6.891e-05  Data: 0.004 (0.005)\n",
            "Train: 16 [1000/1562 ( 64%)]  Loss:  2.145094 (1.9238)  Time: 0.290s,  110.52/s  (0.289s,  110.75/s)  LR: 6.891e-05  Data: 0.004 (0.005)\n",
            "Train: 16 [1050/1562 ( 67%)]  Loss:  1.832970 (1.9269)  Time: 0.286s,  111.89/s  (0.289s,  110.78/s)  LR: 6.891e-05  Data: 0.004 (0.005)\n",
            "Train: 16 [1100/1562 ( 70%)]  Loss:  2.172897 (1.9291)  Time: 0.287s,  111.67/s  (0.289s,  110.80/s)  LR: 6.891e-05  Data: 0.004 (0.005)\n",
            "Train: 16 [1150/1562 ( 74%)]  Loss:  2.159507 (1.9357)  Time: 0.287s,  111.68/s  (0.289s,  110.83/s)  LR: 6.891e-05  Data: 0.004 (0.005)\n",
            "Train: 16 [1200/1562 ( 77%)]  Loss:  1.715144 (1.9414)  Time: 0.285s,  112.12/s  (0.289s,  110.84/s)  LR: 6.891e-05  Data: 0.004 (0.005)\n",
            "Train: 16 [1250/1562 ( 80%)]  Loss:  2.000591 (1.9407)  Time: 0.288s,  111.24/s  (0.289s,  110.86/s)  LR: 6.891e-05  Data: 0.004 (0.005)\n",
            "Train: 16 [1300/1562 ( 83%)]  Loss:  1.668641 (1.9429)  Time: 0.286s,  111.77/s  (0.289s,  110.87/s)  LR: 6.891e-05  Data: 0.004 (0.005)\n",
            "Train: 16 [1350/1562 ( 86%)]  Loss:  2.014110 (1.9440)  Time: 0.286s,  111.75/s  (0.289s,  110.90/s)  LR: 6.891e-05  Data: 0.004 (0.005)\n",
            "Train: 16 [1400/1562 ( 90%)]  Loss:  2.167632 (1.9402)  Time: 0.287s,  111.69/s  (0.289s,  110.92/s)  LR: 6.891e-05  Data: 0.004 (0.005)\n",
            "Train: 16 [1450/1562 ( 93%)]  Loss:  2.098379 (1.9423)  Time: 0.288s,  111.10/s  (0.288s,  110.93/s)  LR: 6.891e-05  Data: 0.006 (0.005)\n",
            "Train: 16 [1500/1562 ( 96%)]  Loss:  2.096509 (1.9427)  Time: 0.287s,  111.56/s  (0.288s,  110.95/s)  LR: 6.891e-05  Data: 0.004 (0.005)\n",
            "Train: 16 [1550/1562 ( 99%)]  Loss:  1.578766 (1.9407)  Time: 0.285s,  112.38/s  (0.288s,  110.97/s)  LR: 6.891e-05  Data: 0.003 (0.005)\n",
            "Train: 16 [1561/1562 (100%)]  Loss:  2.071428 (1.9396)  Time: 0.369s,   86.68/s  (0.288s,  110.96/s)  LR: 6.891e-05  Data: 0.089 (0.005)\n",
            "Test: [   0/312]  Time: 0.897 (0.897)  Loss:  1.1888 (1.1888)  Acc@1: 68.7500 (68.7500)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [  50/312]  Time: 0.095 (0.113)  Loss:  0.8229 (0.8500)  Acc@1: 75.0000 (75.6740)  Acc@5: 100.0000 (98.3456)\n",
            "Test: [ 100/312]  Time: 0.094 (0.103)  Loss:  1.8355 (1.1417)  Acc@1: 21.8750 (61.0767)  Acc@5: 100.0000 (97.3082)\n",
            "Test: [ 150/312]  Time: 0.087 (0.099)  Loss:  1.4761 (1.2806)  Acc@1: 43.7500 (53.2078)  Acc@5: 100.0000 (96.2955)\n",
            "Test: [ 200/312]  Time: 0.089 (0.097)  Loss:  0.7692 (1.2733)  Acc@1: 81.2500 (55.0373)  Acc@5: 100.0000 (96.0821)\n",
            "Test: [ 250/312]  Time: 0.088 (0.096)  Loss:  1.0745 (1.1739)  Acc@1: 68.7500 (59.9228)  Acc@5: 93.7500 (96.2151)\n",
            "Test: [ 300/312]  Time: 0.086 (0.095)  Loss:  0.5617 (1.1508)  Acc@1: 81.2500 (60.9635)  Acc@5: 100.0000 (96.0133)\n",
            "Test: [ 312/312]  Time: 0.137 (0.095)  Loss:  0.7279 (1.1375)  Acc@1: 75.0000 (61.5300)  Acc@5: 100.0000 (96.0200)\n",
            "Test (EMA): [   0/312]  Time: 0.821 (0.821)  Loss:  1.8033 (1.8033)  Acc@1: 43.7500 (43.7500)  Acc@5: 87.5000 (87.5000)\n",
            "Test (EMA): [  50/312]  Time: 0.089 (0.112)  Loss:  1.8687 (1.6791)  Acc@1: 37.5000 (51.8382)  Acc@5: 96.8750 (92.4020)\n",
            "Test (EMA): [ 100/312]  Time: 0.095 (0.103)  Loss:  1.7589 (1.7951)  Acc@1: 21.8750 (35.7364)  Acc@5: 96.8750 (92.7599)\n",
            "Test (EMA): [ 150/312]  Time: 0.104 (0.099)  Loss:  1.7449 (1.7581)  Acc@1: 25.0000 (35.5546)  Acc@5: 100.0000 (93.8535)\n",
            "Test (EMA): [ 200/312]  Time: 0.095 (0.098)  Loss:  0.9512 (1.7604)  Acc@1: 96.8750 (34.5149)  Acc@5: 100.0000 (93.6412)\n",
            "Test (EMA): [ 250/312]  Time: 0.087 (0.097)  Loss:  1.4537 (1.7386)  Acc@1: 65.6250 (36.9771)  Acc@5: 96.8750 (91.4716)\n",
            "Test (EMA): [ 300/312]  Time: 0.086 (0.096)  Loss:  1.5680 (1.7099)  Acc@1: 68.7500 (40.7703)  Acc@5: 100.0000 (91.8708)\n",
            "Test (EMA): [ 312/312]  Time: 0.132 (0.095)  Loss:  1.8173 (1.7137)  Acc@1: 37.5000 (41.0000)  Acc@5: 87.5000 (91.9400)\n",
            "Current checkpoints:\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-16.pth.tar', 41.0)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-15.pth.tar', 38.01)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-14.pth.tar', 34.77)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-13.pth.tar', 31.48)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-12.pth.tar', 28.32)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-11.pth.tar', 25.43)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-10.pth.tar', 22.99)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-9.pth.tar', 21.2)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-8.pth.tar', 19.76)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-7.pth.tar', 18.99)\n",
            "\n",
            "Train: 17 [   0/1562 (  0%)]  Loss:  1.465928 (1.4659)  Time: 1.499s,   21.35/s  (1.499s,   21.35/s)  LR: 6.551e-05  Data: 1.034 (1.034)\n",
            "Train: 17 [  50/1562 (  3%)]  Loss:  1.813914 (1.9826)  Time: 0.289s,  110.69/s  (0.317s,  100.84/s)  LR: 6.551e-05  Data: 0.004 (0.025)\n",
            "Train: 17 [ 100/1562 (  6%)]  Loss:  1.948432 (1.9306)  Time: 0.286s,  111.89/s  (0.303s,  105.78/s)  LR: 6.551e-05  Data: 0.004 (0.014)\n",
            "Train: 17 [ 150/1562 ( 10%)]  Loss:  2.004433 (1.9427)  Time: 0.289s,  110.70/s  (0.297s,  107.58/s)  LR: 6.551e-05  Data: 0.004 (0.011)\n",
            "Train: 17 [ 200/1562 ( 13%)]  Loss:  2.098644 (1.9347)  Time: 0.287s,  111.58/s  (0.295s,  108.44/s)  LR: 6.551e-05  Data: 0.004 (0.009)\n",
            "Train: 17 [ 250/1562 ( 16%)]  Loss:  1.979510 (1.9339)  Time: 0.287s,  111.62/s  (0.294s,  108.97/s)  LR: 6.551e-05  Data: 0.004 (0.008)\n",
            "Train: 17 [ 300/1562 ( 19%)]  Loss:  2.166932 (1.9338)  Time: 0.289s,  110.67/s  (0.293s,  109.37/s)  LR: 6.551e-05  Data: 0.004 (0.007)\n",
            "Train: 17 [ 350/1562 ( 22%)]  Loss:  1.897517 (1.9141)  Time: 0.286s,  111.89/s  (0.292s,  109.65/s)  LR: 6.551e-05  Data: 0.004 (0.007)\n",
            "Train: 17 [ 400/1562 ( 26%)]  Loss:  2.109844 (1.9034)  Time: 0.294s,  109.01/s  (0.291s,  109.85/s)  LR: 6.551e-05  Data: 0.004 (0.006)\n",
            "Train: 17 [ 450/1562 ( 29%)]  Loss:  1.964183 (1.9018)  Time: 0.286s,  111.88/s  (0.291s,  110.05/s)  LR: 6.551e-05  Data: 0.004 (0.006)\n",
            "Train: 17 [ 500/1562 ( 32%)]  Loss:  1.796257 (1.9036)  Time: 0.286s,  111.82/s  (0.290s,  110.19/s)  LR: 6.551e-05  Data: 0.004 (0.006)\n",
            "Train: 17 [ 550/1562 ( 35%)]  Loss:  1.609055 (1.9000)  Time: 0.290s,  110.48/s  (0.290s,  110.27/s)  LR: 6.551e-05  Data: 0.004 (0.006)\n",
            "Train: 17 [ 600/1562 ( 38%)]  Loss:  2.083808 (1.8934)  Time: 0.286s,  111.92/s  (0.290s,  110.36/s)  LR: 6.551e-05  Data: 0.004 (0.006)\n",
            "Train: 17 [ 650/1562 ( 42%)]  Loss:  1.505372 (1.8963)  Time: 0.286s,  111.96/s  (0.290s,  110.44/s)  LR: 6.551e-05  Data: 0.004 (0.005)\n",
            "Train: 17 [ 700/1562 ( 45%)]  Loss:  1.530885 (1.8979)  Time: 0.287s,  111.36/s  (0.290s,  110.52/s)  LR: 6.551e-05  Data: 0.004 (0.005)\n",
            "Train: 17 [ 750/1562 ( 48%)]  Loss:  1.743122 (1.9030)  Time: 0.286s,  111.83/s  (0.289s,  110.55/s)  LR: 6.551e-05  Data: 0.004 (0.005)\n",
            "Train: 17 [ 800/1562 ( 51%)]  Loss:  1.708008 (1.9044)  Time: 0.293s,  109.20/s  (0.289s,  110.59/s)  LR: 6.551e-05  Data: 0.004 (0.005)\n",
            "Train: 17 [ 850/1562 ( 54%)]  Loss:  2.016948 (1.9095)  Time: 0.286s,  111.86/s  (0.289s,  110.62/s)  LR: 6.551e-05  Data: 0.004 (0.005)\n",
            "Train: 17 [ 900/1562 ( 58%)]  Loss:  1.743882 (1.9119)  Time: 0.286s,  111.75/s  (0.289s,  110.65/s)  LR: 6.551e-05  Data: 0.004 (0.005)\n",
            "Train: 17 [ 950/1562 ( 61%)]  Loss:  1.676742 (1.9092)  Time: 0.286s,  111.86/s  (0.289s,  110.70/s)  LR: 6.551e-05  Data: 0.004 (0.005)\n",
            "Train: 17 [1000/1562 ( 64%)]  Loss:  2.084498 (1.9112)  Time: 0.286s,  111.79/s  (0.289s,  110.74/s)  LR: 6.551e-05  Data: 0.004 (0.005)\n",
            "Train: 17 [1050/1562 ( 67%)]  Loss:  1.649663 (1.9149)  Time: 0.287s,  111.56/s  (0.289s,  110.77/s)  LR: 6.551e-05  Data: 0.004 (0.005)\n",
            "Train: 17 [1100/1562 ( 70%)]  Loss:  2.034400 (1.9157)  Time: 0.294s,  108.75/s  (0.289s,  110.79/s)  LR: 6.551e-05  Data: 0.004 (0.005)\n",
            "Train: 17 [1150/1562 ( 74%)]  Loss:  2.042435 (1.9231)  Time: 0.286s,  111.82/s  (0.289s,  110.81/s)  LR: 6.551e-05  Data: 0.004 (0.005)\n",
            "Train: 17 [1200/1562 ( 77%)]  Loss:  1.652969 (1.9290)  Time: 0.286s,  111.85/s  (0.289s,  110.83/s)  LR: 6.551e-05  Data: 0.004 (0.005)\n",
            "Train: 17 [1250/1562 ( 80%)]  Loss:  1.921188 (1.9285)  Time: 0.287s,  111.33/s  (0.289s,  110.84/s)  LR: 6.551e-05  Data: 0.004 (0.005)\n",
            "Train: 17 [1300/1562 ( 83%)]  Loss:  1.900956 (1.9324)  Time: 0.286s,  111.89/s  (0.289s,  110.86/s)  LR: 6.551e-05  Data: 0.004 (0.005)\n",
            "Train: 17 [1350/1562 ( 86%)]  Loss:  2.098952 (1.9335)  Time: 0.286s,  111.74/s  (0.289s,  110.88/s)  LR: 6.551e-05  Data: 0.004 (0.005)\n",
            "Train: 17 [1400/1562 ( 90%)]  Loss:  1.916926 (1.9285)  Time: 0.286s,  111.85/s  (0.289s,  110.89/s)  LR: 6.551e-05  Data: 0.004 (0.005)\n",
            "Train: 17 [1450/1562 ( 93%)]  Loss:  1.992742 (1.9311)  Time: 0.286s,  112.00/s  (0.289s,  110.90/s)  LR: 6.551e-05  Data: 0.004 (0.005)\n",
            "Train: 17 [1500/1562 ( 96%)]  Loss:  2.068651 (1.9325)  Time: 0.290s,  110.53/s  (0.289s,  110.91/s)  LR: 6.551e-05  Data: 0.004 (0.005)\n",
            "Train: 17 [1550/1562 ( 99%)]  Loss:  1.782025 (1.9312)  Time: 0.283s,  112.88/s  (0.288s,  110.93/s)  LR: 6.551e-05  Data: 0.003 (0.005)\n",
            "Train: 17 [1561/1562 (100%)]  Loss:  1.831855 (1.9296)  Time: 0.369s,   86.79/s  (0.288s,  110.92/s)  LR: 6.551e-05  Data: 0.088 (0.005)\n",
            "Test: [   0/312]  Time: 0.938 (0.938)  Loss:  1.5216 (1.5216)  Acc@1: 53.1250 (53.1250)  Acc@5: 93.7500 (93.7500)\n",
            "Test: [  50/312]  Time: 0.105 (0.113)  Loss:  0.7215 (1.0218)  Acc@1: 81.2500 (66.4216)  Acc@5: 100.0000 (97.1814)\n",
            "Test: [ 100/312]  Time: 0.091 (0.103)  Loss:  1.4183 (1.1715)  Acc@1: 56.2500 (59.8700)  Acc@5: 93.7500 (96.4728)\n",
            "Test: [ 150/312]  Time: 0.098 (0.099)  Loss:  1.7378 (1.2701)  Acc@1: 15.6250 (54.9876)  Acc@5: 93.7500 (96.3576)\n",
            "Test: [ 200/312]  Time: 0.087 (0.098)  Loss:  1.0370 (1.2461)  Acc@1: 68.7500 (56.8408)  Acc@5: 100.0000 (96.5641)\n",
            "Test: [ 250/312]  Time: 0.087 (0.096)  Loss:  0.5838 (1.1706)  Acc@1: 87.5000 (60.9811)  Acc@5: 100.0000 (96.6135)\n",
            "Test: [ 300/312]  Time: 0.086 (0.096)  Loss:  0.5224 (1.0943)  Acc@1: 84.3750 (64.2961)  Acc@5: 100.0000 (96.7297)\n",
            "Test: [ 312/312]  Time: 0.130 (0.095)  Loss:  0.5471 (1.0785)  Acc@1: 87.5000 (64.9900)  Acc@5: 100.0000 (96.7900)\n",
            "Test (EMA): [   0/312]  Time: 0.841 (0.841)  Loss:  1.7687 (1.7687)  Acc@1: 43.7500 (43.7500)  Acc@5: 90.6250 (90.6250)\n",
            "Test (EMA): [  50/312]  Time: 0.093 (0.113)  Loss:  1.7845 (1.6185)  Acc@1: 37.5000 (53.9216)  Acc@5: 96.8750 (93.0760)\n",
            "Test (EMA): [ 100/312]  Time: 0.093 (0.102)  Loss:  1.7248 (1.7459)  Acc@1: 25.0000 (37.9332)  Acc@5: 96.8750 (92.9455)\n",
            "Test (EMA): [ 150/312]  Time: 0.086 (0.099)  Loss:  1.7370 (1.7160)  Acc@1: 28.1250 (38.3485)  Acc@5: 100.0000 (93.9363)\n",
            "Test (EMA): [ 200/312]  Time: 0.095 (0.097)  Loss:  0.9324 (1.7187)  Acc@1: 96.8750 (36.9248)  Acc@5: 100.0000 (93.8899)\n",
            "Test (EMA): [ 250/312]  Time: 0.087 (0.096)  Loss:  1.4012 (1.6913)  Acc@1: 65.6250 (39.6165)  Acc@5: 96.8750 (92.1315)\n",
            "Test (EMA): [ 300/312]  Time: 0.086 (0.096)  Loss:  1.4604 (1.6596)  Acc@1: 71.8750 (43.5112)  Acc@5: 100.0000 (92.5249)\n",
            "Test (EMA): [ 312/312]  Time: 0.129 (0.096)  Loss:  1.7282 (1.6616)  Acc@1: 50.0000 (43.8700)  Acc@5: 87.5000 (92.6100)\n",
            "Current checkpoints:\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-17.pth.tar', 43.87)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-16.pth.tar', 41.0)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-15.pth.tar', 38.01)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-14.pth.tar', 34.77)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-13.pth.tar', 31.48)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-12.pth.tar', 28.32)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-11.pth.tar', 25.43)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-10.pth.tar', 22.99)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-9.pth.tar', 21.2)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-8.pth.tar', 19.76)\n",
            "\n",
            "Train: 18 [   0/1562 (  0%)]  Loss:  1.599082 (1.5991)  Time: 1.601s,   19.99/s  (1.601s,   19.99/s)  LR: 6.204e-05  Data: 1.116 (1.116)\n",
            "Train: 18 [  50/1562 (  3%)]  Loss:  2.047937 (1.9541)  Time: 0.289s,  110.66/s  (0.318s,  100.68/s)  LR: 6.204e-05  Data: 0.007 (0.026)\n",
            "Train: 18 [ 100/1562 (  6%)]  Loss:  1.866384 (1.9210)  Time: 0.293s,  109.36/s  (0.303s,  105.67/s)  LR: 6.204e-05  Data: 0.004 (0.015)\n",
            "Train: 18 [ 150/1562 ( 10%)]  Loss:  2.186158 (1.9327)  Time: 0.286s,  111.72/s  (0.298s,  107.52/s)  LR: 6.204e-05  Data: 0.004 (0.011)\n",
            "Train: 18 [ 200/1562 ( 13%)]  Loss:  1.976547 (1.9162)  Time: 0.286s,  111.87/s  (0.295s,  108.44/s)  LR: 6.204e-05  Data: 0.004 (0.009)\n",
            "Train: 18 [ 250/1562 ( 16%)]  Loss:  1.907228 (1.9128)  Time: 0.286s,  112.01/s  (0.294s,  108.99/s)  LR: 6.204e-05  Data: 0.004 (0.008)\n",
            "Train: 18 [ 300/1562 ( 19%)]  Loss:  2.115341 (1.9181)  Time: 0.286s,  111.82/s  (0.293s,  109.38/s)  LR: 6.204e-05  Data: 0.004 (0.008)\n",
            "Train: 18 [ 350/1562 ( 22%)]  Loss:  1.719464 (1.9023)  Time: 0.289s,  110.82/s  (0.292s,  109.63/s)  LR: 6.204e-05  Data: 0.004 (0.007)\n",
            "Train: 18 [ 400/1562 ( 26%)]  Loss:  1.870268 (1.8920)  Time: 0.286s,  111.75/s  (0.291s,  109.84/s)  LR: 6.204e-05  Data: 0.004 (0.007)\n",
            "Train: 18 [ 450/1562 ( 29%)]  Loss:  2.305537 (1.8918)  Time: 0.286s,  111.77/s  (0.291s,  109.98/s)  LR: 6.204e-05  Data: 0.004 (0.006)\n",
            "Train: 18 [ 500/1562 ( 32%)]  Loss:  1.353531 (1.8914)  Time: 0.294s,  108.78/s  (0.291s,  110.11/s)  LR: 6.204e-05  Data: 0.004 (0.006)\n",
            "Train: 18 [ 550/1562 ( 35%)]  Loss:  1.769238 (1.8870)  Time: 0.289s,  110.62/s  (0.290s,  110.16/s)  LR: 6.204e-05  Data: 0.004 (0.006)\n",
            "Train: 18 [ 600/1562 ( 38%)]  Loss:  2.081702 (1.8822)  Time: 0.294s,  108.93/s  (0.290s,  110.24/s)  LR: 6.204e-05  Data: 0.004 (0.006)\n",
            "Train: 18 [ 650/1562 ( 42%)]  Loss:  1.699491 (1.8846)  Time: 0.287s,  111.54/s  (0.290s,  110.31/s)  LR: 6.204e-05  Data: 0.004 (0.006)\n",
            "Train: 18 [ 700/1562 ( 45%)]  Loss:  1.666184 (1.8881)  Time: 0.286s,  111.77/s  (0.290s,  110.38/s)  LR: 6.204e-05  Data: 0.004 (0.005)\n",
            "Train: 18 [ 750/1562 ( 48%)]  Loss:  1.734708 (1.8931)  Time: 0.286s,  111.77/s  (0.290s,  110.45/s)  LR: 6.204e-05  Data: 0.004 (0.005)\n",
            "Train: 18 [ 800/1562 ( 51%)]  Loss:  1.746451 (1.8945)  Time: 0.286s,  111.80/s  (0.290s,  110.50/s)  LR: 6.204e-05  Data: 0.004 (0.005)\n",
            "Train: 18 [ 850/1562 ( 54%)]  Loss:  2.038446 (1.9017)  Time: 0.286s,  111.90/s  (0.289s,  110.54/s)  LR: 6.204e-05  Data: 0.004 (0.005)\n",
            "Train: 18 [ 900/1562 ( 58%)]  Loss:  1.901316 (1.9047)  Time: 0.288s,  111.30/s  (0.289s,  110.57/s)  LR: 6.204e-05  Data: 0.004 (0.005)\n",
            "Train: 18 [ 950/1562 ( 61%)]  Loss:  1.828598 (1.9032)  Time: 0.286s,  111.70/s  (0.289s,  110.61/s)  LR: 6.204e-05  Data: 0.004 (0.005)\n",
            "Train: 18 [1000/1562 ( 64%)]  Loss:  2.039174 (1.9055)  Time: 0.298s,  107.41/s  (0.289s,  110.64/s)  LR: 6.204e-05  Data: 0.004 (0.005)\n",
            "Train: 18 [1050/1562 ( 67%)]  Loss:  1.689747 (1.9105)  Time: 0.286s,  111.79/s  (0.289s,  110.67/s)  LR: 6.204e-05  Data: 0.004 (0.005)\n",
            "Train: 18 [1100/1562 ( 70%)]  Loss:  2.225784 (1.9134)  Time: 0.286s,  111.75/s  (0.289s,  110.69/s)  LR: 6.204e-05  Data: 0.004 (0.005)\n",
            "Train: 18 [1150/1562 ( 74%)]  Loss:  2.089906 (1.9212)  Time: 0.289s,  110.72/s  (0.289s,  110.71/s)  LR: 6.204e-05  Data: 0.004 (0.005)\n",
            "Train: 18 [1200/1562 ( 77%)]  Loss:  1.799928 (1.9276)  Time: 0.286s,  111.70/s  (0.289s,  110.73/s)  LR: 6.204e-05  Data: 0.004 (0.005)\n",
            "Train: 18 [1250/1562 ( 80%)]  Loss:  1.998550 (1.9278)  Time: 0.287s,  111.64/s  (0.289s,  110.75/s)  LR: 6.204e-05  Data: 0.004 (0.005)\n",
            "Train: 18 [1300/1562 ( 83%)]  Loss:  1.975471 (1.9300)  Time: 0.286s,  111.72/s  (0.289s,  110.77/s)  LR: 6.204e-05  Data: 0.004 (0.005)\n",
            "Train: 18 [1350/1562 ( 86%)]  Loss:  2.150509 (1.9312)  Time: 0.287s,  111.65/s  (0.289s,  110.78/s)  LR: 6.204e-05  Data: 0.004 (0.005)\n",
            "Train: 18 [1400/1562 ( 90%)]  Loss:  2.118346 (1.9265)  Time: 0.287s,  111.67/s  (0.289s,  110.80/s)  LR: 6.204e-05  Data: 0.004 (0.005)\n",
            "Train: 18 [1450/1562 ( 93%)]  Loss:  2.146994 (1.9281)  Time: 0.286s,  111.80/s  (0.289s,  110.81/s)  LR: 6.204e-05  Data: 0.004 (0.005)\n",
            "Train: 18 [1500/1562 ( 96%)]  Loss:  2.069855 (1.9285)  Time: 0.286s,  111.71/s  (0.289s,  110.83/s)  LR: 6.204e-05  Data: 0.004 (0.005)\n",
            "Train: 18 [1550/1562 ( 99%)]  Loss:  1.865406 (1.9266)  Time: 0.284s,  112.75/s  (0.289s,  110.84/s)  LR: 6.204e-05  Data: 0.003 (0.005)\n",
            "Train: 18 [1561/1562 (100%)]  Loss:  1.919299 (1.9252)  Time: 0.373s,   85.71/s  (0.289s,  110.83/s)  LR: 6.204e-05  Data: 0.093 (0.005)\n",
            "Test: [   0/312]  Time: 0.929 (0.929)  Loss:  1.3319 (1.3319)  Acc@1: 53.1250 (53.1250)  Acc@5: 96.8750 (96.8750)\n",
            "Test: [  50/312]  Time: 0.097 (0.115)  Loss:  0.8513 (0.9771)  Acc@1: 78.1250 (68.5662)  Acc@5: 100.0000 (97.3039)\n",
            "Test: [ 100/312]  Time: 0.096 (0.104)  Loss:  1.4726 (1.1758)  Acc@1: 50.0000 (59.8700)  Acc@5: 100.0000 (96.2871)\n",
            "Test: [ 150/312]  Time: 0.095 (0.100)  Loss:  1.4715 (1.2421)  Acc@1: 37.5000 (57.3055)  Acc@5: 100.0000 (96.4404)\n",
            "Test: [ 200/312]  Time: 0.087 (0.099)  Loss:  0.8857 (1.2509)  Acc@1: 71.8750 (57.1984)  Acc@5: 100.0000 (96.3464)\n",
            "Test: [ 250/312]  Time: 0.087 (0.097)  Loss:  0.6508 (1.1638)  Acc@1: 87.5000 (61.4417)  Acc@5: 96.8750 (96.5264)\n",
            "Test: [ 300/312]  Time: 0.086 (0.097)  Loss:  0.5007 (1.0887)  Acc@1: 90.6250 (64.5972)  Acc@5: 100.0000 (96.6570)\n",
            "Test: [ 312/312]  Time: 0.136 (0.096)  Loss:  0.7836 (1.0718)  Acc@1: 81.2500 (65.3900)  Acc@5: 100.0000 (96.7300)\n",
            "Test (EMA): [   0/312]  Time: 0.880 (0.880)  Loss:  1.7319 (1.7319)  Acc@1: 43.7500 (43.7500)  Acc@5: 93.7500 (93.7500)\n",
            "Test (EMA): [  50/312]  Time: 0.088 (0.114)  Loss:  1.6975 (1.5553)  Acc@1: 40.6250 (56.6176)  Acc@5: 96.8750 (93.5662)\n",
            "Test (EMA): [ 100/312]  Time: 0.088 (0.104)  Loss:  1.6910 (1.6958)  Acc@1: 34.3750 (40.7488)  Acc@5: 96.8750 (93.3168)\n",
            "Test (EMA): [ 150/312]  Time: 0.096 (0.100)  Loss:  1.7329 (1.6741)  Acc@1: 31.2500 (40.9975)  Acc@5: 100.0000 (94.1639)\n",
            "Test (EMA): [ 200/312]  Time: 0.088 (0.099)  Loss:  0.9113 (1.6782)  Acc@1: 93.7500 (39.1325)  Acc@5: 100.0000 (94.1231)\n",
            "Test (EMA): [ 250/312]  Time: 0.091 (0.098)  Loss:  1.3517 (1.6457)  Acc@1: 68.7500 (42.0692)  Acc@5: 96.8750 (92.7166)\n",
            "Test (EMA): [ 300/312]  Time: 0.086 (0.097)  Loss:  1.3623 (1.6113)  Acc@1: 78.1250 (46.0029)  Acc@5: 100.0000 (93.0855)\n",
            "Test (EMA): [ 312/312]  Time: 0.133 (0.096)  Loss:  1.6428 (1.6117)  Acc@1: 56.2500 (46.3700)  Acc@5: 87.5000 (93.1700)\n",
            "Current checkpoints:\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-18.pth.tar', 46.37)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-17.pth.tar', 43.87)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-16.pth.tar', 41.0)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-15.pth.tar', 38.01)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-14.pth.tar', 34.77)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-13.pth.tar', 31.48)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-12.pth.tar', 28.32)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-11.pth.tar', 25.43)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-10.pth.tar', 22.99)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-9.pth.tar', 21.2)\n",
            "\n",
            "Train: 19 [   0/1562 (  0%)]  Loss:  1.588748 (1.5887)  Time: 1.823s,   17.55/s  (1.823s,   17.55/s)  LR: 5.853e-05  Data: 1.323 (1.323)\n",
            "Train: 19 [  50/1562 (  3%)]  Loss:  1.639251 (1.9556)  Time: 0.287s,  111.55/s  (0.321s,   99.64/s)  LR: 5.853e-05  Data: 0.004 (0.030)\n",
            "Train: 19 [ 100/1562 (  6%)]  Loss:  1.763454 (1.9251)  Time: 0.286s,  111.77/s  (0.304s,  105.11/s)  LR: 5.853e-05  Data: 0.004 (0.017)\n",
            "Train: 19 [ 150/1562 ( 10%)]  Loss:  2.022118 (1.9323)  Time: 0.286s,  111.86/s  (0.299s,  107.12/s)  LR: 5.853e-05  Data: 0.004 (0.013)\n",
            "Train: 19 [ 200/1562 ( 13%)]  Loss:  2.068575 (1.9186)  Time: 0.287s,  111.65/s  (0.296s,  108.13/s)  LR: 5.853e-05  Data: 0.004 (0.010)\n",
            "Train: 19 [ 250/1562 ( 16%)]  Loss:  1.719824 (1.9133)  Time: 0.286s,  111.86/s  (0.294s,  108.72/s)  LR: 5.853e-05  Data: 0.004 (0.009)\n",
            "Train: 19 [ 300/1562 ( 19%)]  Loss:  1.983053 (1.9101)  Time: 0.290s,  110.49/s  (0.293s,  109.06/s)  LR: 5.853e-05  Data: 0.004 (0.008)\n",
            "Train: 19 [ 350/1562 ( 22%)]  Loss:  1.872506 (1.8962)  Time: 0.286s,  111.86/s  (0.293s,  109.34/s)  LR: 5.853e-05  Data: 0.004 (0.008)\n",
            "Train: 19 [ 400/1562 ( 26%)]  Loss:  2.014287 (1.8854)  Time: 0.286s,  111.95/s  (0.292s,  109.58/s)  LR: 5.853e-05  Data: 0.004 (0.007)\n",
            "Train: 19 [ 450/1562 ( 29%)]  Loss:  2.106555 (1.8798)  Time: 0.286s,  111.83/s  (0.292s,  109.77/s)  LR: 5.853e-05  Data: 0.004 (0.007)\n",
            "Train: 19 [ 500/1562 ( 32%)]  Loss:  1.677785 (1.8792)  Time: 0.286s,  111.76/s  (0.291s,  109.92/s)  LR: 5.853e-05  Data: 0.004 (0.007)\n",
            "Train: 19 [ 550/1562 ( 35%)]  Loss:  1.569625 (1.8744)  Time: 0.286s,  111.72/s  (0.291s,  110.03/s)  LR: 5.853e-05  Data: 0.004 (0.006)\n",
            "Train: 19 [ 600/1562 ( 38%)]  Loss:  1.977729 (1.8699)  Time: 0.286s,  111.96/s  (0.291s,  110.12/s)  LR: 5.853e-05  Data: 0.004 (0.006)\n",
            "Train: 19 [ 650/1562 ( 42%)]  Loss:  1.593558 (1.8711)  Time: 0.286s,  112.00/s  (0.290s,  110.20/s)  LR: 5.853e-05  Data: 0.004 (0.006)\n",
            "Train: 19 [ 700/1562 ( 45%)]  Loss:  1.732870 (1.8748)  Time: 0.288s,  111.26/s  (0.290s,  110.28/s)  LR: 5.853e-05  Data: 0.004 (0.006)\n",
            "Train: 19 [ 750/1562 ( 48%)]  Loss:  1.789320 (1.8807)  Time: 0.289s,  110.87/s  (0.290s,  110.35/s)  LR: 5.853e-05  Data: 0.004 (0.006)\n",
            "Train: 19 [ 800/1562 ( 51%)]  Loss:  1.696019 (1.8834)  Time: 0.287s,  111.54/s  (0.290s,  110.39/s)  LR: 5.853e-05  Data: 0.004 (0.006)\n",
            "Train: 19 [ 850/1562 ( 54%)]  Loss:  2.013575 (1.8904)  Time: 0.286s,  111.84/s  (0.290s,  110.45/s)  LR: 5.853e-05  Data: 0.004 (0.005)\n",
            "Train: 19 [ 900/1562 ( 58%)]  Loss:  1.823269 (1.8940)  Time: 0.292s,  109.66/s  (0.290s,  110.48/s)  LR: 5.853e-05  Data: 0.004 (0.005)\n",
            "Train: 19 [ 950/1562 ( 61%)]  Loss:  1.700861 (1.8917)  Time: 0.287s,  111.54/s  (0.290s,  110.51/s)  LR: 5.853e-05  Data: 0.004 (0.005)\n",
            "Train: 19 [1000/1562 ( 64%)]  Loss:  2.057401 (1.8942)  Time: 0.292s,  109.74/s  (0.290s,  110.52/s)  LR: 5.853e-05  Data: 0.004 (0.005)\n",
            "Train: 19 [1050/1562 ( 67%)]  Loss:  1.587561 (1.8988)  Time: 0.288s,  110.99/s  (0.289s,  110.56/s)  LR: 5.853e-05  Data: 0.004 (0.005)\n",
            "Train: 19 [1100/1562 ( 70%)]  Loss:  1.965307 (1.9008)  Time: 0.287s,  111.66/s  (0.289s,  110.59/s)  LR: 5.853e-05  Data: 0.004 (0.005)\n",
            "Train: 19 [1150/1562 ( 74%)]  Loss:  1.930278 (1.9094)  Time: 0.287s,  111.54/s  (0.289s,  110.60/s)  LR: 5.853e-05  Data: 0.004 (0.005)\n",
            "Train: 19 [1200/1562 ( 77%)]  Loss:  1.716933 (1.9144)  Time: 0.293s,  109.08/s  (0.289s,  110.63/s)  LR: 5.853e-05  Data: 0.004 (0.005)\n",
            "Train: 19 [1250/1562 ( 80%)]  Loss:  2.188799 (1.9134)  Time: 0.288s,  111.03/s  (0.289s,  110.65/s)  LR: 5.853e-05  Data: 0.004 (0.005)\n",
            "Train: 19 [1300/1562 ( 83%)]  Loss:  1.732346 (1.9165)  Time: 0.290s,  110.36/s  (0.289s,  110.67/s)  LR: 5.853e-05  Data: 0.004 (0.005)\n",
            "Train: 19 [1350/1562 ( 86%)]  Loss:  2.027616 (1.9186)  Time: 0.287s,  111.65/s  (0.289s,  110.69/s)  LR: 5.853e-05  Data: 0.004 (0.005)\n",
            "Train: 19 [1400/1562 ( 90%)]  Loss:  1.990224 (1.9131)  Time: 0.292s,  109.74/s  (0.289s,  110.70/s)  LR: 5.853e-05  Data: 0.009 (0.005)\n",
            "Train: 19 [1450/1562 ( 93%)]  Loss:  2.071378 (1.9151)  Time: 0.290s,  110.32/s  (0.289s,  110.72/s)  LR: 5.853e-05  Data: 0.004 (0.005)\n",
            "Train: 19 [1500/1562 ( 96%)]  Loss:  2.141078 (1.9166)  Time: 0.287s,  111.49/s  (0.289s,  110.74/s)  LR: 5.853e-05  Data: 0.004 (0.005)\n",
            "Train: 19 [1550/1562 ( 99%)]  Loss:  1.972641 (1.9143)  Time: 0.292s,  109.51/s  (0.289s,  110.76/s)  LR: 5.853e-05  Data: 0.003 (0.005)\n",
            "Train: 19 [1561/1562 (100%)]  Loss:  1.840743 (1.9127)  Time: 0.375s,   85.43/s  (0.289s,  110.75/s)  LR: 5.853e-05  Data: 0.089 (0.005)\n",
            "Test: [   0/312]  Time: 0.955 (0.955)  Loss:  1.3153 (1.3153)  Acc@1: 62.5000 (62.5000)  Acc@5: 96.8750 (96.8750)\n",
            "Test: [  50/312]  Time: 0.087 (0.112)  Loss:  0.6318 (0.9527)  Acc@1: 81.2500 (70.9559)  Acc@5: 100.0000 (97.1814)\n",
            "Test: [ 100/312]  Time: 0.087 (0.103)  Loss:  1.4583 (1.1493)  Acc@1: 43.7500 (61.7884)  Acc@5: 100.0000 (96.3800)\n",
            "Test: [ 150/312]  Time: 0.101 (0.099)  Loss:  1.2374 (1.1967)  Acc@1: 53.1250 (60.5132)  Acc@5: 100.0000 (96.5232)\n",
            "Test: [ 200/312]  Time: 0.093 (0.098)  Loss:  1.1555 (1.2161)  Acc@1: 65.6250 (59.6859)  Acc@5: 96.8750 (96.4241)\n",
            "Test: [ 250/312]  Time: 0.089 (0.097)  Loss:  0.7193 (1.1568)  Acc@1: 81.2500 (62.5249)  Acc@5: 100.0000 (96.4641)\n",
            "Test: [ 300/312]  Time: 0.088 (0.096)  Loss:  0.5163 (1.0849)  Acc@1: 87.5000 (65.6458)  Acc@5: 100.0000 (96.6674)\n",
            "Test: [ 312/312]  Time: 0.131 (0.096)  Loss:  0.6235 (1.0677)  Acc@1: 87.5000 (66.4200)  Acc@5: 100.0000 (96.7600)\n",
            "Test (EMA): [   0/312]  Time: 0.820 (0.820)  Loss:  1.6911 (1.6911)  Acc@1: 43.7500 (43.7500)  Acc@5: 93.7500 (93.7500)\n",
            "Test (EMA): [  50/312]  Time: 0.099 (0.112)  Loss:  1.6113 (1.4916)  Acc@1: 43.7500 (59.4975)  Acc@5: 96.8750 (94.1176)\n",
            "Test (EMA): [ 100/312]  Time: 0.097 (0.103)  Loss:  1.6551 (1.6452)  Acc@1: 40.6250 (43.2240)  Acc@5: 96.8750 (93.9047)\n",
            "Test (EMA): [ 150/312]  Time: 0.093 (0.099)  Loss:  1.7295 (1.6320)  Acc@1: 31.2500 (43.6465)  Acc@5: 100.0000 (94.5364)\n",
            "Test (EMA): [ 200/312]  Time: 0.107 (0.098)  Loss:  0.8971 (1.6374)  Acc@1: 90.6250 (41.5734)  Acc@5: 100.0000 (94.5118)\n",
            "Test (EMA): [ 250/312]  Time: 0.100 (0.097)  Loss:  1.3075 (1.6004)  Acc@1: 68.7500 (44.5468)  Acc@5: 93.7500 (93.3889)\n",
            "Test (EMA): [ 300/312]  Time: 0.086 (0.096)  Loss:  1.2650 (1.5637)  Acc@1: 78.1250 (48.2558)  Acc@5: 100.0000 (93.6669)\n",
            "Test (EMA): [ 312/312]  Time: 0.147 (0.096)  Loss:  1.5590 (1.5623)  Acc@1: 56.2500 (48.7000)  Acc@5: 87.5000 (93.7600)\n",
            "Current checkpoints:\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-19.pth.tar', 48.7)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-18.pth.tar', 46.37)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-17.pth.tar', 43.87)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-16.pth.tar', 41.0)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-15.pth.tar', 38.01)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-14.pth.tar', 34.77)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-13.pth.tar', 31.48)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-12.pth.tar', 28.32)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-11.pth.tar', 25.43)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-10.pth.tar', 22.99)\n",
            "\n",
            "Train: 20 [   0/1562 (  0%)]  Loss:  1.755961 (1.7560)  Time: 1.748s,   18.30/s  (1.748s,   18.30/s)  LR: 5.500e-05  Data: 1.227 (1.227)\n",
            "Train: 20 [  50/1562 (  3%)]  Loss:  1.779716 (1.9803)  Time: 0.287s,  111.62/s  (0.321s,   99.63/s)  LR: 5.500e-05  Data: 0.004 (0.028)\n",
            "Train: 20 [ 100/1562 (  6%)]  Loss:  1.754389 (1.9280)  Time: 0.288s,  111.03/s  (0.304s,  105.09/s)  LR: 5.500e-05  Data: 0.004 (0.016)\n",
            "Train: 20 [ 150/1562 ( 10%)]  Loss:  2.032070 (1.9252)  Time: 0.287s,  111.65/s  (0.299s,  107.08/s)  LR: 5.500e-05  Data: 0.004 (0.012)\n",
            "Train: 20 [ 200/1562 ( 13%)]  Loss:  2.034677 (1.9082)  Time: 0.287s,  111.51/s  (0.296s,  108.10/s)  LR: 5.500e-05  Data: 0.004 (0.010)\n",
            "Train: 20 [ 250/1562 ( 16%)]  Loss:  1.825066 (1.9037)  Time: 0.293s,  109.31/s  (0.294s,  108.68/s)  LR: 5.500e-05  Data: 0.004 (0.009)\n",
            "Train: 20 [ 300/1562 ( 19%)]  Loss:  2.036903 (1.9064)  Time: 0.287s,  111.58/s  (0.293s,  109.09/s)  LR: 5.500e-05  Data: 0.004 (0.008)\n",
            "Train: 20 [ 350/1562 ( 22%)]  Loss:  1.903447 (1.8859)  Time: 0.287s,  111.58/s  (0.292s,  109.43/s)  LR: 5.500e-05  Data: 0.004 (0.007)\n",
            "Train: 20 [ 400/1562 ( 26%)]  Loss:  2.303448 (1.8742)  Time: 0.287s,  111.53/s  (0.292s,  109.60/s)  LR: 5.500e-05  Data: 0.004 (0.007)\n",
            "Train: 20 [ 450/1562 ( 29%)]  Loss:  2.111330 (1.8716)  Time: 0.286s,  111.86/s  (0.292s,  109.76/s)  LR: 5.500e-05  Data: 0.004 (0.007)\n",
            "Train: 20 [ 500/1562 ( 32%)]  Loss:  1.809401 (1.8687)  Time: 0.286s,  111.71/s  (0.291s,  109.91/s)  LR: 5.500e-05  Data: 0.004 (0.006)\n",
            "Train: 20 [ 550/1562 ( 35%)]  Loss:  1.701049 (1.8631)  Time: 0.287s,  111.56/s  (0.291s,  110.01/s)  LR: 5.500e-05  Data: 0.004 (0.006)\n",
            "Train: 20 [ 600/1562 ( 38%)]  Loss:  2.003344 (1.8564)  Time: 0.286s,  111.77/s  (0.291s,  110.11/s)  LR: 5.500e-05  Data: 0.004 (0.006)\n",
            "Train: 20 [ 650/1562 ( 42%)]  Loss:  1.854208 (1.8597)  Time: 0.287s,  111.40/s  (0.290s,  110.19/s)  LR: 5.500e-05  Data: 0.004 (0.006)\n",
            "Train: 20 [ 700/1562 ( 45%)]  Loss:  1.508086 (1.8624)  Time: 0.294s,  108.72/s  (0.290s,  110.26/s)  LR: 5.500e-05  Data: 0.004 (0.006)\n",
            "Train: 20 [ 750/1562 ( 48%)]  Loss:  1.694485 (1.8703)  Time: 0.287s,  111.52/s  (0.290s,  110.30/s)  LR: 5.500e-05  Data: 0.004 (0.006)\n",
            "Train: 20 [ 800/1562 ( 51%)]  Loss:  1.887413 (1.8756)  Time: 0.287s,  111.58/s  (0.290s,  110.36/s)  LR: 5.500e-05  Data: 0.004 (0.005)\n",
            "Train: 20 [ 850/1562 ( 54%)]  Loss:  2.002157 (1.8829)  Time: 0.294s,  108.76/s  (0.290s,  110.41/s)  LR: 5.500e-05  Data: 0.004 (0.005)\n",
            "Train: 20 [ 900/1562 ( 58%)]  Loss:  1.727841 (1.8864)  Time: 0.290s,  110.46/s  (0.290s,  110.45/s)  LR: 5.500e-05  Data: 0.004 (0.005)\n",
            "Train: 20 [ 950/1562 ( 61%)]  Loss:  1.574416 (1.8837)  Time: 0.296s,  108.00/s  (0.290s,  110.49/s)  LR: 5.500e-05  Data: 0.004 (0.005)\n",
            "Train: 20 [1000/1562 ( 64%)]  Loss:  2.225737 (1.8871)  Time: 0.287s,  111.43/s  (0.290s,  110.53/s)  LR: 5.500e-05  Data: 0.004 (0.005)\n",
            "Train: 20 [1050/1562 ( 67%)]  Loss:  1.596076 (1.8912)  Time: 0.287s,  111.60/s  (0.289s,  110.57/s)  LR: 5.500e-05  Data: 0.004 (0.005)\n",
            "Train: 20 [1100/1562 ( 70%)]  Loss:  1.958403 (1.8933)  Time: 0.290s,  110.43/s  (0.289s,  110.58/s)  LR: 5.500e-05  Data: 0.007 (0.005)\n",
            "Train: 20 [1150/1562 ( 74%)]  Loss:  2.106101 (1.9011)  Time: 0.287s,  111.63/s  (0.289s,  110.60/s)  LR: 5.500e-05  Data: 0.004 (0.005)\n",
            "Train: 20 [1200/1562 ( 77%)]  Loss:  1.834273 (1.9070)  Time: 0.287s,  111.61/s  (0.289s,  110.63/s)  LR: 5.500e-05  Data: 0.004 (0.005)\n",
            "Train: 20 [1250/1562 ( 80%)]  Loss:  2.060384 (1.9063)  Time: 0.294s,  108.92/s  (0.289s,  110.65/s)  LR: 5.500e-05  Data: 0.004 (0.005)\n",
            "Train: 20 [1300/1562 ( 83%)]  Loss:  1.748443 (1.9095)  Time: 0.287s,  111.56/s  (0.289s,  110.67/s)  LR: 5.500e-05  Data: 0.004 (0.005)\n",
            "Train: 20 [1350/1562 ( 86%)]  Loss:  2.088930 (1.9111)  Time: 0.287s,  111.64/s  (0.289s,  110.68/s)  LR: 5.500e-05  Data: 0.004 (0.005)\n",
            "Train: 20 [1400/1562 ( 90%)]  Loss:  2.108523 (1.9070)  Time: 0.286s,  111.74/s  (0.289s,  110.69/s)  LR: 5.500e-05  Data: 0.004 (0.005)\n",
            "Train: 20 [1450/1562 ( 93%)]  Loss:  2.117454 (1.9091)  Time: 0.287s,  111.46/s  (0.289s,  110.70/s)  LR: 5.500e-05  Data: 0.004 (0.005)\n",
            "Train: 20 [1500/1562 ( 96%)]  Loss:  1.972778 (1.9111)  Time: 0.290s,  110.39/s  (0.289s,  110.72/s)  LR: 5.500e-05  Data: 0.004 (0.005)\n",
            "Train: 20 [1550/1562 ( 99%)]  Loss:  1.523739 (1.9092)  Time: 0.285s,  112.19/s  (0.289s,  110.74/s)  LR: 5.500e-05  Data: 0.003 (0.005)\n",
            "Train: 20 [1561/1562 (100%)]  Loss:  1.701294 (1.9077)  Time: 0.369s,   86.70/s  (0.289s,  110.73/s)  LR: 5.500e-05  Data: 0.089 (0.005)\n",
            "Test: [   0/312]  Time: 0.992 (0.992)  Loss:  1.2790 (1.2790)  Acc@1: 59.3750 (59.3750)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [  50/312]  Time: 0.094 (0.114)  Loss:  0.5870 (0.8533)  Acc@1: 81.2500 (73.8971)  Acc@5: 100.0000 (98.5294)\n",
            "Test: [ 100/312]  Time: 0.097 (0.103)  Loss:  1.4154 (1.1001)  Acc@1: 50.0000 (63.3045)  Acc@5: 96.8750 (96.6275)\n",
            "Test: [ 150/312]  Time: 0.088 (0.100)  Loss:  1.6529 (1.2131)  Acc@1: 40.6250 (58.4230)  Acc@5: 100.0000 (96.5232)\n",
            "Test: [ 200/312]  Time: 0.094 (0.098)  Loss:  0.9686 (1.1896)  Acc@1: 71.8750 (59.7481)  Acc@5: 96.8750 (96.3619)\n",
            "Test: [ 250/312]  Time: 0.087 (0.097)  Loss:  0.7199 (1.1128)  Acc@1: 84.3750 (63.3591)  Acc@5: 100.0000 (96.4766)\n",
            "Test: [ 300/312]  Time: 0.086 (0.096)  Loss:  0.4176 (1.0490)  Acc@1: 90.6250 (66.1545)  Acc@5: 100.0000 (96.6985)\n",
            "Test: [ 312/312]  Time: 0.139 (0.096)  Loss:  0.5133 (1.0297)  Acc@1: 87.5000 (67.0300)  Acc@5: 100.0000 (96.7700)\n",
            "Test (EMA): [   0/312]  Time: 0.933 (0.933)  Loss:  1.6574 (1.6574)  Acc@1: 40.6250 (40.6250)  Acc@5: 93.7500 (93.7500)\n",
            "Test (EMA): [  50/312]  Time: 0.093 (0.114)  Loss:  1.5326 (1.4343)  Acc@1: 43.7500 (61.2132)  Acc@5: 100.0000 (94.5466)\n",
            "Test (EMA): [ 100/312]  Time: 0.094 (0.103)  Loss:  1.6199 (1.5976)  Acc@1: 46.8750 (45.8849)  Acc@5: 96.8750 (94.0903)\n",
            "Test (EMA): [ 150/312]  Time: 0.098 (0.100)  Loss:  1.7241 (1.5916)  Acc@1: 28.1250 (46.1093)  Acc@5: 100.0000 (94.7227)\n",
            "Test (EMA): [ 200/312]  Time: 0.095 (0.098)  Loss:  0.8858 (1.5986)  Acc@1: 90.6250 (43.8899)  Acc@5: 100.0000 (94.7295)\n",
            "Test (EMA): [ 250/312]  Time: 0.095 (0.097)  Loss:  1.2666 (1.5575)  Acc@1: 68.7500 (46.8999)  Acc@5: 93.7500 (93.7998)\n",
            "Test (EMA): [ 300/312]  Time: 0.086 (0.096)  Loss:  1.1772 (1.5191)  Acc@1: 81.2500 (50.4049)  Acc@5: 100.0000 (94.1445)\n",
            "Test (EMA): [ 312/312]  Time: 0.132 (0.096)  Loss:  1.4826 (1.5161)  Acc@1: 56.2500 (50.8300)  Acc@5: 87.5000 (94.2300)\n",
            "Current checkpoints:\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-20.pth.tar', 50.83)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-19.pth.tar', 48.7)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-18.pth.tar', 46.37)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-17.pth.tar', 43.87)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-16.pth.tar', 41.0)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-15.pth.tar', 38.01)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-14.pth.tar', 34.77)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-13.pth.tar', 31.48)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-12.pth.tar', 28.32)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-11.pth.tar', 25.43)\n",
            "\n",
            "Train: 21 [   0/1562 (  0%)]  Loss:  1.577025 (1.5770)  Time: 1.801s,   17.77/s  (1.801s,   17.77/s)  LR: 5.147e-05  Data: 1.328 (1.328)\n",
            "Train: 21 [  50/1562 (  3%)]  Loss:  1.613006 (1.9165)  Time: 0.290s,  110.37/s  (0.320s,   99.97/s)  LR: 5.147e-05  Data: 0.007 (0.030)\n",
            "Train: 21 [ 100/1562 (  6%)]  Loss:  1.761010 (1.8900)  Time: 0.287s,  111.54/s  (0.304s,  105.18/s)  LR: 5.147e-05  Data: 0.004 (0.017)\n",
            "Train: 21 [ 150/1562 ( 10%)]  Loss:  2.170332 (1.8957)  Time: 0.291s,  109.83/s  (0.299s,  107.01/s)  LR: 5.147e-05  Data: 0.004 (0.013)\n",
            "Train: 21 [ 200/1562 ( 13%)]  Loss:  2.041788 (1.8877)  Time: 0.287s,  111.68/s  (0.296s,  108.03/s)  LR: 5.147e-05  Data: 0.004 (0.011)\n",
            "Train: 21 [ 250/1562 ( 16%)]  Loss:  1.654563 (1.8873)  Time: 0.286s,  111.93/s  (0.295s,  108.63/s)  LR: 5.147e-05  Data: 0.004 (0.009)\n",
            "Train: 21 [ 300/1562 ( 19%)]  Loss:  1.965735 (1.8870)  Time: 0.287s,  111.40/s  (0.294s,  109.03/s)  LR: 5.147e-05  Data: 0.004 (0.008)\n",
            "Train: 21 [ 350/1562 ( 22%)]  Loss:  1.691479 (1.8682)  Time: 0.287s,  111.39/s  (0.293s,  109.35/s)  LR: 5.147e-05  Data: 0.004 (0.008)\n",
            "Train: 21 [ 400/1562 ( 26%)]  Loss:  2.133971 (1.8592)  Time: 0.286s,  112.01/s  (0.292s,  109.60/s)  LR: 5.147e-05  Data: 0.004 (0.007)\n",
            "Train: 21 [ 450/1562 ( 29%)]  Loss:  2.128544 (1.8593)  Time: 0.287s,  111.68/s  (0.291s,  109.80/s)  LR: 5.147e-05  Data: 0.004 (0.007)\n",
            "Train: 21 [ 500/1562 ( 32%)]  Loss:  1.685450 (1.8616)  Time: 0.286s,  111.70/s  (0.291s,  109.93/s)  LR: 5.147e-05  Data: 0.004 (0.007)\n",
            "Train: 21 [ 550/1562 ( 35%)]  Loss:  1.771007 (1.8558)  Time: 0.290s,  110.45/s  (0.291s,  110.04/s)  LR: 5.147e-05  Data: 0.004 (0.006)\n",
            "Train: 21 [ 600/1562 ( 38%)]  Loss:  1.910291 (1.8518)  Time: 0.288s,  111.20/s  (0.291s,  110.12/s)  LR: 5.147e-05  Data: 0.004 (0.006)\n",
            "Train: 21 [ 650/1562 ( 42%)]  Loss:  1.443163 (1.8533)  Time: 0.291s,  109.88/s  (0.290s,  110.21/s)  LR: 5.147e-05  Data: 0.004 (0.006)\n",
            "Train: 21 [ 700/1562 ( 45%)]  Loss:  1.595286 (1.8562)  Time: 0.286s,  111.81/s  (0.290s,  110.29/s)  LR: 5.147e-05  Data: 0.004 (0.006)\n",
            "Train: 21 [ 750/1562 ( 48%)]  Loss:  1.703439 (1.8608)  Time: 0.286s,  111.88/s  (0.290s,  110.33/s)  LR: 5.147e-05  Data: 0.004 (0.006)\n",
            "Train: 21 [ 800/1562 ( 51%)]  Loss:  1.393945 (1.8645)  Time: 0.287s,  111.66/s  (0.290s,  110.40/s)  LR: 5.147e-05  Data: 0.004 (0.006)\n",
            "Train: 21 [ 850/1562 ( 54%)]  Loss:  2.027247 (1.8713)  Time: 0.286s,  111.95/s  (0.290s,  110.44/s)  LR: 5.147e-05  Data: 0.004 (0.005)\n",
            "Train: 21 [ 900/1562 ( 58%)]  Loss:  1.805632 (1.8752)  Time: 0.286s,  111.81/s  (0.290s,  110.48/s)  LR: 5.147e-05  Data: 0.004 (0.005)\n",
            "Train: 21 [ 950/1562 ( 61%)]  Loss:  1.811102 (1.8739)  Time: 0.287s,  111.58/s  (0.290s,  110.52/s)  LR: 5.147e-05  Data: 0.004 (0.005)\n",
            "Train: 21 [1000/1562 ( 64%)]  Loss:  1.986193 (1.8748)  Time: 0.286s,  111.87/s  (0.289s,  110.55/s)  LR: 5.147e-05  Data: 0.004 (0.005)\n",
            "Train: 21 [1050/1562 ( 67%)]  Loss:  1.835553 (1.8804)  Time: 0.287s,  111.66/s  (0.289s,  110.58/s)  LR: 5.147e-05  Data: 0.004 (0.005)\n",
            "Train: 21 [1100/1562 ( 70%)]  Loss:  1.867333 (1.8827)  Time: 0.287s,  111.55/s  (0.289s,  110.61/s)  LR: 5.147e-05  Data: 0.004 (0.005)\n",
            "Train: 21 [1150/1562 ( 74%)]  Loss:  2.118900 (1.8912)  Time: 0.289s,  110.84/s  (0.289s,  110.64/s)  LR: 5.147e-05  Data: 0.004 (0.005)\n",
            "Train: 21 [1200/1562 ( 77%)]  Loss:  1.505932 (1.8980)  Time: 0.290s,  110.38/s  (0.289s,  110.66/s)  LR: 5.147e-05  Data: 0.004 (0.005)\n",
            "Train: 21 [1250/1562 ( 80%)]  Loss:  1.944999 (1.8964)  Time: 0.286s,  111.91/s  (0.289s,  110.69/s)  LR: 5.147e-05  Data: 0.004 (0.005)\n",
            "Train: 21 [1300/1562 ( 83%)]  Loss:  1.745015 (1.8996)  Time: 0.287s,  111.41/s  (0.289s,  110.70/s)  LR: 5.147e-05  Data: 0.004 (0.005)\n",
            "Train: 21 [1350/1562 ( 86%)]  Loss:  1.937690 (1.9015)  Time: 0.286s,  111.87/s  (0.289s,  110.71/s)  LR: 5.147e-05  Data: 0.004 (0.005)\n",
            "Train: 21 [1400/1562 ( 90%)]  Loss:  2.132731 (1.8968)  Time: 0.287s,  111.55/s  (0.289s,  110.71/s)  LR: 5.147e-05  Data: 0.004 (0.005)\n",
            "Train: 21 [1450/1562 ( 93%)]  Loss:  2.077158 (1.8983)  Time: 0.287s,  111.51/s  (0.289s,  110.73/s)  LR: 5.147e-05  Data: 0.004 (0.005)\n",
            "Train: 21 [1500/1562 ( 96%)]  Loss:  2.023502 (1.9007)  Time: 0.287s,  111.66/s  (0.289s,  110.74/s)  LR: 5.147e-05  Data: 0.004 (0.005)\n",
            "Train: 21 [1550/1562 ( 99%)]  Loss:  1.903754 (1.8992)  Time: 0.284s,  112.68/s  (0.289s,  110.76/s)  LR: 5.147e-05  Data: 0.004 (0.005)\n",
            "Train: 21 [1561/1562 (100%)]  Loss:  1.946662 (1.8976)  Time: 0.369s,   86.76/s  (0.289s,  110.75/s)  LR: 5.147e-05  Data: 0.088 (0.005)\n",
            "Test: [   0/312]  Time: 0.941 (0.941)  Loss:  1.2710 (1.2710)  Acc@1: 50.0000 (50.0000)  Acc@5: 96.8750 (96.8750)\n",
            "Test: [  50/312]  Time: 0.092 (0.114)  Loss:  0.5238 (0.8501)  Acc@1: 84.3750 (74.0809)  Acc@5: 100.0000 (98.2843)\n",
            "Test: [ 100/312]  Time: 0.087 (0.104)  Loss:  1.6813 (1.1836)  Acc@1: 34.3750 (58.9109)  Acc@5: 93.7500 (96.0087)\n",
            "Test: [ 150/312]  Time: 0.093 (0.100)  Loss:  1.5432 (1.2815)  Acc@1: 43.7500 (53.9942)  Acc@5: 100.0000 (95.7781)\n",
            "Test: [ 200/312]  Time: 0.093 (0.098)  Loss:  0.7115 (1.2394)  Acc@1: 81.2500 (56.7164)  Acc@5: 100.0000 (95.8022)\n",
            "Test: [ 250/312]  Time: 0.095 (0.097)  Loss:  0.6916 (1.1296)  Acc@1: 87.5000 (61.9273)  Acc@5: 96.8750 (96.1529)\n",
            "Test: [ 300/312]  Time: 0.086 (0.096)  Loss:  0.4449 (1.0678)  Acc@1: 81.2500 (64.4622)  Acc@5: 100.0000 (96.3870)\n",
            "Test: [ 312/312]  Time: 0.132 (0.096)  Loss:  0.6417 (1.0515)  Acc@1: 75.0000 (65.1000)  Acc@5: 100.0000 (96.5100)\n",
            "Test (EMA): [   0/312]  Time: 0.963 (0.963)  Loss:  1.6293 (1.6293)  Acc@1: 40.6250 (40.6250)  Acc@5: 93.7500 (93.7500)\n",
            "Test (EMA): [  50/312]  Time: 0.093 (0.114)  Loss:  1.4575 (1.3823)  Acc@1: 43.7500 (62.8676)  Acc@5: 100.0000 (94.9142)\n",
            "Test (EMA): [ 100/312]  Time: 0.086 (0.103)  Loss:  1.5857 (1.5526)  Acc@1: 50.0000 (47.9579)  Acc@5: 96.8750 (94.3998)\n",
            "Test (EMA): [ 150/312]  Time: 0.092 (0.100)  Loss:  1.7206 (1.5536)  Acc@1: 31.2500 (48.0339)  Acc@5: 100.0000 (94.9503)\n",
            "Test (EMA): [ 200/312]  Time: 0.087 (0.098)  Loss:  0.8713 (1.5617)  Acc@1: 90.6250 (45.7400)  Acc@5: 100.0000 (94.9471)\n",
            "Test (EMA): [ 250/312]  Time: 0.089 (0.097)  Loss:  1.2283 (1.5168)  Acc@1: 68.7500 (48.8172)  Acc@5: 93.7500 (94.1609)\n",
            "Test (EMA): [ 300/312]  Time: 0.086 (0.096)  Loss:  1.0953 (1.4767)  Acc@1: 84.3750 (52.3256)  Acc@5: 100.0000 (94.4871)\n",
            "Test (EMA): [ 312/312]  Time: 0.136 (0.096)  Loss:  1.4091 (1.4723)  Acc@1: 68.7500 (52.8000)  Acc@5: 93.7500 (94.5900)\n",
            "Current checkpoints:\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-21.pth.tar', 52.8)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-20.pth.tar', 50.83)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-19.pth.tar', 48.7)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-18.pth.tar', 46.37)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-17.pth.tar', 43.87)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-16.pth.tar', 41.0)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-15.pth.tar', 38.01)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-14.pth.tar', 34.77)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-13.pth.tar', 31.48)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-12.pth.tar', 28.32)\n",
            "\n",
            "Train: 22 [   0/1562 (  0%)]  Loss:  1.669943 (1.6699)  Time: 1.670s,   19.16/s  (1.670s,   19.16/s)  LR: 4.796e-05  Data: 1.187 (1.187)\n",
            "Train: 22 [  50/1562 (  3%)]  Loss:  1.690623 (1.9453)  Time: 0.287s,  111.60/s  (0.318s,  100.53/s)  LR: 4.796e-05  Data: 0.004 (0.027)\n",
            "Train: 22 [ 100/1562 (  6%)]  Loss:  1.693510 (1.8760)  Time: 0.292s,  109.46/s  (0.303s,  105.58/s)  LR: 4.796e-05  Data: 0.004 (0.016)\n",
            "Train: 22 [ 150/1562 ( 10%)]  Loss:  2.257807 (1.8891)  Time: 0.287s,  111.55/s  (0.298s,  107.42/s)  LR: 4.796e-05  Data: 0.004 (0.012)\n",
            "Train: 22 [ 200/1562 ( 13%)]  Loss:  1.956132 (1.8776)  Time: 0.286s,  111.84/s  (0.295s,  108.32/s)  LR: 4.796e-05  Data: 0.004 (0.010)\n",
            "Train: 22 [ 250/1562 ( 16%)]  Loss:  1.656689 (1.8714)  Time: 0.287s,  111.31/s  (0.294s,  108.87/s)  LR: 4.796e-05  Data: 0.004 (0.009)\n",
            "Train: 22 [ 300/1562 ( 19%)]  Loss:  1.897161 (1.8800)  Time: 0.286s,  111.80/s  (0.293s,  109.22/s)  LR: 4.796e-05  Data: 0.004 (0.008)\n",
            "Train: 22 [ 350/1562 ( 22%)]  Loss:  1.950797 (1.8639)  Time: 0.286s,  111.70/s  (0.292s,  109.48/s)  LR: 4.796e-05  Data: 0.004 (0.007)\n",
            "Train: 22 [ 400/1562 ( 26%)]  Loss:  2.216200 (1.8538)  Time: 0.286s,  111.98/s  (0.292s,  109.70/s)  LR: 4.796e-05  Data: 0.004 (0.007)\n",
            "Train: 22 [ 450/1562 ( 29%)]  Loss:  1.946647 (1.8568)  Time: 0.286s,  111.78/s  (0.291s,  109.88/s)  LR: 4.796e-05  Data: 0.004 (0.007)\n",
            "Train: 22 [ 500/1562 ( 32%)]  Loss:  1.711780 (1.8571)  Time: 0.287s,  111.49/s  (0.291s,  110.01/s)  LR: 4.796e-05  Data: 0.004 (0.006)\n",
            "Train: 22 [ 550/1562 ( 35%)]  Loss:  1.733268 (1.8537)  Time: 0.287s,  111.67/s  (0.291s,  110.11/s)  LR: 4.796e-05  Data: 0.004 (0.006)\n",
            "Train: 22 [ 600/1562 ( 38%)]  Loss:  2.257496 (1.8469)  Time: 0.286s,  111.77/s  (0.290s,  110.21/s)  LR: 4.796e-05  Data: 0.004 (0.006)\n",
            "Train: 22 [ 650/1562 ( 42%)]  Loss:  1.821203 (1.8496)  Time: 0.287s,  111.49/s  (0.290s,  110.29/s)  LR: 4.796e-05  Data: 0.004 (0.006)\n",
            "Train: 22 [ 700/1562 ( 45%)]  Loss:  1.746883 (1.8510)  Time: 0.286s,  111.85/s  (0.290s,  110.38/s)  LR: 4.796e-05  Data: 0.004 (0.006)\n",
            "Train: 22 [ 750/1562 ( 48%)]  Loss:  1.659382 (1.8560)  Time: 0.287s,  111.42/s  (0.290s,  110.44/s)  LR: 4.796e-05  Data: 0.004 (0.005)\n",
            "Train: 22 [ 800/1562 ( 51%)]  Loss:  1.656333 (1.8570)  Time: 0.286s,  111.81/s  (0.290s,  110.50/s)  LR: 4.796e-05  Data: 0.004 (0.005)\n",
            "Train: 22 [ 850/1562 ( 54%)]  Loss:  2.173443 (1.8660)  Time: 0.286s,  111.72/s  (0.289s,  110.55/s)  LR: 4.796e-05  Data: 0.004 (0.005)\n",
            "Train: 22 [ 900/1562 ( 58%)]  Loss:  1.921683 (1.8692)  Time: 0.290s,  110.25/s  (0.289s,  110.60/s)  LR: 4.796e-05  Data: 0.004 (0.005)\n",
            "Train: 22 [ 950/1562 ( 61%)]  Loss:  1.731552 (1.8689)  Time: 0.288s,  111.28/s  (0.289s,  110.63/s)  LR: 4.796e-05  Data: 0.004 (0.005)\n",
            "Train: 22 [1000/1562 ( 64%)]  Loss:  2.484028 (1.8709)  Time: 0.290s,  110.44/s  (0.289s,  110.64/s)  LR: 4.796e-05  Data: 0.007 (0.005)\n",
            "Train: 22 [1050/1562 ( 67%)]  Loss:  1.645905 (1.8769)  Time: 0.286s,  111.80/s  (0.289s,  110.67/s)  LR: 4.796e-05  Data: 0.004 (0.005)\n",
            "Train: 22 [1100/1562 ( 70%)]  Loss:  1.951003 (1.8788)  Time: 0.286s,  111.72/s  (0.289s,  110.69/s)  LR: 4.796e-05  Data: 0.004 (0.005)\n",
            "Train: 22 [1150/1562 ( 74%)]  Loss:  2.093433 (1.8880)  Time: 0.287s,  111.64/s  (0.289s,  110.71/s)  LR: 4.796e-05  Data: 0.004 (0.005)\n",
            "Train: 22 [1200/1562 ( 77%)]  Loss:  1.487442 (1.8940)  Time: 0.287s,  111.54/s  (0.289s,  110.73/s)  LR: 4.796e-05  Data: 0.004 (0.005)\n",
            "Train: 22 [1250/1562 ( 80%)]  Loss:  2.033381 (1.8931)  Time: 0.286s,  111.81/s  (0.289s,  110.74/s)  LR: 4.796e-05  Data: 0.004 (0.005)\n",
            "Train: 22 [1300/1562 ( 83%)]  Loss:  1.933664 (1.8951)  Time: 0.286s,  111.73/s  (0.289s,  110.76/s)  LR: 4.796e-05  Data: 0.004 (0.005)\n",
            "Train: 22 [1350/1562 ( 86%)]  Loss:  1.823481 (1.8971)  Time: 0.287s,  111.35/s  (0.289s,  110.77/s)  LR: 4.796e-05  Data: 0.004 (0.005)\n",
            "Train: 22 [1400/1562 ( 90%)]  Loss:  2.101369 (1.8925)  Time: 0.291s,  109.95/s  (0.289s,  110.78/s)  LR: 4.796e-05  Data: 0.004 (0.005)\n",
            "Train: 22 [1450/1562 ( 93%)]  Loss:  1.952197 (1.8947)  Time: 0.287s,  111.59/s  (0.289s,  110.80/s)  LR: 4.796e-05  Data: 0.004 (0.005)\n",
            "Train: 22 [1500/1562 ( 96%)]  Loss:  2.068275 (1.8958)  Time: 0.294s,  108.89/s  (0.289s,  110.80/s)  LR: 4.796e-05  Data: 0.004 (0.005)\n",
            "Train: 22 [1550/1562 ( 99%)]  Loss:  1.801204 (1.8947)  Time: 0.284s,  112.83/s  (0.289s,  110.82/s)  LR: 4.796e-05  Data: 0.004 (0.005)\n",
            "Train: 22 [1561/1562 (100%)]  Loss:  1.826054 (1.8935)  Time: 0.370s,   86.39/s  (0.289s,  110.81/s)  LR: 4.796e-05  Data: 0.090 (0.005)\n",
            "Test: [   0/312]  Time: 0.872 (0.872)  Loss:  1.1204 (1.1204)  Acc@1: 65.6250 (65.6250)  Acc@5: 96.8750 (96.8750)\n",
            "Test: [  50/312]  Time: 0.087 (0.111)  Loss:  0.6985 (0.7912)  Acc@1: 84.3750 (76.1642)  Acc@5: 100.0000 (98.7745)\n",
            "Test: [ 100/312]  Time: 0.086 (0.102)  Loss:  1.3359 (1.1097)  Acc@1: 46.8750 (62.3144)  Acc@5: 96.8750 (96.2871)\n",
            "Test: [ 150/312]  Time: 0.100 (0.099)  Loss:  1.4802 (1.1590)  Acc@1: 50.0000 (61.1134)  Acc@5: 100.0000 (96.5439)\n",
            "Test: [ 200/312]  Time: 0.095 (0.098)  Loss:  0.7127 (1.1760)  Acc@1: 87.5000 (59.8103)  Acc@5: 100.0000 (96.2376)\n",
            "Test: [ 250/312]  Time: 0.087 (0.097)  Loss:  0.5627 (1.1116)  Acc@1: 87.5000 (62.9731)  Acc@5: 100.0000 (96.2027)\n",
            "Test: [ 300/312]  Time: 0.087 (0.096)  Loss:  0.3192 (1.0329)  Acc@1: 93.7500 (66.2272)  Acc@5: 100.0000 (96.5739)\n",
            "Test: [ 312/312]  Time: 0.132 (0.096)  Loss:  0.5052 (1.0134)  Acc@1: 87.5000 (67.0600)  Acc@5: 100.0000 (96.6900)\n",
            "Test (EMA): [   0/312]  Time: 0.948 (0.948)  Loss:  1.5958 (1.5958)  Acc@1: 43.7500 (43.7500)  Acc@5: 96.8750 (96.8750)\n",
            "Test (EMA): [  50/312]  Time: 0.086 (0.113)  Loss:  1.3859 (1.3303)  Acc@1: 50.0000 (64.7059)  Acc@5: 100.0000 (95.4044)\n",
            "Test (EMA): [ 100/312]  Time: 0.094 (0.103)  Loss:  1.5552 (1.5096)  Acc@1: 53.1250 (50.0309)  Acc@5: 96.8750 (94.7092)\n",
            "Test (EMA): [ 150/312]  Time: 0.092 (0.100)  Loss:  1.7148 (1.5172)  Acc@1: 34.3750 (50.0000)  Acc@5: 100.0000 (95.1780)\n",
            "Test (EMA): [ 200/312]  Time: 0.093 (0.098)  Loss:  0.8572 (1.5267)  Acc@1: 87.5000 (47.6057)  Acc@5: 100.0000 (95.1959)\n",
            "Test (EMA): [ 250/312]  Time: 0.096 (0.097)  Loss:  1.1938 (1.4778)  Acc@1: 68.7500 (50.8093)  Acc@5: 93.7500 (94.6340)\n",
            "Test (EMA): [ 300/312]  Time: 0.086 (0.096)  Loss:  1.0184 (1.4364)  Acc@1: 84.3750 (54.1632)  Acc@5: 100.0000 (94.8920)\n",
            "Test (EMA): [ 312/312]  Time: 0.138 (0.096)  Loss:  1.3386 (1.4306)  Acc@1: 68.7500 (54.7200)  Acc@5: 93.7500 (95.0100)\n",
            "Current checkpoints:\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-22.pth.tar', 54.72)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-21.pth.tar', 52.8)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-20.pth.tar', 50.83)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-19.pth.tar', 48.7)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-18.pth.tar', 46.37)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-17.pth.tar', 43.87)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-16.pth.tar', 41.0)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-15.pth.tar', 38.01)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-14.pth.tar', 34.77)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-13.pth.tar', 31.48)\n",
            "\n",
            "Train: 23 [   0/1562 (  0%)]  Loss:  1.690922 (1.6909)  Time: 1.694s,   18.89/s  (1.694s,   18.89/s)  LR: 4.449e-05  Data: 1.163 (1.163)\n",
            "Train: 23 [  50/1562 (  3%)]  Loss:  1.659879 (1.9391)  Time: 0.286s,  111.90/s  (0.320s,  100.02/s)  LR: 4.449e-05  Data: 0.004 (0.027)\n",
            "Train: 23 [ 100/1562 (  6%)]  Loss:  1.542772 (1.8835)  Time: 0.286s,  111.75/s  (0.304s,  105.23/s)  LR: 4.449e-05  Data: 0.004 (0.015)\n",
            "Train: 23 [ 150/1562 ( 10%)]  Loss:  1.882146 (1.9087)  Time: 0.286s,  111.88/s  (0.298s,  107.21/s)  LR: 4.449e-05  Data: 0.004 (0.012)\n",
            "Train: 23 [ 200/1562 ( 13%)]  Loss:  1.901493 (1.8870)  Time: 0.291s,  110.04/s  (0.296s,  108.21/s)  LR: 4.449e-05  Data: 0.004 (0.010)\n",
            "Train: 23 [ 250/1562 ( 16%)]  Loss:  1.676890 (1.8772)  Time: 0.287s,  111.49/s  (0.294s,  108.84/s)  LR: 4.449e-05  Data: 0.004 (0.009)\n",
            "Train: 23 [ 300/1562 ( 19%)]  Loss:  2.202317 (1.8827)  Time: 0.288s,  111.09/s  (0.293s,  109.19/s)  LR: 4.449e-05  Data: 0.004 (0.008)\n",
            "Train: 23 [ 350/1562 ( 22%)]  Loss:  2.036275 (1.8642)  Time: 0.287s,  111.43/s  (0.292s,  109.49/s)  LR: 4.449e-05  Data: 0.004 (0.007)\n",
            "Train: 23 [ 400/1562 ( 26%)]  Loss:  2.043383 (1.8517)  Time: 0.291s,  109.80/s  (0.292s,  109.69/s)  LR: 4.449e-05  Data: 0.004 (0.007)\n",
            "Train: 23 [ 450/1562 ( 29%)]  Loss:  1.902888 (1.8489)  Time: 0.290s,  110.49/s  (0.291s,  109.86/s)  LR: 4.449e-05  Data: 0.004 (0.006)\n",
            "Train: 23 [ 500/1562 ( 32%)]  Loss:  1.746106 (1.8514)  Time: 0.288s,  111.14/s  (0.291s,  110.01/s)  LR: 4.449e-05  Data: 0.004 (0.006)\n",
            "Train: 23 [ 550/1562 ( 35%)]  Loss:  1.799800 (1.8465)  Time: 0.287s,  111.60/s  (0.291s,  110.12/s)  LR: 4.449e-05  Data: 0.004 (0.006)\n",
            "Train: 23 [ 600/1562 ( 38%)]  Loss:  2.037510 (1.8431)  Time: 0.289s,  110.57/s  (0.290s,  110.20/s)  LR: 4.449e-05  Data: 0.004 (0.006)\n",
            "Train: 23 [ 650/1562 ( 42%)]  Loss:  1.745285 (1.8465)  Time: 0.287s,  111.57/s  (0.290s,  110.28/s)  LR: 4.449e-05  Data: 0.004 (0.006)\n",
            "Train: 23 [ 700/1562 ( 45%)]  Loss:  1.640972 (1.8475)  Time: 0.290s,  110.51/s  (0.290s,  110.34/s)  LR: 4.449e-05  Data: 0.004 (0.006)\n",
            "Train: 23 [ 750/1562 ( 48%)]  Loss:  1.770942 (1.8532)  Time: 0.287s,  111.57/s  (0.290s,  110.40/s)  LR: 4.449e-05  Data: 0.004 (0.005)\n",
            "Train: 23 [ 800/1562 ( 51%)]  Loss:  1.699182 (1.8550)  Time: 0.288s,  110.99/s  (0.290s,  110.45/s)  LR: 4.449e-05  Data: 0.004 (0.005)\n",
            "Train: 23 [ 850/1562 ( 54%)]  Loss:  1.870606 (1.8619)  Time: 0.286s,  111.76/s  (0.290s,  110.49/s)  LR: 4.449e-05  Data: 0.004 (0.005)\n",
            "Train: 23 [ 900/1562 ( 58%)]  Loss:  1.672612 (1.8644)  Time: 0.290s,  110.47/s  (0.290s,  110.52/s)  LR: 4.449e-05  Data: 0.004 (0.005)\n",
            "Train: 23 [ 950/1562 ( 61%)]  Loss:  1.614963 (1.8613)  Time: 0.286s,  111.73/s  (0.289s,  110.56/s)  LR: 4.449e-05  Data: 0.004 (0.005)\n",
            "Train: 23 [1000/1562 ( 64%)]  Loss:  1.979752 (1.8624)  Time: 0.287s,  111.62/s  (0.289s,  110.59/s)  LR: 4.449e-05  Data: 0.004 (0.005)\n",
            "Train: 23 [1050/1562 ( 67%)]  Loss:  1.658903 (1.8666)  Time: 0.287s,  111.65/s  (0.289s,  110.61/s)  LR: 4.449e-05  Data: 0.004 (0.005)\n",
            "Train: 23 [1100/1562 ( 70%)]  Loss:  2.228437 (1.8685)  Time: 0.287s,  111.47/s  (0.289s,  110.64/s)  LR: 4.449e-05  Data: 0.004 (0.005)\n",
            "Train: 23 [1150/1562 ( 74%)]  Loss:  2.011921 (1.8774)  Time: 0.287s,  111.43/s  (0.289s,  110.66/s)  LR: 4.449e-05  Data: 0.004 (0.005)\n",
            "Train: 23 [1200/1562 ( 77%)]  Loss:  1.710234 (1.8841)  Time: 0.294s,  108.77/s  (0.289s,  110.68/s)  LR: 4.449e-05  Data: 0.004 (0.005)\n",
            "Train: 23 [1250/1562 ( 80%)]  Loss:  1.871661 (1.8825)  Time: 0.294s,  108.94/s  (0.289s,  110.70/s)  LR: 4.449e-05  Data: 0.004 (0.005)\n",
            "Train: 23 [1300/1562 ( 83%)]  Loss:  1.925676 (1.8851)  Time: 0.286s,  111.72/s  (0.289s,  110.72/s)  LR: 4.449e-05  Data: 0.004 (0.005)\n",
            "Train: 23 [1350/1562 ( 86%)]  Loss:  1.895323 (1.8874)  Time: 0.287s,  111.51/s  (0.289s,  110.74/s)  LR: 4.449e-05  Data: 0.004 (0.005)\n",
            "Train: 23 [1400/1562 ( 90%)]  Loss:  2.038052 (1.8832)  Time: 0.286s,  111.82/s  (0.289s,  110.75/s)  LR: 4.449e-05  Data: 0.004 (0.005)\n",
            "Train: 23 [1450/1562 ( 93%)]  Loss:  2.033656 (1.8856)  Time: 0.286s,  111.86/s  (0.289s,  110.77/s)  LR: 4.449e-05  Data: 0.004 (0.005)\n",
            "Train: 23 [1500/1562 ( 96%)]  Loss:  1.970692 (1.8873)  Time: 0.287s,  111.64/s  (0.289s,  110.78/s)  LR: 4.449e-05  Data: 0.004 (0.005)\n",
            "Train: 23 [1550/1562 ( 99%)]  Loss:  1.536471 (1.8864)  Time: 0.285s,  112.45/s  (0.289s,  110.80/s)  LR: 4.449e-05  Data: 0.003 (0.005)\n",
            "Train: 23 [1561/1562 (100%)]  Loss:  1.845039 (1.8851)  Time: 0.370s,   86.58/s  (0.289s,  110.79/s)  LR: 4.449e-05  Data: 0.089 (0.005)\n",
            "Test: [   0/312]  Time: 0.898 (0.898)  Loss:  1.1365 (1.1365)  Acc@1: 62.5000 (62.5000)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [  50/312]  Time: 0.088 (0.114)  Loss:  0.5913 (0.7858)  Acc@1: 81.2500 (75.9804)  Acc@5: 100.0000 (97.9779)\n",
            "Test: [ 100/312]  Time: 0.096 (0.103)  Loss:  1.4547 (0.9934)  Acc@1: 50.0000 (67.6052)  Acc@5: 96.8750 (97.2463)\n",
            "Test: [ 150/312]  Time: 0.086 (0.100)  Loss:  1.4341 (1.1164)  Acc@1: 43.7500 (63.0588)  Acc@5: 100.0000 (96.9578)\n",
            "Test: [ 200/312]  Time: 0.089 (0.098)  Loss:  0.7526 (1.1453)  Acc@1: 81.2500 (61.8004)  Acc@5: 100.0000 (96.8750)\n",
            "Test: [ 250/312]  Time: 0.087 (0.097)  Loss:  0.5874 (1.0674)  Acc@1: 90.6250 (65.5005)  Acc@5: 96.8750 (96.9248)\n",
            "Test: [ 300/312]  Time: 0.086 (0.096)  Loss:  0.4735 (1.0077)  Acc@1: 90.6250 (68.2205)  Acc@5: 100.0000 (97.0930)\n",
            "Test: [ 312/312]  Time: 0.132 (0.096)  Loss:  0.6303 (0.9941)  Acc@1: 87.5000 (68.8600)  Acc@5: 100.0000 (97.1700)\n",
            "Test (EMA): [   0/312]  Time: 0.880 (0.880)  Loss:  1.5618 (1.5618)  Acc@1: 43.7500 (43.7500)  Acc@5: 96.8750 (96.8750)\n",
            "Test (EMA): [  50/312]  Time: 0.090 (0.113)  Loss:  1.3178 (1.2805)  Acc@1: 56.2500 (66.3603)  Acc@5: 100.0000 (95.7108)\n",
            "Test (EMA): [ 100/312]  Time: 0.086 (0.103)  Loss:  1.5312 (1.4677)  Acc@1: 56.2500 (51.8874)  Acc@5: 96.8750 (95.0186)\n",
            "Test (EMA): [ 150/312]  Time: 0.093 (0.099)  Loss:  1.7087 (1.4828)  Acc@1: 34.3750 (51.5728)  Acc@5: 100.0000 (95.3849)\n",
            "Test (EMA): [ 200/312]  Time: 0.097 (0.098)  Loss:  0.8440 (1.4938)  Acc@1: 87.5000 (49.1915)  Acc@5: 100.0000 (95.3514)\n",
            "Test (EMA): [ 250/312]  Time: 0.096 (0.097)  Loss:  1.1593 (1.4410)  Acc@1: 68.7500 (52.5647)  Acc@5: 93.7500 (94.9701)\n",
            "Test (EMA): [ 300/312]  Time: 0.086 (0.096)  Loss:  0.9498 (1.3985)  Acc@1: 87.5000 (55.8140)  Acc@5: 100.0000 (95.2035)\n",
            "Test (EMA): [ 312/312]  Time: 0.135 (0.096)  Loss:  1.2745 (1.3915)  Acc@1: 75.0000 (56.3900)  Acc@5: 93.7500 (95.3100)\n",
            "Current checkpoints:\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-23.pth.tar', 56.39)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-22.pth.tar', 54.72)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-21.pth.tar', 52.8)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-20.pth.tar', 50.83)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-19.pth.tar', 48.7)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-18.pth.tar', 46.37)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-17.pth.tar', 43.87)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-16.pth.tar', 41.0)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-15.pth.tar', 38.01)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-14.pth.tar', 34.77)\n",
            "\n",
            "Train: 24 [   0/1562 (  0%)]  Loss:  1.599447 (1.5994)  Time: 1.653s,   19.36/s  (1.653s,   19.36/s)  LR: 4.109e-05  Data: 1.150 (1.150)\n",
            "Train: 24 [  50/1562 (  3%)]  Loss:  1.556544 (1.9253)  Time: 0.286s,  111.79/s  (0.319s,  100.20/s)  LR: 4.109e-05  Data: 0.004 (0.027)\n",
            "Train: 24 [ 100/1562 (  6%)]  Loss:  1.673207 (1.8868)  Time: 0.288s,  111.27/s  (0.304s,  105.37/s)  LR: 4.109e-05  Data: 0.004 (0.016)\n",
            "Train: 24 [ 150/1562 ( 10%)]  Loss:  1.832619 (1.8937)  Time: 0.286s,  111.73/s  (0.298s,  107.25/s)  LR: 4.109e-05  Data: 0.004 (0.012)\n",
            "Train: 24 [ 200/1562 ( 13%)]  Loss:  1.943370 (1.8754)  Time: 0.286s,  111.80/s  (0.296s,  108.25/s)  LR: 4.109e-05  Data: 0.004 (0.010)\n",
            "Train: 24 [ 250/1562 ( 16%)]  Loss:  1.597464 (1.8662)  Time: 0.286s,  111.77/s  (0.294s,  108.81/s)  LR: 4.109e-05  Data: 0.004 (0.009)\n",
            "Train: 24 [ 300/1562 ( 19%)]  Loss:  1.896790 (1.8677)  Time: 0.290s,  110.39/s  (0.293s,  109.19/s)  LR: 4.109e-05  Data: 0.004 (0.008)\n",
            "Train: 24 [ 350/1562 ( 22%)]  Loss:  1.559868 (1.8516)  Time: 0.287s,  111.59/s  (0.292s,  109.51/s)  LR: 4.109e-05  Data: 0.004 (0.007)\n",
            "Train: 24 [ 400/1562 ( 26%)]  Loss:  2.146752 (1.8387)  Time: 0.286s,  111.77/s  (0.292s,  109.71/s)  LR: 4.109e-05  Data: 0.004 (0.007)\n",
            "Train: 24 [ 450/1562 ( 29%)]  Loss:  2.241520 (1.8382)  Time: 0.287s,  111.69/s  (0.291s,  109.85/s)  LR: 4.109e-05  Data: 0.004 (0.007)\n",
            "Train: 24 [ 500/1562 ( 32%)]  Loss:  1.753681 (1.8391)  Time: 0.287s,  111.56/s  (0.291s,  109.97/s)  LR: 4.109e-05  Data: 0.004 (0.006)\n",
            "Train: 24 [ 550/1562 ( 35%)]  Loss:  1.695438 (1.8310)  Time: 0.286s,  111.89/s  (0.291s,  110.08/s)  LR: 4.109e-05  Data: 0.004 (0.006)\n",
            "Train: 24 [ 600/1562 ( 38%)]  Loss:  2.092742 (1.8274)  Time: 0.286s,  111.81/s  (0.290s,  110.17/s)  LR: 4.109e-05  Data: 0.004 (0.006)\n",
            "Train: 24 [ 650/1562 ( 42%)]  Loss:  1.551270 (1.8300)  Time: 0.286s,  111.85/s  (0.290s,  110.25/s)  LR: 4.109e-05  Data: 0.004 (0.006)\n",
            "Train: 24 [ 700/1562 ( 45%)]  Loss:  1.684617 (1.8328)  Time: 0.290s,  110.17/s  (0.290s,  110.30/s)  LR: 4.109e-05  Data: 0.004 (0.006)\n",
            "Train: 24 [ 750/1562 ( 48%)]  Loss:  1.762024 (1.8378)  Time: 0.289s,  110.56/s  (0.290s,  110.36/s)  LR: 4.109e-05  Data: 0.004 (0.005)\n",
            "Train: 24 [ 800/1562 ( 51%)]  Loss:  1.572633 (1.8388)  Time: 0.297s,  107.66/s  (0.290s,  110.40/s)  LR: 4.109e-05  Data: 0.004 (0.005)\n",
            "Train: 24 [ 850/1562 ( 54%)]  Loss:  1.930309 (1.8470)  Time: 0.286s,  111.86/s  (0.290s,  110.45/s)  LR: 4.109e-05  Data: 0.004 (0.005)\n",
            "Train: 24 [ 900/1562 ( 58%)]  Loss:  1.780451 (1.8521)  Time: 0.286s,  111.85/s  (0.290s,  110.50/s)  LR: 4.109e-05  Data: 0.004 (0.005)\n",
            "Train: 24 [ 950/1562 ( 61%)]  Loss:  1.932689 (1.8514)  Time: 0.294s,  108.73/s  (0.290s,  110.52/s)  LR: 4.109e-05  Data: 0.004 (0.005)\n",
            "Train: 24 [1000/1562 ( 64%)]  Loss:  2.044711 (1.8531)  Time: 0.296s,  107.99/s  (0.289s,  110.56/s)  LR: 4.109e-05  Data: 0.014 (0.005)\n",
            "Train: 24 [1050/1562 ( 67%)]  Loss:  1.493923 (1.8580)  Time: 0.287s,  111.65/s  (0.289s,  110.59/s)  LR: 4.109e-05  Data: 0.004 (0.005)\n",
            "Train: 24 [1100/1562 ( 70%)]  Loss:  2.151305 (1.8590)  Time: 0.287s,  111.53/s  (0.289s,  110.62/s)  LR: 4.109e-05  Data: 0.004 (0.005)\n",
            "Train: 24 [1150/1562 ( 74%)]  Loss:  2.171155 (1.8684)  Time: 0.286s,  111.92/s  (0.289s,  110.65/s)  LR: 4.109e-05  Data: 0.004 (0.005)\n",
            "Train: 24 [1200/1562 ( 77%)]  Loss:  1.740037 (1.8753)  Time: 0.286s,  111.74/s  (0.289s,  110.67/s)  LR: 4.109e-05  Data: 0.004 (0.005)\n",
            "Train: 24 [1250/1562 ( 80%)]  Loss:  1.964943 (1.8742)  Time: 0.287s,  111.64/s  (0.289s,  110.69/s)  LR: 4.109e-05  Data: 0.004 (0.005)\n",
            "Train: 24 [1300/1562 ( 83%)]  Loss:  1.911928 (1.8778)  Time: 0.287s,  111.59/s  (0.289s,  110.71/s)  LR: 4.109e-05  Data: 0.004 (0.005)\n",
            "Train: 24 [1350/1562 ( 86%)]  Loss:  2.050535 (1.8794)  Time: 0.290s,  110.49/s  (0.289s,  110.73/s)  LR: 4.109e-05  Data: 0.004 (0.005)\n",
            "Train: 24 [1400/1562 ( 90%)]  Loss:  2.061995 (1.8741)  Time: 0.287s,  111.68/s  (0.289s,  110.75/s)  LR: 4.109e-05  Data: 0.004 (0.005)\n",
            "Train: 24 [1450/1562 ( 93%)]  Loss:  2.188858 (1.8762)  Time: 0.287s,  111.53/s  (0.289s,  110.77/s)  LR: 4.109e-05  Data: 0.004 (0.005)\n",
            "Train: 24 [1500/1562 ( 96%)]  Loss:  2.037173 (1.8769)  Time: 0.287s,  111.69/s  (0.289s,  110.79/s)  LR: 4.109e-05  Data: 0.004 (0.005)\n",
            "Train: 24 [1550/1562 ( 99%)]  Loss:  1.522636 (1.8753)  Time: 0.286s,  111.82/s  (0.289s,  110.81/s)  LR: 4.109e-05  Data: 0.004 (0.005)\n",
            "Train: 24 [1561/1562 (100%)]  Loss:  1.884548 (1.8739)  Time: 0.372s,   86.06/s  (0.289s,  110.80/s)  LR: 4.109e-05  Data: 0.092 (0.005)\n",
            "Test: [   0/312]  Time: 0.969 (0.969)  Loss:  1.1580 (1.1580)  Acc@1: 56.2500 (56.2500)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [  50/312]  Time: 0.087 (0.114)  Loss:  0.6666 (0.8050)  Acc@1: 78.1250 (73.8971)  Acc@5: 100.0000 (98.4681)\n",
            "Test: [ 100/312]  Time: 0.093 (0.104)  Loss:  1.4501 (0.9801)  Acc@1: 43.7500 (67.7290)  Acc@5: 96.8750 (97.5248)\n",
            "Test: [ 150/312]  Time: 0.100 (0.100)  Loss:  1.3074 (1.0856)  Acc@1: 53.1250 (63.8038)  Acc@5: 100.0000 (97.2682)\n",
            "Test: [ 200/312]  Time: 0.087 (0.098)  Loss:  0.8960 (1.1049)  Acc@1: 78.1250 (62.8887)  Acc@5: 100.0000 (96.8905)\n",
            "Test: [ 250/312]  Time: 0.092 (0.097)  Loss:  0.4198 (1.0655)  Acc@1: 93.7500 (65.1021)  Acc@5: 100.0000 (96.6135)\n",
            "Test: [ 300/312]  Time: 0.086 (0.096)  Loss:  0.4315 (0.9849)  Acc@1: 93.7500 (68.4801)  Acc@5: 100.0000 (96.9581)\n",
            "Test: [ 312/312]  Time: 0.130 (0.096)  Loss:  0.7035 (0.9728)  Acc@1: 87.5000 (68.9800)  Acc@5: 100.0000 (97.0200)\n",
            "Test (EMA): [   0/312]  Time: 0.928 (0.928)  Loss:  1.5258 (1.5258)  Acc@1: 46.8750 (46.8750)  Acc@5: 96.8750 (96.8750)\n",
            "Test (EMA): [  50/312]  Time: 0.088 (0.113)  Loss:  1.2493 (1.2305)  Acc@1: 62.5000 (67.4632)  Acc@5: 100.0000 (96.2010)\n",
            "Test (EMA): [ 100/312]  Time: 0.087 (0.103)  Loss:  1.5098 (1.4250)  Acc@1: 56.2500 (53.3106)  Acc@5: 96.8750 (95.4517)\n",
            "Test (EMA): [ 150/312]  Time: 0.093 (0.100)  Loss:  1.7061 (1.4490)  Acc@1: 31.2500 (52.7111)  Acc@5: 100.0000 (95.7368)\n",
            "Test (EMA): [ 200/312]  Time: 0.087 (0.098)  Loss:  0.8309 (1.4615)  Acc@1: 84.3750 (50.4820)  Acc@5: 100.0000 (95.6779)\n",
            "Test (EMA): [ 250/312]  Time: 0.093 (0.097)  Loss:  1.1252 (1.4052)  Acc@1: 68.7500 (53.9467)  Acc@5: 96.8750 (95.3312)\n",
            "Test (EMA): [ 300/312]  Time: 0.086 (0.096)  Loss:  0.8861 (1.3619)  Acc@1: 90.6250 (57.1117)  Acc@5: 100.0000 (95.5046)\n",
            "Test (EMA): [ 312/312]  Time: 0.130 (0.096)  Loss:  1.2133 (1.3537)  Acc@1: 75.0000 (57.7500)  Acc@5: 93.7500 (95.5900)\n",
            "Current checkpoints:\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-24.pth.tar', 57.75)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-23.pth.tar', 56.39)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-22.pth.tar', 54.72)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-21.pth.tar', 52.8)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-20.pth.tar', 50.83)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-19.pth.tar', 48.7)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-18.pth.tar', 46.37)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-17.pth.tar', 43.87)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-16.pth.tar', 41.0)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-15.pth.tar', 38.01)\n",
            "\n",
            "Train: 25 [   0/1562 (  0%)]  Loss:  1.639112 (1.6391)  Time: 1.694s,   18.89/s  (1.694s,   18.89/s)  LR: 3.778e-05  Data: 1.201 (1.201)\n",
            "Train: 25 [  50/1562 (  3%)]  Loss:  1.688511 (1.9050)  Time: 0.290s,  110.42/s  (0.318s,  100.55/s)  LR: 3.778e-05  Data: 0.004 (0.028)\n",
            "Train: 25 [ 100/1562 (  6%)]  Loss:  1.819295 (1.8631)  Time: 0.286s,  111.83/s  (0.303s,  105.54/s)  LR: 3.778e-05  Data: 0.004 (0.016)\n",
            "Train: 25 [ 150/1562 ( 10%)]  Loss:  2.126599 (1.8839)  Time: 0.286s,  111.78/s  (0.298s,  107.38/s)  LR: 3.778e-05  Data: 0.004 (0.012)\n",
            "Train: 25 [ 200/1562 ( 13%)]  Loss:  1.877535 (1.8638)  Time: 0.286s,  111.88/s  (0.295s,  108.35/s)  LR: 3.778e-05  Data: 0.004 (0.010)\n",
            "Train: 25 [ 250/1562 ( 16%)]  Loss:  1.696792 (1.8567)  Time: 0.286s,  111.84/s  (0.294s,  108.95/s)  LR: 3.778e-05  Data: 0.004 (0.009)\n",
            "Train: 25 [ 300/1562 ( 19%)]  Loss:  2.046444 (1.8573)  Time: 0.287s,  111.59/s  (0.293s,  109.28/s)  LR: 3.778e-05  Data: 0.004 (0.008)\n",
            "Train: 25 [ 350/1562 ( 22%)]  Loss:  2.130050 (1.8383)  Time: 0.291s,  110.11/s  (0.292s,  109.55/s)  LR: 3.778e-05  Data: 0.004 (0.007)\n",
            "Train: 25 [ 400/1562 ( 26%)]  Loss:  2.129754 (1.8283)  Time: 0.289s,  110.60/s  (0.292s,  109.77/s)  LR: 3.778e-05  Data: 0.004 (0.007)\n",
            "Train: 25 [ 450/1562 ( 29%)]  Loss:  1.898048 (1.8260)  Time: 0.287s,  111.36/s  (0.291s,  109.96/s)  LR: 3.778e-05  Data: 0.004 (0.007)\n",
            "Train: 25 [ 500/1562 ( 32%)]  Loss:  1.683291 (1.8312)  Time: 0.287s,  111.63/s  (0.291s,  110.11/s)  LR: 3.778e-05  Data: 0.004 (0.006)\n",
            "Train: 25 [ 550/1562 ( 35%)]  Loss:  1.598984 (1.8246)  Time: 0.286s,  111.70/s  (0.290s,  110.23/s)  LR: 3.778e-05  Data: 0.004 (0.006)\n",
            "Train: 25 [ 600/1562 ( 38%)]  Loss:  2.042803 (1.8209)  Time: 0.287s,  111.37/s  (0.290s,  110.32/s)  LR: 3.778e-05  Data: 0.005 (0.006)\n",
            "Train: 25 [ 650/1562 ( 42%)]  Loss:  1.759521 (1.8243)  Time: 0.286s,  111.72/s  (0.290s,  110.40/s)  LR: 3.778e-05  Data: 0.004 (0.006)\n",
            "Train: 25 [ 700/1562 ( 45%)]  Loss:  1.776220 (1.8293)  Time: 0.286s,  111.70/s  (0.290s,  110.45/s)  LR: 3.778e-05  Data: 0.004 (0.006)\n",
            "Train: 25 [ 750/1562 ( 48%)]  Loss:  1.697216 (1.8348)  Time: 0.286s,  111.76/s  (0.290s,  110.53/s)  LR: 3.778e-05  Data: 0.004 (0.005)\n",
            "Train: 25 [ 800/1562 ( 51%)]  Loss:  1.836236 (1.8372)  Time: 0.286s,  111.76/s  (0.289s,  110.58/s)  LR: 3.778e-05  Data: 0.004 (0.005)\n",
            "Train: 25 [ 850/1562 ( 54%)]  Loss:  2.134666 (1.8450)  Time: 0.287s,  111.57/s  (0.289s,  110.62/s)  LR: 3.778e-05  Data: 0.004 (0.005)\n",
            "Train: 25 [ 900/1562 ( 58%)]  Loss:  1.700645 (1.8489)  Time: 0.287s,  111.56/s  (0.289s,  110.67/s)  LR: 3.778e-05  Data: 0.004 (0.005)\n",
            "Train: 25 [ 950/1562 ( 61%)]  Loss:  1.571316 (1.8468)  Time: 0.287s,  111.45/s  (0.289s,  110.67/s)  LR: 3.778e-05  Data: 0.004 (0.005)\n",
            "Train: 25 [1000/1562 ( 64%)]  Loss:  2.098829 (1.8487)  Time: 0.288s,  111.14/s  (0.289s,  110.70/s)  LR: 3.778e-05  Data: 0.005 (0.005)\n",
            "Train: 25 [1050/1562 ( 67%)]  Loss:  1.474090 (1.8539)  Time: 0.288s,  111.22/s  (0.289s,  110.72/s)  LR: 3.778e-05  Data: 0.004 (0.005)\n",
            "Train: 25 [1100/1562 ( 70%)]  Loss:  2.030566 (1.8555)  Time: 0.286s,  111.75/s  (0.289s,  110.73/s)  LR: 3.778e-05  Data: 0.004 (0.005)\n",
            "Train: 25 [1150/1562 ( 74%)]  Loss:  2.115222 (1.8640)  Time: 0.286s,  111.76/s  (0.289s,  110.76/s)  LR: 3.778e-05  Data: 0.004 (0.005)\n",
            "Train: 25 [1200/1562 ( 77%)]  Loss:  1.673805 (1.8713)  Time: 0.288s,  111.24/s  (0.289s,  110.77/s)  LR: 3.778e-05  Data: 0.004 (0.005)\n",
            "Train: 25 [1250/1562 ( 80%)]  Loss:  1.906784 (1.8703)  Time: 0.287s,  111.64/s  (0.289s,  110.79/s)  LR: 3.778e-05  Data: 0.004 (0.005)\n",
            "Train: 25 [1300/1562 ( 83%)]  Loss:  1.616040 (1.8733)  Time: 0.287s,  111.69/s  (0.289s,  110.81/s)  LR: 3.778e-05  Data: 0.004 (0.005)\n",
            "Train: 25 [1350/1562 ( 86%)]  Loss:  1.934313 (1.8740)  Time: 0.287s,  111.65/s  (0.289s,  110.82/s)  LR: 3.778e-05  Data: 0.004 (0.005)\n",
            "Train: 25 [1400/1562 ( 90%)]  Loss:  2.081417 (1.8685)  Time: 0.291s,  109.86/s  (0.289s,  110.83/s)  LR: 3.778e-05  Data: 0.004 (0.005)\n",
            "Train: 25 [1450/1562 ( 93%)]  Loss:  2.164107 (1.8709)  Time: 0.286s,  111.74/s  (0.289s,  110.83/s)  LR: 3.778e-05  Data: 0.004 (0.005)\n",
            "Train: 25 [1500/1562 ( 96%)]  Loss:  1.994079 (1.8726)  Time: 0.287s,  111.58/s  (0.289s,  110.84/s)  LR: 3.778e-05  Data: 0.004 (0.005)\n",
            "Train: 25 [1550/1562 ( 99%)]  Loss:  1.633401 (1.8716)  Time: 0.284s,  112.55/s  (0.289s,  110.85/s)  LR: 3.778e-05  Data: 0.003 (0.005)\n",
            "Train: 25 [1561/1562 (100%)]  Loss:  1.726958 (1.8697)  Time: 0.370s,   86.51/s  (0.289s,  110.84/s)  LR: 3.778e-05  Data: 0.089 (0.005)\n",
            "Test: [   0/312]  Time: 0.826 (0.826)  Loss:  1.0684 (1.0684)  Acc@1: 62.5000 (62.5000)  Acc@5: 96.8750 (96.8750)\n",
            "Test: [  50/312]  Time: 0.094 (0.112)  Loss:  0.5754 (0.7263)  Acc@1: 81.2500 (78.7377)  Acc@5: 100.0000 (98.2230)\n",
            "Test: [ 100/312]  Time: 0.093 (0.103)  Loss:  1.4221 (0.9661)  Acc@1: 50.0000 (68.6572)  Acc@5: 93.7500 (97.7413)\n",
            "Test: [ 150/312]  Time: 0.089 (0.099)  Loss:  1.6826 (1.1260)  Acc@1: 25.0000 (61.8584)  Acc@5: 100.0000 (97.3924)\n",
            "Test: [ 200/312]  Time: 0.098 (0.098)  Loss:  0.6936 (1.1430)  Acc@1: 84.3750 (61.1629)  Acc@5: 100.0000 (97.1393)\n",
            "Test: [ 250/312]  Time: 0.089 (0.097)  Loss:  0.6076 (1.0448)  Acc@1: 93.7500 (65.6997)  Acc@5: 96.8750 (97.2610)\n",
            "Test: [ 300/312]  Time: 0.086 (0.096)  Loss:  0.4317 (0.9855)  Acc@1: 90.6250 (68.2932)  Acc@5: 100.0000 (97.3526)\n",
            "Test: [ 312/312]  Time: 0.130 (0.096)  Loss:  0.6426 (0.9730)  Acc@1: 87.5000 (68.8800)  Acc@5: 100.0000 (97.4000)\n",
            "Test (EMA): [   0/312]  Time: 0.882 (0.882)  Loss:  1.4896 (1.4896)  Acc@1: 43.7500 (43.7500)  Acc@5: 96.8750 (96.8750)\n",
            "Test (EMA): [  50/312]  Time: 0.102 (0.113)  Loss:  1.1861 (1.1850)  Acc@1: 68.7500 (68.5049)  Acc@5: 96.8750 (96.3235)\n",
            "Test (EMA): [ 100/312]  Time: 0.094 (0.103)  Loss:  1.4865 (1.3853)  Acc@1: 56.2500 (54.6101)  Acc@5: 96.8750 (95.6374)\n",
            "Test (EMA): [ 150/312]  Time: 0.089 (0.099)  Loss:  1.7027 (1.4170)  Acc@1: 28.1250 (53.8286)  Acc@5: 100.0000 (95.9230)\n",
            "Test (EMA): [ 200/312]  Time: 0.093 (0.098)  Loss:  0.8233 (1.4306)  Acc@1: 84.3750 (51.8657)  Acc@5: 100.0000 (95.8644)\n",
            "Test (EMA): [ 250/312]  Time: 0.087 (0.097)  Loss:  1.0900 (1.3715)  Acc@1: 68.7500 (55.2540)  Acc@5: 96.8750 (95.5428)\n",
            "Test (EMA): [ 300/312]  Time: 0.086 (0.096)  Loss:  0.8267 (1.3269)  Acc@1: 93.7500 (58.3160)  Acc@5: 100.0000 (95.7330)\n",
            "Test (EMA): [ 312/312]  Time: 0.133 (0.096)  Loss:  1.1561 (1.3177)  Acc@1: 75.0000 (58.9500)  Acc@5: 93.7500 (95.8100)\n",
            "Current checkpoints:\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-25.pth.tar', 58.95)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-24.pth.tar', 57.75)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-23.pth.tar', 56.39)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-22.pth.tar', 54.72)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-21.pth.tar', 52.8)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-20.pth.tar', 50.83)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-19.pth.tar', 48.7)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-18.pth.tar', 46.37)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-17.pth.tar', 43.87)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-16.pth.tar', 41.0)\n",
            "\n",
            "Train: 26 [   0/1562 (  0%)]  Loss:  1.660635 (1.6606)  Time: 1.555s,   20.57/s  (1.555s,   20.57/s)  LR: 3.457e-05  Data: 1.078 (1.078)\n",
            "Train: 26 [  50/1562 (  3%)]  Loss:  1.645076 (1.8859)  Time: 0.287s,  111.53/s  (0.318s,  100.71/s)  LR: 3.457e-05  Data: 0.004 (0.025)\n",
            "Train: 26 [ 100/1562 (  6%)]  Loss:  1.627731 (1.8446)  Time: 0.286s,  111.88/s  (0.303s,  105.67/s)  LR: 3.457e-05  Data: 0.004 (0.015)\n",
            "Train: 26 [ 150/1562 ( 10%)]  Loss:  1.845496 (1.8605)  Time: 0.298s,  107.49/s  (0.298s,  107.53/s)  LR: 3.457e-05  Data: 0.004 (0.011)\n",
            "Train: 26 [ 200/1562 ( 13%)]  Loss:  2.100383 (1.8522)  Time: 0.288s,  111.06/s  (0.295s,  108.41/s)  LR: 3.457e-05  Data: 0.004 (0.009)\n",
            "Train: 26 [ 250/1562 ( 16%)]  Loss:  1.460342 (1.8568)  Time: 0.286s,  111.73/s  (0.294s,  108.99/s)  LR: 3.457e-05  Data: 0.004 (0.008)\n",
            "Train: 26 [ 300/1562 ( 19%)]  Loss:  1.965364 (1.8561)  Time: 0.286s,  112.02/s  (0.293s,  109.38/s)  LR: 3.457e-05  Data: 0.004 (0.007)\n",
            "Train: 26 [ 350/1562 ( 22%)]  Loss:  1.874743 (1.8386)  Time: 0.287s,  111.38/s  (0.292s,  109.62/s)  LR: 3.457e-05  Data: 0.004 (0.007)\n",
            "Train: 26 [ 400/1562 ( 26%)]  Loss:  1.991705 (1.8246)  Time: 0.287s,  111.47/s  (0.291s,  109.82/s)  LR: 3.457e-05  Data: 0.005 (0.007)\n",
            "Train: 26 [ 450/1562 ( 29%)]  Loss:  2.017212 (1.8214)  Time: 0.290s,  110.38/s  (0.291s,  109.98/s)  LR: 3.457e-05  Data: 0.004 (0.006)\n",
            "Train: 26 [ 500/1562 ( 32%)]  Loss:  1.657099 (1.8246)  Time: 0.290s,  110.28/s  (0.291s,  110.12/s)  LR: 3.457e-05  Data: 0.004 (0.006)\n",
            "Train: 26 [ 550/1562 ( 35%)]  Loss:  1.570980 (1.8200)  Time: 0.294s,  108.99/s  (0.290s,  110.21/s)  LR: 3.457e-05  Data: 0.004 (0.006)\n",
            "Train: 26 [ 600/1562 ( 38%)]  Loss:  2.115721 (1.8155)  Time: 0.287s,  111.42/s  (0.290s,  110.32/s)  LR: 3.457e-05  Data: 0.004 (0.006)\n",
            "Train: 26 [ 650/1562 ( 42%)]  Loss:  1.295460 (1.8175)  Time: 0.286s,  111.78/s  (0.290s,  110.40/s)  LR: 3.457e-05  Data: 0.004 (0.005)\n",
            "Train: 26 [ 700/1562 ( 45%)]  Loss:  1.586447 (1.8197)  Time: 0.286s,  111.86/s  (0.290s,  110.43/s)  LR: 3.457e-05  Data: 0.004 (0.005)\n",
            "Train: 26 [ 750/1562 ( 48%)]  Loss:  1.782120 (1.8263)  Time: 0.289s,  110.81/s  (0.290s,  110.49/s)  LR: 3.457e-05  Data: 0.004 (0.005)\n",
            "Train: 26 [ 800/1562 ( 51%)]  Loss:  1.710535 (1.8284)  Time: 0.297s,  107.75/s  (0.290s,  110.53/s)  LR: 3.457e-05  Data: 0.004 (0.005)\n",
            "Train: 26 [ 850/1562 ( 54%)]  Loss:  2.042293 (1.8370)  Time: 0.290s,  110.45/s  (0.289s,  110.57/s)  LR: 3.457e-05  Data: 0.004 (0.005)\n",
            "Train: 26 [ 900/1562 ( 58%)]  Loss:  1.843692 (1.8421)  Time: 0.286s,  111.80/s  (0.289s,  110.61/s)  LR: 3.457e-05  Data: 0.004 (0.005)\n",
            "Train: 26 [ 950/1562 ( 61%)]  Loss:  1.717757 (1.8404)  Time: 0.286s,  111.82/s  (0.289s,  110.65/s)  LR: 3.457e-05  Data: 0.004 (0.005)\n",
            "Train: 26 [1000/1562 ( 64%)]  Loss:  2.269177 (1.8436)  Time: 0.286s,  111.78/s  (0.289s,  110.69/s)  LR: 3.457e-05  Data: 0.004 (0.005)\n",
            "Train: 26 [1050/1562 ( 67%)]  Loss:  1.545895 (1.8480)  Time: 0.286s,  111.84/s  (0.289s,  110.72/s)  LR: 3.457e-05  Data: 0.004 (0.005)\n",
            "Train: 26 [1100/1562 ( 70%)]  Loss:  2.129164 (1.8501)  Time: 0.286s,  111.88/s  (0.289s,  110.74/s)  LR: 3.457e-05  Data: 0.004 (0.005)\n",
            "Train: 26 [1150/1562 ( 74%)]  Loss:  2.115387 (1.8592)  Time: 0.287s,  111.55/s  (0.289s,  110.76/s)  LR: 3.457e-05  Data: 0.004 (0.005)\n",
            "Train: 26 [1200/1562 ( 77%)]  Loss:  1.605610 (1.8656)  Time: 0.287s,  111.49/s  (0.289s,  110.78/s)  LR: 3.457e-05  Data: 0.004 (0.005)\n",
            "Train: 26 [1250/1562 ( 80%)]  Loss:  1.826755 (1.8655)  Time: 0.287s,  111.68/s  (0.289s,  110.81/s)  LR: 3.457e-05  Data: 0.004 (0.005)\n",
            "Train: 26 [1300/1562 ( 83%)]  Loss:  1.762715 (1.8688)  Time: 0.286s,  111.73/s  (0.289s,  110.83/s)  LR: 3.457e-05  Data: 0.004 (0.005)\n",
            "Train: 26 [1350/1562 ( 86%)]  Loss:  1.707887 (1.8701)  Time: 0.292s,  109.66/s  (0.289s,  110.85/s)  LR: 3.457e-05  Data: 0.009 (0.005)\n",
            "Train: 26 [1400/1562 ( 90%)]  Loss:  2.014503 (1.8648)  Time: 0.286s,  111.96/s  (0.289s,  110.84/s)  LR: 3.457e-05  Data: 0.004 (0.005)\n",
            "Train: 26 [1450/1562 ( 93%)]  Loss:  2.124473 (1.8669)  Time: 0.290s,  110.21/s  (0.289s,  110.85/s)  LR: 3.457e-05  Data: 0.004 (0.005)\n",
            "Train: 26 [1500/1562 ( 96%)]  Loss:  2.230656 (1.8683)  Time: 0.286s,  111.73/s  (0.289s,  110.86/s)  LR: 3.457e-05  Data: 0.004 (0.005)\n",
            "Train: 26 [1550/1562 ( 99%)]  Loss:  1.725397 (1.8661)  Time: 0.284s,  112.84/s  (0.289s,  110.88/s)  LR: 3.457e-05  Data: 0.003 (0.005)\n",
            "Train: 26 [1561/1562 (100%)]  Loss:  2.011134 (1.8646)  Time: 0.371s,   86.35/s  (0.289s,  110.87/s)  LR: 3.457e-05  Data: 0.090 (0.005)\n",
            "Test: [   0/312]  Time: 0.906 (0.906)  Loss:  1.1757 (1.1757)  Acc@1: 53.1250 (53.1250)  Acc@5: 96.8750 (96.8750)\n",
            "Test: [  50/312]  Time: 0.098 (0.113)  Loss:  0.5958 (0.7683)  Acc@1: 81.2500 (76.7770)  Acc@5: 100.0000 (98.1005)\n",
            "Test: [ 100/312]  Time: 0.087 (0.103)  Loss:  1.2572 (1.0448)  Acc@1: 53.1250 (65.1609)  Acc@5: 100.0000 (96.1324)\n",
            "Test: [ 150/312]  Time: 0.096 (0.099)  Loss:  1.4106 (1.1341)  Acc@1: 40.6250 (61.3618)  Acc@5: 100.0000 (96.2955)\n",
            "Test: [ 200/312]  Time: 0.093 (0.098)  Loss:  0.8450 (1.1156)  Acc@1: 84.3750 (62.4689)  Acc@5: 100.0000 (96.4552)\n",
            "Test: [ 250/312]  Time: 0.088 (0.097)  Loss:  0.5440 (1.0279)  Acc@1: 93.7500 (66.6086)  Acc@5: 96.8750 (96.7505)\n",
            "Test: [ 300/312]  Time: 0.086 (0.096)  Loss:  0.3526 (0.9661)  Acc@1: 93.7500 (69.1860)  Acc@5: 100.0000 (96.9373)\n",
            "Test: [ 312/312]  Time: 0.133 (0.096)  Loss:  0.5113 (0.9518)  Acc@1: 87.5000 (69.8100)  Acc@5: 100.0000 (97.0200)\n",
            "Test (EMA): [   0/312]  Time: 0.855 (0.855)  Loss:  1.4539 (1.4539)  Acc@1: 53.1250 (53.1250)  Acc@5: 96.8750 (96.8750)\n",
            "Test (EMA): [  50/312]  Time: 0.097 (0.113)  Loss:  1.1268 (1.1425)  Acc@1: 68.7500 (69.3627)  Acc@5: 96.8750 (96.5074)\n",
            "Test (EMA): [ 100/312]  Time: 0.087 (0.103)  Loss:  1.4641 (1.3477)  Acc@1: 56.2500 (56.0644)  Acc@5: 96.8750 (95.8540)\n",
            "Test (EMA): [ 150/312]  Time: 0.093 (0.099)  Loss:  1.6963 (1.3863)  Acc@1: 31.2500 (54.9876)  Acc@5: 100.0000 (96.1093)\n",
            "Test (EMA): [ 200/312]  Time: 0.111 (0.098)  Loss:  0.8162 (1.4011)  Acc@1: 84.3750 (52.9073)  Acc@5: 100.0000 (96.0510)\n",
            "Test (EMA): [ 250/312]  Time: 0.089 (0.097)  Loss:  1.0559 (1.3397)  Acc@1: 68.7500 (56.3870)  Acc@5: 96.8750 (95.8167)\n",
            "Test (EMA): [ 300/312]  Time: 0.086 (0.096)  Loss:  0.7775 (1.2941)  Acc@1: 93.7500 (59.3750)  Acc@5: 100.0000 (95.9718)\n",
            "Test (EMA): [ 312/312]  Time: 0.130 (0.096)  Loss:  1.1078 (1.2841)  Acc@1: 75.0000 (60.0200)  Acc@5: 93.7500 (96.0400)\n",
            "Current checkpoints:\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-26.pth.tar', 60.02)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-25.pth.tar', 58.95)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-24.pth.tar', 57.75)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-23.pth.tar', 56.39)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-22.pth.tar', 54.72)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-21.pth.tar', 52.8)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-20.pth.tar', 50.83)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-19.pth.tar', 48.7)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-18.pth.tar', 46.37)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-17.pth.tar', 43.87)\n",
            "\n",
            "Train: 27 [   0/1562 (  0%)]  Loss:  1.738873 (1.7389)  Time: 1.670s,   19.16/s  (1.670s,   19.16/s)  LR: 3.149e-05  Data: 1.210 (1.210)\n",
            "Train: 27 [  50/1562 (  3%)]  Loss:  1.556450 (1.9160)  Time: 0.286s,  111.82/s  (0.318s,  100.65/s)  LR: 3.149e-05  Data: 0.004 (0.028)\n",
            "Train: 27 [ 100/1562 (  6%)]  Loss:  1.454724 (1.8756)  Time: 0.286s,  111.80/s  (0.303s,  105.65/s)  LR: 3.149e-05  Data: 0.004 (0.016)\n",
            "Train: 27 [ 150/1562 ( 10%)]  Loss:  2.018791 (1.8784)  Time: 0.286s,  111.88/s  (0.298s,  107.44/s)  LR: 3.149e-05  Data: 0.004 (0.012)\n",
            "Train: 27 [ 200/1562 ( 13%)]  Loss:  1.942823 (1.8641)  Time: 0.293s,  109.16/s  (0.295s,  108.40/s)  LR: 3.149e-05  Data: 0.004 (0.010)\n",
            "Train: 27 [ 250/1562 ( 16%)]  Loss:  1.653552 (1.8514)  Time: 0.287s,  111.57/s  (0.294s,  108.99/s)  LR: 3.149e-05  Data: 0.004 (0.009)\n",
            "Train: 27 [ 300/1562 ( 19%)]  Loss:  1.916462 (1.8514)  Time: 0.286s,  111.75/s  (0.293s,  109.36/s)  LR: 3.149e-05  Data: 0.004 (0.008)\n",
            "Train: 27 [ 350/1562 ( 22%)]  Loss:  1.721765 (1.8310)  Time: 0.288s,  111.26/s  (0.292s,  109.63/s)  LR: 3.149e-05  Data: 0.004 (0.007)\n",
            "Train: 27 [ 400/1562 ( 26%)]  Loss:  2.058464 (1.8158)  Time: 0.286s,  111.86/s  (0.291s,  109.85/s)  LR: 3.149e-05  Data: 0.004 (0.007)\n",
            "Train: 27 [ 450/1562 ( 29%)]  Loss:  2.086419 (1.8145)  Time: 0.294s,  108.68/s  (0.291s,  109.99/s)  LR: 3.149e-05  Data: 0.004 (0.007)\n",
            "Train: 27 [ 500/1562 ( 32%)]  Loss:  1.771461 (1.8147)  Time: 0.286s,  111.83/s  (0.291s,  110.11/s)  LR: 3.149e-05  Data: 0.004 (0.006)\n",
            "Train: 27 [ 550/1562 ( 35%)]  Loss:  1.763132 (1.8072)  Time: 0.286s,  111.82/s  (0.290s,  110.21/s)  LR: 3.149e-05  Data: 0.004 (0.006)\n",
            "Train: 27 [ 600/1562 ( 38%)]  Loss:  1.859289 (1.8029)  Time: 0.294s,  108.89/s  (0.290s,  110.31/s)  LR: 3.149e-05  Data: 0.004 (0.006)\n",
            "Train: 27 [ 650/1562 ( 42%)]  Loss:  1.719440 (1.8029)  Time: 0.287s,  111.67/s  (0.290s,  110.38/s)  LR: 3.149e-05  Data: 0.004 (0.006)\n",
            "Train: 27 [ 700/1562 ( 45%)]  Loss:  1.830222 (1.8073)  Time: 0.287s,  111.66/s  (0.290s,  110.43/s)  LR: 3.149e-05  Data: 0.004 (0.006)\n",
            "Train: 27 [ 750/1562 ( 48%)]  Loss:  1.476392 (1.8138)  Time: 0.287s,  111.45/s  (0.290s,  110.48/s)  LR: 3.149e-05  Data: 0.004 (0.005)\n",
            "Train: 27 [ 800/1562 ( 51%)]  Loss:  1.654672 (1.8162)  Time: 0.287s,  111.67/s  (0.290s,  110.52/s)  LR: 3.149e-05  Data: 0.004 (0.005)\n",
            "Train: 27 [ 850/1562 ( 54%)]  Loss:  2.047295 (1.8264)  Time: 0.286s,  111.71/s  (0.289s,  110.57/s)  LR: 3.149e-05  Data: 0.004 (0.005)\n",
            "Train: 27 [ 900/1562 ( 58%)]  Loss:  1.636934 (1.8321)  Time: 0.287s,  111.54/s  (0.289s,  110.60/s)  LR: 3.149e-05  Data: 0.004 (0.005)\n",
            "Train: 27 [ 950/1562 ( 61%)]  Loss:  1.350432 (1.8302)  Time: 0.286s,  111.84/s  (0.289s,  110.64/s)  LR: 3.149e-05  Data: 0.004 (0.005)\n",
            "Train: 27 [1000/1562 ( 64%)]  Loss:  1.999584 (1.8328)  Time: 0.287s,  111.43/s  (0.289s,  110.67/s)  LR: 3.149e-05  Data: 0.004 (0.005)\n",
            "Train: 27 [1050/1562 ( 67%)]  Loss:  1.717615 (1.8387)  Time: 0.286s,  111.92/s  (0.289s,  110.69/s)  LR: 3.149e-05  Data: 0.004 (0.005)\n",
            "Train: 27 [1100/1562 ( 70%)]  Loss:  1.850119 (1.8411)  Time: 0.286s,  111.99/s  (0.289s,  110.71/s)  LR: 3.149e-05  Data: 0.004 (0.005)\n",
            "Train: 27 [1150/1562 ( 74%)]  Loss:  2.118596 (1.8507)  Time: 0.287s,  111.35/s  (0.289s,  110.73/s)  LR: 3.149e-05  Data: 0.004 (0.005)\n",
            "Train: 27 [1200/1562 ( 77%)]  Loss:  1.584963 (1.8578)  Time: 0.286s,  111.71/s  (0.289s,  110.76/s)  LR: 3.149e-05  Data: 0.004 (0.005)\n",
            "Train: 27 [1250/1562 ( 80%)]  Loss:  2.008231 (1.8579)  Time: 0.288s,  111.22/s  (0.289s,  110.79/s)  LR: 3.149e-05  Data: 0.004 (0.005)\n",
            "Train: 27 [1300/1562 ( 83%)]  Loss:  1.828805 (1.8605)  Time: 0.290s,  110.19/s  (0.289s,  110.80/s)  LR: 3.149e-05  Data: 0.004 (0.005)\n",
            "Train: 27 [1350/1562 ( 86%)]  Loss:  1.920747 (1.8609)  Time: 0.287s,  111.52/s  (0.289s,  110.81/s)  LR: 3.149e-05  Data: 0.004 (0.005)\n",
            "Train: 27 [1400/1562 ( 90%)]  Loss:  1.992265 (1.8561)  Time: 0.287s,  111.53/s  (0.289s,  110.82/s)  LR: 3.149e-05  Data: 0.004 (0.005)\n",
            "Train: 27 [1450/1562 ( 93%)]  Loss:  1.954125 (1.8583)  Time: 0.286s,  111.95/s  (0.289s,  110.83/s)  LR: 3.149e-05  Data: 0.004 (0.005)\n",
            "Train: 27 [1500/1562 ( 96%)]  Loss:  2.155774 (1.8603)  Time: 0.287s,  111.62/s  (0.289s,  110.85/s)  LR: 3.149e-05  Data: 0.004 (0.005)\n",
            "Train: 27 [1550/1562 ( 99%)]  Loss:  1.723446 (1.8586)  Time: 0.286s,  111.93/s  (0.289s,  110.86/s)  LR: 3.149e-05  Data: 0.004 (0.005)\n",
            "Train: 27 [1561/1562 (100%)]  Loss:  1.925712 (1.8571)  Time: 0.371s,   86.15/s  (0.289s,  110.85/s)  LR: 3.149e-05  Data: 0.091 (0.005)\n",
            "Test: [   0/312]  Time: 0.984 (0.984)  Loss:  1.1142 (1.1142)  Acc@1: 59.3750 (59.3750)  Acc@5: 96.8750 (96.8750)\n",
            "Test: [  50/312]  Time: 0.096 (0.115)  Loss:  0.5740 (0.7446)  Acc@1: 81.2500 (76.7157)  Acc@5: 100.0000 (98.6520)\n",
            "Test: [ 100/312]  Time: 0.094 (0.104)  Loss:  1.3272 (1.0364)  Acc@1: 46.8750 (64.8515)  Acc@5: 100.0000 (96.5656)\n",
            "Test: [ 150/312]  Time: 0.094 (0.100)  Loss:  1.3954 (1.1201)  Acc@1: 37.5000 (61.6929)  Acc@5: 100.0000 (96.5646)\n",
            "Test: [ 200/312]  Time: 0.095 (0.098)  Loss:  0.8631 (1.0940)  Acc@1: 78.1250 (63.2618)  Acc@5: 100.0000 (96.6418)\n",
            "Test: [ 250/312]  Time: 0.098 (0.097)  Loss:  0.4928 (1.0179)  Acc@1: 96.8750 (66.7082)  Acc@5: 100.0000 (96.8625)\n",
            "Test: [ 300/312]  Time: 0.086 (0.096)  Loss:  0.3552 (0.9510)  Acc@1: 96.8750 (69.6221)  Acc@5: 100.0000 (97.1346)\n",
            "Test: [ 312/312]  Time: 0.131 (0.096)  Loss:  0.5610 (0.9371)  Acc@1: 87.5000 (70.2000)  Acc@5: 100.0000 (97.2300)\n",
            "Test (EMA): [   0/312]  Time: 0.900 (0.900)  Loss:  1.4198 (1.4198)  Acc@1: 53.1250 (53.1250)  Acc@5: 96.8750 (96.8750)\n",
            "Test (EMA): [  50/312]  Time: 0.087 (0.113)  Loss:  1.0700 (1.1013)  Acc@1: 71.8750 (70.3431)  Acc@5: 100.0000 (96.6299)\n",
            "Test (EMA): [ 100/312]  Time: 0.089 (0.103)  Loss:  1.4448 (1.3114)  Acc@1: 56.2500 (57.4257)  Acc@5: 96.8750 (95.9777)\n",
            "Test (EMA): [ 150/312]  Time: 0.105 (0.100)  Loss:  1.6877 (1.3567)  Acc@1: 31.2500 (56.1051)  Acc@5: 100.0000 (96.1714)\n",
            "Test (EMA): [ 200/312]  Time: 0.089 (0.098)  Loss:  0.8094 (1.3729)  Acc@1: 84.3750 (54.0267)  Acc@5: 100.0000 (96.1132)\n",
            "Test (EMA): [ 250/312]  Time: 0.093 (0.097)  Loss:  1.0219 (1.3096)  Acc@1: 71.8750 (57.5075)  Acc@5: 96.8750 (95.9537)\n",
            "Test (EMA): [ 300/312]  Time: 0.086 (0.096)  Loss:  0.7335 (1.2632)  Acc@1: 93.7500 (60.3821)  Acc@5: 100.0000 (96.1067)\n",
            "Test (EMA): [ 312/312]  Time: 0.137 (0.096)  Loss:  1.0645 (1.2527)  Acc@1: 75.0000 (61.0400)  Acc@5: 93.7500 (96.1700)\n",
            "Current checkpoints:\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-27.pth.tar', 61.04)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-26.pth.tar', 60.02)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-25.pth.tar', 58.95)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-24.pth.tar', 57.75)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-23.pth.tar', 56.39)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-22.pth.tar', 54.72)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-21.pth.tar', 52.8)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-20.pth.tar', 50.83)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-19.pth.tar', 48.7)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-18.pth.tar', 46.37)\n",
            "\n",
            "Train: 28 [   0/1562 (  0%)]  Loss:  1.455263 (1.4553)  Time: 1.684s,   19.00/s  (1.684s,   19.00/s)  LR: 2.855e-05  Data: 1.164 (1.164)\n",
            "Train: 28 [  50/1562 (  3%)]  Loss:  1.607232 (1.9086)  Time: 0.289s,  110.68/s  (0.321s,   99.81/s)  LR: 2.855e-05  Data: 0.004 (0.028)\n",
            "Train: 28 [ 100/1562 (  6%)]  Loss:  1.413340 (1.8502)  Time: 0.287s,  111.37/s  (0.305s,  105.05/s)  LR: 2.855e-05  Data: 0.004 (0.016)\n",
            "Train: 28 [ 150/1562 ( 10%)]  Loss:  1.951747 (1.8553)  Time: 0.287s,  111.66/s  (0.299s,  106.94/s)  LR: 2.855e-05  Data: 0.004 (0.012)\n",
            "Train: 28 [ 200/1562 ( 13%)]  Loss:  1.814756 (1.8383)  Time: 0.290s,  110.52/s  (0.296s,  107.96/s)  LR: 2.855e-05  Data: 0.004 (0.010)\n",
            "Train: 28 [ 250/1562 ( 16%)]  Loss:  1.674165 (1.8364)  Time: 0.286s,  111.97/s  (0.295s,  108.58/s)  LR: 2.855e-05  Data: 0.004 (0.009)\n",
            "Train: 28 [ 300/1562 ( 19%)]  Loss:  2.199629 (1.8387)  Time: 0.286s,  111.81/s  (0.293s,  109.04/s)  LR: 2.855e-05  Data: 0.004 (0.008)\n",
            "Train: 28 [ 350/1562 ( 22%)]  Loss:  1.796711 (1.8201)  Time: 0.287s,  111.67/s  (0.293s,  109.37/s)  LR: 2.855e-05  Data: 0.004 (0.007)\n",
            "Train: 28 [ 400/1562 ( 26%)]  Loss:  2.146513 (1.8096)  Time: 0.294s,  108.75/s  (0.292s,  109.59/s)  LR: 2.855e-05  Data: 0.004 (0.007)\n",
            "Train: 28 [ 450/1562 ( 29%)]  Loss:  2.158111 (1.8077)  Time: 0.290s,  110.42/s  (0.292s,  109.76/s)  LR: 2.855e-05  Data: 0.004 (0.007)\n",
            "Train: 28 [ 500/1562 ( 32%)]  Loss:  1.516708 (1.8068)  Time: 0.290s,  110.46/s  (0.291s,  109.89/s)  LR: 2.855e-05  Data: 0.004 (0.006)\n",
            "Train: 28 [ 550/1562 ( 35%)]  Loss:  1.647453 (1.8000)  Time: 0.289s,  110.63/s  (0.291s,  109.99/s)  LR: 2.855e-05  Data: 0.004 (0.006)\n",
            "Train: 28 [ 600/1562 ( 38%)]  Loss:  1.941742 (1.7930)  Time: 0.287s,  111.61/s  (0.291s,  110.10/s)  LR: 2.855e-05  Data: 0.004 (0.006)\n",
            "Train: 28 [ 650/1562 ( 42%)]  Loss:  1.458100 (1.7948)  Time: 0.287s,  111.31/s  (0.290s,  110.19/s)  LR: 2.855e-05  Data: 0.004 (0.006)\n",
            "Train: 28 [ 700/1562 ( 45%)]  Loss:  1.652456 (1.7984)  Time: 0.289s,  110.65/s  (0.290s,  110.26/s)  LR: 2.855e-05  Data: 0.004 (0.006)\n",
            "Train: 28 [ 750/1562 ( 48%)]  Loss:  1.598782 (1.8036)  Time: 0.288s,  110.92/s  (0.290s,  110.33/s)  LR: 2.855e-05  Data: 0.004 (0.006)\n",
            "Train: 28 [ 800/1562 ( 51%)]  Loss:  1.614100 (1.8067)  Time: 0.287s,  111.60/s  (0.290s,  110.38/s)  LR: 2.855e-05  Data: 0.004 (0.005)\n",
            "Train: 28 [ 850/1562 ( 54%)]  Loss:  1.928306 (1.8142)  Time: 0.286s,  111.70/s  (0.290s,  110.44/s)  LR: 2.855e-05  Data: 0.004 (0.005)\n",
            "Train: 28 [ 900/1562 ( 58%)]  Loss:  1.661814 (1.8180)  Time: 0.287s,  111.53/s  (0.290s,  110.48/s)  LR: 2.855e-05  Data: 0.004 (0.005)\n",
            "Train: 28 [ 950/1562 ( 61%)]  Loss:  1.628832 (1.8167)  Time: 0.293s,  109.13/s  (0.290s,  110.50/s)  LR: 2.855e-05  Data: 0.004 (0.005)\n",
            "Train: 28 [1000/1562 ( 64%)]  Loss:  1.983068 (1.8183)  Time: 0.287s,  111.57/s  (0.289s,  110.54/s)  LR: 2.855e-05  Data: 0.004 (0.005)\n",
            "Train: 28 [1050/1562 ( 67%)]  Loss:  1.774764 (1.8244)  Time: 0.291s,  109.87/s  (0.289s,  110.55/s)  LR: 2.855e-05  Data: 0.009 (0.005)\n",
            "Train: 28 [1100/1562 ( 70%)]  Loss:  2.182005 (1.8271)  Time: 0.287s,  111.55/s  (0.289s,  110.57/s)  LR: 2.855e-05  Data: 0.004 (0.005)\n",
            "Train: 28 [1150/1562 ( 74%)]  Loss:  2.157515 (1.8377)  Time: 0.287s,  111.60/s  (0.289s,  110.60/s)  LR: 2.855e-05  Data: 0.005 (0.005)\n",
            "Train: 28 [1200/1562 ( 77%)]  Loss:  1.519414 (1.8446)  Time: 0.287s,  111.48/s  (0.289s,  110.62/s)  LR: 2.855e-05  Data: 0.004 (0.005)\n",
            "Train: 28 [1250/1562 ( 80%)]  Loss:  2.054567 (1.8443)  Time: 0.286s,  111.84/s  (0.289s,  110.64/s)  LR: 2.855e-05  Data: 0.004 (0.005)\n",
            "Train: 28 [1300/1562 ( 83%)]  Loss:  1.525049 (1.8477)  Time: 0.287s,  111.59/s  (0.289s,  110.67/s)  LR: 2.855e-05  Data: 0.004 (0.005)\n",
            "Train: 28 [1350/1562 ( 86%)]  Loss:  2.066020 (1.8480)  Time: 0.287s,  111.57/s  (0.289s,  110.69/s)  LR: 2.855e-05  Data: 0.004 (0.005)\n",
            "Train: 28 [1400/1562 ( 90%)]  Loss:  1.951410 (1.8429)  Time: 0.286s,  111.79/s  (0.289s,  110.72/s)  LR: 2.855e-05  Data: 0.004 (0.005)\n",
            "Train: 28 [1450/1562 ( 93%)]  Loss:  2.105258 (1.8453)  Time: 0.286s,  111.77/s  (0.289s,  110.74/s)  LR: 2.855e-05  Data: 0.004 (0.005)\n",
            "Train: 28 [1500/1562 ( 96%)]  Loss:  2.004987 (1.8460)  Time: 0.286s,  111.72/s  (0.289s,  110.75/s)  LR: 2.855e-05  Data: 0.004 (0.005)\n",
            "Train: 28 [1550/1562 ( 99%)]  Loss:  1.656838 (1.8455)  Time: 0.284s,  112.62/s  (0.289s,  110.77/s)  LR: 2.855e-05  Data: 0.003 (0.005)\n",
            "Train: 28 [1561/1562 (100%)]  Loss:  1.925737 (1.8443)  Time: 0.381s,   84.07/s  (0.289s,  110.76/s)  LR: 2.855e-05  Data: 0.089 (0.005)\n",
            "Test: [   0/312]  Time: 0.932 (0.932)  Loss:  1.1604 (1.1604)  Acc@1: 59.3750 (59.3750)  Acc@5: 96.8750 (96.8750)\n",
            "Test: [  50/312]  Time: 0.101 (0.114)  Loss:  0.6472 (0.7453)  Acc@1: 78.1250 (76.6544)  Acc@5: 100.0000 (98.5907)\n",
            "Test: [ 100/312]  Time: 0.087 (0.103)  Loss:  1.2993 (0.9567)  Acc@1: 46.8750 (68.7500)  Acc@5: 100.0000 (97.5248)\n",
            "Test: [ 150/312]  Time: 0.108 (0.100)  Loss:  1.2827 (1.0661)  Acc@1: 50.0000 (64.6730)  Acc@5: 100.0000 (97.3717)\n",
            "Test: [ 200/312]  Time: 0.093 (0.098)  Loss:  0.8465 (1.0732)  Acc@1: 75.0000 (64.5367)  Acc@5: 100.0000 (97.1238)\n",
            "Test: [ 250/312]  Time: 0.089 (0.097)  Loss:  0.5083 (1.0074)  Acc@1: 90.6250 (67.6295)  Acc@5: 100.0000 (97.1987)\n",
            "Test: [ 300/312]  Time: 0.086 (0.096)  Loss:  0.3082 (0.9402)  Acc@1: 93.7500 (70.3800)  Acc@5: 100.0000 (97.4045)\n",
            "Test: [ 312/312]  Time: 0.130 (0.096)  Loss:  0.4576 (0.9230)  Acc@1: 87.5000 (71.0500)  Acc@5: 100.0000 (97.4900)\n",
            "Test (EMA): [   0/312]  Time: 0.984 (0.984)  Loss:  1.3874 (1.3874)  Acc@1: 53.1250 (53.1250)  Acc@5: 96.8750 (96.8750)\n",
            "Test (EMA): [  50/312]  Time: 0.093 (0.112)  Loss:  1.0174 (1.0630)  Acc@1: 71.8750 (70.6495)  Acc@5: 100.0000 (96.6912)\n",
            "Test (EMA): [ 100/312]  Time: 0.096 (0.102)  Loss:  1.4246 (1.2765)  Acc@1: 56.2500 (58.4777)  Acc@5: 96.8750 (96.0087)\n",
            "Test (EMA): [ 150/312]  Time: 0.096 (0.099)  Loss:  1.6779 (1.3278)  Acc@1: 31.2500 (56.7881)  Acc@5: 100.0000 (96.2127)\n",
            "Test (EMA): [ 200/312]  Time: 0.095 (0.098)  Loss:  0.8050 (1.3449)  Acc@1: 84.3750 (54.8818)  Acc@5: 100.0000 (96.2376)\n",
            "Test (EMA): [ 250/312]  Time: 0.087 (0.096)  Loss:  0.9877 (1.2805)  Acc@1: 71.8750 (58.4039)  Acc@5: 96.8750 (96.1280)\n",
            "Test (EMA): [ 300/312]  Time: 0.086 (0.096)  Loss:  0.6918 (1.2333)  Acc@1: 93.7500 (61.2645)  Acc@5: 100.0000 (96.2625)\n",
            "Test (EMA): [ 312/312]  Time: 0.136 (0.096)  Loss:  1.0219 (1.2222)  Acc@1: 75.0000 (61.9600)  Acc@5: 93.7500 (96.3200)\n",
            "Current checkpoints:\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-28.pth.tar', 61.96)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-27.pth.tar', 61.04)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-26.pth.tar', 60.02)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-25.pth.tar', 58.95)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-24.pth.tar', 57.75)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-23.pth.tar', 56.39)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-22.pth.tar', 54.72)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-21.pth.tar', 52.8)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-20.pth.tar', 50.83)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-19.pth.tar', 48.7)\n",
            "\n",
            "Train: 29 [   0/1562 (  0%)]  Loss:  1.456201 (1.4562)  Time: 1.768s,   18.10/s  (1.768s,   18.10/s)  LR: 2.577e-05  Data: 1.300 (1.300)\n",
            "Train: 29 [  50/1562 (  3%)]  Loss:  1.353403 (1.8793)  Time: 0.287s,  111.40/s  (0.320s,   99.87/s)  LR: 2.577e-05  Data: 0.005 (0.030)\n",
            "Train: 29 [ 100/1562 (  6%)]  Loss:  1.667439 (1.8255)  Time: 0.290s,  110.19/s  (0.304s,  105.20/s)  LR: 2.577e-05  Data: 0.004 (0.017)\n",
            "Train: 29 [ 150/1562 ( 10%)]  Loss:  2.070190 (1.8411)  Time: 0.287s,  111.68/s  (0.298s,  107.23/s)  LR: 2.577e-05  Data: 0.004 (0.013)\n",
            "Train: 29 [ 200/1562 ( 13%)]  Loss:  2.258853 (1.8286)  Time: 0.286s,  111.88/s  (0.296s,  108.18/s)  LR: 2.577e-05  Data: 0.004 (0.010)\n",
            "Train: 29 [ 250/1562 ( 16%)]  Loss:  1.609885 (1.8327)  Time: 0.286s,  111.75/s  (0.294s,  108.82/s)  LR: 2.577e-05  Data: 0.004 (0.009)\n",
            "Train: 29 [ 300/1562 ( 19%)]  Loss:  1.914985 (1.8392)  Time: 0.292s,  109.59/s  (0.293s,  109.19/s)  LR: 2.577e-05  Data: 0.004 (0.008)\n",
            "Train: 29 [ 350/1562 ( 22%)]  Loss:  1.882113 (1.8220)  Time: 0.286s,  111.75/s  (0.292s,  109.51/s)  LR: 2.577e-05  Data: 0.004 (0.008)\n",
            "Train: 29 [ 400/1562 ( 26%)]  Loss:  2.218727 (1.8103)  Time: 0.287s,  111.54/s  (0.292s,  109.72/s)  LR: 2.577e-05  Data: 0.004 (0.007)\n",
            "Train: 29 [ 450/1562 ( 29%)]  Loss:  1.852078 (1.8060)  Time: 0.288s,  111.16/s  (0.291s,  109.90/s)  LR: 2.577e-05  Data: 0.004 (0.007)\n",
            "Train: 29 [ 500/1562 ( 32%)]  Loss:  1.683530 (1.8060)  Time: 0.287s,  111.34/s  (0.291s,  110.05/s)  LR: 2.577e-05  Data: 0.004 (0.006)\n",
            "Train: 29 [ 550/1562 ( 35%)]  Loss:  1.935597 (1.7999)  Time: 0.287s,  111.68/s  (0.290s,  110.17/s)  LR: 2.577e-05  Data: 0.004 (0.006)\n",
            "Train: 29 [ 600/1562 ( 38%)]  Loss:  1.873335 (1.7949)  Time: 0.289s,  110.55/s  (0.290s,  110.26/s)  LR: 2.577e-05  Data: 0.004 (0.006)\n",
            "Train: 29 [ 650/1562 ( 42%)]  Loss:  1.668251 (1.7999)  Time: 0.286s,  111.76/s  (0.290s,  110.34/s)  LR: 2.577e-05  Data: 0.004 (0.006)\n",
            "Train: 29 [ 700/1562 ( 45%)]  Loss:  1.540495 (1.8028)  Time: 0.286s,  111.78/s  (0.290s,  110.39/s)  LR: 2.577e-05  Data: 0.004 (0.006)\n",
            "Train: 29 [ 750/1562 ( 48%)]  Loss:  1.639184 (1.8073)  Time: 0.294s,  108.76/s  (0.290s,  110.44/s)  LR: 2.577e-05  Data: 0.004 (0.006)\n",
            "Train: 29 [ 800/1562 ( 51%)]  Loss:  1.680634 (1.8096)  Time: 0.286s,  111.96/s  (0.290s,  110.48/s)  LR: 2.577e-05  Data: 0.004 (0.006)\n",
            "Train: 29 [ 850/1562 ( 54%)]  Loss:  2.063765 (1.8170)  Time: 0.286s,  111.85/s  (0.290s,  110.51/s)  LR: 2.577e-05  Data: 0.004 (0.005)\n",
            "Train: 29 [ 900/1562 ( 58%)]  Loss:  1.629390 (1.8201)  Time: 0.286s,  111.83/s  (0.289s,  110.54/s)  LR: 2.577e-05  Data: 0.004 (0.005)\n",
            "Train: 29 [ 950/1562 ( 61%)]  Loss:  1.758467 (1.8174)  Time: 0.286s,  111.75/s  (0.289s,  110.58/s)  LR: 2.577e-05  Data: 0.004 (0.005)\n",
            "Train: 29 [1000/1562 ( 64%)]  Loss:  1.810991 (1.8206)  Time: 0.287s,  111.63/s  (0.289s,  110.61/s)  LR: 2.577e-05  Data: 0.004 (0.005)\n",
            "Train: 29 [1050/1562 ( 67%)]  Loss:  1.513692 (1.8254)  Time: 0.286s,  111.72/s  (0.289s,  110.65/s)  LR: 2.577e-05  Data: 0.004 (0.005)\n",
            "Train: 29 [1100/1562 ( 70%)]  Loss:  1.997589 (1.8280)  Time: 0.286s,  111.82/s  (0.289s,  110.68/s)  LR: 2.577e-05  Data: 0.004 (0.005)\n",
            "Train: 29 [1150/1562 ( 74%)]  Loss:  2.100935 (1.8378)  Time: 0.292s,  109.73/s  (0.289s,  110.70/s)  LR: 2.577e-05  Data: 0.004 (0.005)\n",
            "Train: 29 [1200/1562 ( 77%)]  Loss:  1.576085 (1.8446)  Time: 0.286s,  111.82/s  (0.289s,  110.72/s)  LR: 2.577e-05  Data: 0.004 (0.005)\n",
            "Train: 29 [1250/1562 ( 80%)]  Loss:  2.202291 (1.8443)  Time: 0.287s,  111.49/s  (0.289s,  110.74/s)  LR: 2.577e-05  Data: 0.004 (0.005)\n",
            "Train: 29 [1300/1562 ( 83%)]  Loss:  1.749463 (1.8481)  Time: 0.289s,  110.90/s  (0.289s,  110.76/s)  LR: 2.577e-05  Data: 0.004 (0.005)\n",
            "Train: 29 [1350/1562 ( 86%)]  Loss:  1.920918 (1.8495)  Time: 0.290s,  110.19/s  (0.289s,  110.77/s)  LR: 2.577e-05  Data: 0.004 (0.005)\n",
            "Train: 29 [1400/1562 ( 90%)]  Loss:  1.769456 (1.8446)  Time: 0.287s,  111.58/s  (0.289s,  110.77/s)  LR: 2.577e-05  Data: 0.004 (0.005)\n",
            "Train: 29 [1450/1562 ( 93%)]  Loss:  2.035526 (1.8475)  Time: 0.286s,  111.73/s  (0.289s,  110.78/s)  LR: 2.577e-05  Data: 0.004 (0.005)\n",
            "Train: 29 [1500/1562 ( 96%)]  Loss:  2.103540 (1.8492)  Time: 0.287s,  111.44/s  (0.289s,  110.79/s)  LR: 2.577e-05  Data: 0.004 (0.005)\n",
            "Train: 29 [1550/1562 ( 99%)]  Loss:  1.487737 (1.8476)  Time: 0.284s,  112.66/s  (0.289s,  110.81/s)  LR: 2.577e-05  Data: 0.003 (0.005)\n",
            "Train: 29 [1561/1562 (100%)]  Loss:  1.986686 (1.8459)  Time: 0.370s,   86.38/s  (0.289s,  110.80/s)  LR: 2.577e-05  Data: 0.089 (0.005)\n",
            "Test: [   0/312]  Time: 0.931 (0.931)  Loss:  1.1295 (1.1295)  Acc@1: 62.5000 (62.5000)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [  50/312]  Time: 0.091 (0.113)  Loss:  0.6017 (0.7611)  Acc@1: 81.2500 (77.0221)  Acc@5: 100.0000 (98.4069)\n",
            "Test: [ 100/312]  Time: 0.105 (0.103)  Loss:  1.1944 (0.9074)  Acc@1: 59.3750 (71.0396)  Acc@5: 100.0000 (97.9270)\n",
            "Test: [ 150/312]  Time: 0.094 (0.100)  Loss:  1.5284 (1.0582)  Acc@1: 34.3750 (64.5695)  Acc@5: 96.8750 (97.6614)\n",
            "Test: [ 200/312]  Time: 0.090 (0.098)  Loss:  0.9033 (1.0419)  Acc@1: 68.7500 (65.2985)  Acc@5: 100.0000 (97.7146)\n",
            "Test: [ 250/312]  Time: 0.098 (0.097)  Loss:  0.4761 (0.9811)  Acc@1: 96.8750 (68.4138)  Acc@5: 100.0000 (97.7963)\n",
            "Test: [ 300/312]  Time: 0.085 (0.096)  Loss:  0.3498 (0.9237)  Acc@1: 96.8750 (70.8472)  Acc@5: 100.0000 (97.7886)\n",
            "Test: [ 312/312]  Time: 0.133 (0.096)  Loss:  0.4507 (0.9096)  Acc@1: 87.5000 (71.4700)  Acc@5: 100.0000 (97.8300)\n",
            "Test (EMA): [   0/312]  Time: 0.894 (0.894)  Loss:  1.3557 (1.3557)  Acc@1: 53.1250 (53.1250)  Acc@5: 96.8750 (96.8750)\n",
            "Test (EMA): [  50/312]  Time: 0.091 (0.114)  Loss:  0.9708 (1.0274)  Acc@1: 75.0000 (71.4461)  Acc@5: 100.0000 (97.1201)\n",
            "Test (EMA): [ 100/312]  Time: 0.087 (0.103)  Loss:  1.4058 (1.2437)  Acc@1: 59.3750 (59.6535)  Acc@5: 96.8750 (96.4109)\n",
            "Test (EMA): [ 150/312]  Time: 0.096 (0.099)  Loss:  1.6662 (1.3006)  Acc@1: 25.0000 (57.6780)  Acc@5: 100.0000 (96.4404)\n",
            "Test (EMA): [ 200/312]  Time: 0.095 (0.098)  Loss:  0.8010 (1.3190)  Acc@1: 84.3750 (55.7836)  Acc@5: 100.0000 (96.4086)\n",
            "Test (EMA): [ 250/312]  Time: 0.094 (0.097)  Loss:  0.9558 (1.2531)  Acc@1: 75.0000 (59.3750)  Acc@5: 96.8750 (96.3272)\n",
            "Test (EMA): [ 300/312]  Time: 0.086 (0.096)  Loss:  0.6523 (1.2053)  Acc@1: 93.7500 (62.1678)  Acc@5: 100.0000 (96.4597)\n",
            "Test (EMA): [ 312/312]  Time: 0.130 (0.096)  Loss:  0.9800 (1.1938)  Acc@1: 75.0000 (62.8600)  Acc@5: 93.7500 (96.5100)\n",
            "Current checkpoints:\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-29.pth.tar', 62.86)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-28.pth.tar', 61.96)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-27.pth.tar', 61.04)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-26.pth.tar', 60.02)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-25.pth.tar', 58.95)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-24.pth.tar', 57.75)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-23.pth.tar', 56.39)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-22.pth.tar', 54.72)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-21.pth.tar', 52.8)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-20.pth.tar', 50.83)\n",
            "\n",
            "Train: 30 [   0/1562 (  0%)]  Loss:  1.539980 (1.5400)  Time: 1.679s,   19.06/s  (1.679s,   19.06/s)  LR: 2.318e-05  Data: 1.212 (1.212)\n",
            "Train: 30 [  50/1562 (  3%)]  Loss:  1.564043 (1.8863)  Time: 0.290s,  110.22/s  (0.318s,  100.64/s)  LR: 2.318e-05  Data: 0.004 (0.028)\n",
            "Train: 30 [ 100/1562 (  6%)]  Loss:  1.508427 (1.8259)  Time: 0.287s,  111.67/s  (0.303s,  105.63/s)  LR: 2.318e-05  Data: 0.004 (0.016)\n",
            "Train: 30 [ 150/1562 ( 10%)]  Loss:  1.888036 (1.8339)  Time: 0.287s,  111.53/s  (0.298s,  107.45/s)  LR: 2.318e-05  Data: 0.004 (0.012)\n",
            "Train: 30 [ 200/1562 ( 13%)]  Loss:  1.893139 (1.8222)  Time: 0.287s,  111.67/s  (0.295s,  108.36/s)  LR: 2.318e-05  Data: 0.004 (0.010)\n",
            "Train: 30 [ 250/1562 ( 16%)]  Loss:  1.982308 (1.8191)  Time: 0.288s,  111.28/s  (0.294s,  108.94/s)  LR: 2.318e-05  Data: 0.004 (0.009)\n",
            "Train: 30 [ 300/1562 ( 19%)]  Loss:  2.048325 (1.8229)  Time: 0.289s,  110.90/s  (0.293s,  109.36/s)  LR: 2.318e-05  Data: 0.004 (0.008)\n",
            "Train: 30 [ 350/1562 ( 22%)]  Loss:  1.858836 (1.8040)  Time: 0.287s,  111.61/s  (0.292s,  109.65/s)  LR: 2.318e-05  Data: 0.004 (0.007)\n",
            "Train: 30 [ 400/1562 ( 26%)]  Loss:  2.338422 (1.7929)  Time: 0.286s,  111.76/s  (0.291s,  109.86/s)  LR: 2.318e-05  Data: 0.004 (0.007)\n",
            "Train: 30 [ 450/1562 ( 29%)]  Loss:  2.071049 (1.7907)  Time: 0.286s,  111.87/s  (0.291s,  109.98/s)  LR: 2.318e-05  Data: 0.004 (0.007)\n",
            "Train: 30 [ 500/1562 ( 32%)]  Loss:  1.687974 (1.7972)  Time: 0.287s,  111.45/s  (0.291s,  110.07/s)  LR: 2.318e-05  Data: 0.004 (0.006)\n",
            "Train: 30 [ 550/1562 ( 35%)]  Loss:  1.707987 (1.7919)  Time: 0.290s,  110.44/s  (0.290s,  110.18/s)  LR: 2.318e-05  Data: 0.004 (0.006)\n",
            "Train: 30 [ 600/1562 ( 38%)]  Loss:  1.929469 (1.7850)  Time: 0.286s,  111.87/s  (0.290s,  110.29/s)  LR: 2.318e-05  Data: 0.004 (0.006)\n",
            "Train: 30 [ 650/1562 ( 42%)]  Loss:  1.659205 (1.7875)  Time: 0.287s,  111.65/s  (0.290s,  110.36/s)  LR: 2.318e-05  Data: 0.004 (0.006)\n",
            "Train: 30 [ 700/1562 ( 45%)]  Loss:  1.778909 (1.7895)  Time: 0.287s,  111.53/s  (0.290s,  110.43/s)  LR: 2.318e-05  Data: 0.004 (0.006)\n",
            "Train: 30 [ 750/1562 ( 48%)]  Loss:  1.460850 (1.7934)  Time: 0.287s,  111.44/s  (0.290s,  110.48/s)  LR: 2.318e-05  Data: 0.004 (0.005)\n",
            "Train: 30 [ 800/1562 ( 51%)]  Loss:  1.435904 (1.7968)  Time: 0.287s,  111.67/s  (0.290s,  110.52/s)  LR: 2.318e-05  Data: 0.004 (0.005)\n",
            "Train: 30 [ 850/1562 ( 54%)]  Loss:  2.094049 (1.8055)  Time: 0.287s,  111.67/s  (0.289s,  110.56/s)  LR: 2.318e-05  Data: 0.004 (0.005)\n",
            "Train: 30 [ 900/1562 ( 58%)]  Loss:  1.547712 (1.8088)  Time: 0.286s,  111.78/s  (0.289s,  110.61/s)  LR: 2.318e-05  Data: 0.004 (0.005)\n",
            "Train: 30 [ 950/1562 ( 61%)]  Loss:  1.547970 (1.8060)  Time: 0.286s,  111.70/s  (0.289s,  110.64/s)  LR: 2.318e-05  Data: 0.004 (0.005)\n",
            "Train: 30 [1000/1562 ( 64%)]  Loss:  2.134266 (1.8103)  Time: 0.287s,  111.46/s  (0.289s,  110.68/s)  LR: 2.318e-05  Data: 0.004 (0.005)\n",
            "Train: 30 [1050/1562 ( 67%)]  Loss:  1.510211 (1.8167)  Time: 0.287s,  111.65/s  (0.289s,  110.70/s)  LR: 2.318e-05  Data: 0.004 (0.005)\n",
            "Train: 30 [1100/1562 ( 70%)]  Loss:  2.104355 (1.8192)  Time: 0.289s,  110.69/s  (0.289s,  110.72/s)  LR: 2.318e-05  Data: 0.004 (0.005)\n",
            "Train: 30 [1150/1562 ( 74%)]  Loss:  2.066700 (1.8288)  Time: 0.290s,  110.54/s  (0.289s,  110.73/s)  LR: 2.318e-05  Data: 0.004 (0.005)\n",
            "Train: 30 [1200/1562 ( 77%)]  Loss:  1.617075 (1.8365)  Time: 0.286s,  111.76/s  (0.289s,  110.74/s)  LR: 2.318e-05  Data: 0.004 (0.005)\n",
            "Train: 30 [1250/1562 ( 80%)]  Loss:  2.089220 (1.8362)  Time: 0.287s,  111.64/s  (0.289s,  110.76/s)  LR: 2.318e-05  Data: 0.004 (0.005)\n",
            "Train: 30 [1300/1562 ( 83%)]  Loss:  1.683908 (1.8407)  Time: 0.289s,  110.77/s  (0.289s,  110.78/s)  LR: 2.318e-05  Data: 0.004 (0.005)\n",
            "Train: 30 [1350/1562 ( 86%)]  Loss:  1.784098 (1.8419)  Time: 0.287s,  111.64/s  (0.289s,  110.79/s)  LR: 2.318e-05  Data: 0.004 (0.005)\n",
            "Train: 30 [1400/1562 ( 90%)]  Loss:  2.091439 (1.8364)  Time: 0.286s,  111.75/s  (0.289s,  110.81/s)  LR: 2.318e-05  Data: 0.004 (0.005)\n",
            "Train: 30 [1450/1562 ( 93%)]  Loss:  1.909384 (1.8388)  Time: 0.287s,  111.48/s  (0.289s,  110.82/s)  LR: 2.318e-05  Data: 0.004 (0.005)\n",
            "Train: 30 [1500/1562 ( 96%)]  Loss:  2.023463 (1.8405)  Time: 0.286s,  111.94/s  (0.289s,  110.84/s)  LR: 2.318e-05  Data: 0.004 (0.005)\n",
            "Train: 30 [1550/1562 ( 99%)]  Loss:  1.487145 (1.8384)  Time: 0.283s,  112.88/s  (0.289s,  110.85/s)  LR: 2.318e-05  Data: 0.003 (0.005)\n",
            "Train: 30 [1561/1562 (100%)]  Loss:  1.983336 (1.8370)  Time: 0.378s,   84.56/s  (0.289s,  110.84/s)  LR: 2.318e-05  Data: 0.089 (0.005)\n",
            "Test: [   0/312]  Time: 0.937 (0.937)  Loss:  1.0070 (1.0070)  Acc@1: 59.3750 (59.3750)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [  50/312]  Time: 0.092 (0.113)  Loss:  0.5569 (0.6779)  Acc@1: 81.2500 (80.5760)  Acc@5: 100.0000 (99.0196)\n",
            "Test: [ 100/312]  Time: 0.090 (0.103)  Loss:  1.1783 (0.9001)  Acc@1: 56.2500 (71.6584)  Acc@5: 100.0000 (97.9270)\n",
            "Test: [ 150/312]  Time: 0.087 (0.099)  Loss:  1.5225 (1.0409)  Acc@1: 34.3750 (65.8320)  Acc@5: 100.0000 (97.4545)\n",
            "Test: [ 200/312]  Time: 0.095 (0.098)  Loss:  0.8034 (1.0559)  Acc@1: 81.2500 (65.1119)  Acc@5: 100.0000 (97.2170)\n",
            "Test: [ 250/312]  Time: 0.093 (0.097)  Loss:  0.4005 (0.9868)  Acc@1: 93.7500 (68.3889)  Acc@5: 100.0000 (97.2859)\n",
            "Test: [ 300/312]  Time: 0.086 (0.096)  Loss:  0.3049 (0.9147)  Acc@1: 96.8750 (71.2728)  Acc@5: 100.0000 (97.4668)\n",
            "Test: [ 312/312]  Time: 0.132 (0.096)  Loss:  0.4184 (0.8995)  Acc@1: 87.5000 (71.9100)  Acc@5: 100.0000 (97.5400)\n",
            "Test (EMA): [   0/312]  Time: 0.904 (0.904)  Loss:  1.3263 (1.3263)  Acc@1: 59.3750 (59.3750)  Acc@5: 96.8750 (96.8750)\n",
            "Test (EMA): [  50/312]  Time: 0.094 (0.113)  Loss:  0.9275 (0.9946)  Acc@1: 75.0000 (72.1201)  Acc@5: 100.0000 (96.9975)\n",
            "Test (EMA): [ 100/312]  Time: 0.095 (0.103)  Loss:  1.3862 (1.2131)  Acc@1: 59.3750 (60.8601)  Acc@5: 96.8750 (96.4418)\n",
            "Test (EMA): [ 150/312]  Time: 0.089 (0.100)  Loss:  1.6556 (1.2754)  Acc@1: 28.1250 (58.7955)  Acc@5: 100.0000 (96.4197)\n",
            "Test (EMA): [ 200/312]  Time: 0.087 (0.098)  Loss:  0.7976 (1.2941)  Acc@1: 84.3750 (57.0274)  Acc@5: 100.0000 (96.4086)\n",
            "Test (EMA): [ 250/312]  Time: 0.093 (0.097)  Loss:  0.9248 (1.2271)  Acc@1: 75.0000 (60.6698)  Acc@5: 96.8750 (96.3645)\n",
            "Test (EMA): [ 300/312]  Time: 0.086 (0.096)  Loss:  0.6151 (1.1787)  Acc@1: 93.7500 (63.2890)  Acc@5: 100.0000 (96.5220)\n",
            "Test (EMA): [ 312/312]  Time: 0.133 (0.096)  Loss:  0.9389 (1.1667)  Acc@1: 75.0000 (63.9900)  Acc@5: 93.7500 (96.5700)\n",
            "Current checkpoints:\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-30.pth.tar', 63.99)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-29.pth.tar', 62.86)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-28.pth.tar', 61.96)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-27.pth.tar', 61.04)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-26.pth.tar', 60.02)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-25.pth.tar', 58.95)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-24.pth.tar', 57.75)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-23.pth.tar', 56.39)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-22.pth.tar', 54.72)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-21.pth.tar', 52.8)\n",
            "\n",
            "Train: 31 [   0/1562 (  0%)]  Loss:  1.428004 (1.4280)  Time: 1.716s,   18.65/s  (1.716s,   18.65/s)  LR: 2.078e-05  Data: 1.218 (1.218)\n",
            "Train: 31 [  50/1562 (  3%)]  Loss:  1.439066 (1.8878)  Time: 0.290s,  110.44/s  (0.320s,  100.09/s)  LR: 2.078e-05  Data: 0.005 (0.028)\n",
            "Train: 31 [ 100/1562 (  6%)]  Loss:  1.418909 (1.8263)  Time: 0.287s,  111.46/s  (0.304s,  105.31/s)  LR: 2.078e-05  Data: 0.004 (0.016)\n",
            "Train: 31 [ 150/1562 ( 10%)]  Loss:  1.904782 (1.8405)  Time: 0.287s,  111.68/s  (0.298s,  107.22/s)  LR: 2.078e-05  Data: 0.004 (0.012)\n",
            "Train: 31 [ 200/1562 ( 13%)]  Loss:  2.041791 (1.8213)  Time: 0.286s,  111.83/s  (0.296s,  108.23/s)  LR: 2.078e-05  Data: 0.004 (0.010)\n",
            "Train: 31 [ 250/1562 ( 16%)]  Loss:  1.327560 (1.8121)  Time: 0.290s,  110.49/s  (0.294s,  108.75/s)  LR: 2.078e-05  Data: 0.004 (0.009)\n",
            "Train: 31 [ 300/1562 ( 19%)]  Loss:  2.175905 (1.8197)  Time: 0.290s,  110.36/s  (0.293s,  109.11/s)  LR: 2.078e-05  Data: 0.004 (0.008)\n",
            "Train: 31 [ 350/1562 ( 22%)]  Loss:  1.832074 (1.8022)  Time: 0.286s,  111.82/s  (0.293s,  109.39/s)  LR: 2.078e-05  Data: 0.004 (0.007)\n",
            "Train: 31 [ 400/1562 ( 26%)]  Loss:  2.169817 (1.7920)  Time: 0.286s,  111.82/s  (0.292s,  109.64/s)  LR: 2.078e-05  Data: 0.004 (0.007)\n",
            "Train: 31 [ 450/1562 ( 29%)]  Loss:  1.959134 (1.7910)  Time: 0.286s,  111.86/s  (0.291s,  109.83/s)  LR: 2.078e-05  Data: 0.004 (0.007)\n",
            "Train: 31 [ 500/1562 ( 32%)]  Loss:  1.416668 (1.7924)  Time: 0.287s,  111.60/s  (0.291s,  109.95/s)  LR: 2.078e-05  Data: 0.004 (0.006)\n",
            "Train: 31 [ 550/1562 ( 35%)]  Loss:  1.932453 (1.7887)  Time: 0.286s,  111.97/s  (0.291s,  110.09/s)  LR: 2.078e-05  Data: 0.004 (0.006)\n",
            "Train: 31 [ 600/1562 ( 38%)]  Loss:  2.039041 (1.7829)  Time: 0.286s,  111.79/s  (0.290s,  110.17/s)  LR: 2.078e-05  Data: 0.004 (0.006)\n",
            "Train: 31 [ 650/1562 ( 42%)]  Loss:  1.672263 (1.7863)  Time: 0.286s,  111.96/s  (0.290s,  110.25/s)  LR: 2.078e-05  Data: 0.004 (0.006)\n",
            "Train: 31 [ 700/1562 ( 45%)]  Loss:  1.594955 (1.7884)  Time: 0.290s,  110.42/s  (0.290s,  110.31/s)  LR: 2.078e-05  Data: 0.004 (0.006)\n",
            "Train: 31 [ 750/1562 ( 48%)]  Loss:  1.608569 (1.7947)  Time: 0.286s,  111.74/s  (0.290s,  110.38/s)  LR: 2.078e-05  Data: 0.004 (0.006)\n",
            "Train: 31 [ 800/1562 ( 51%)]  Loss:  1.799926 (1.7991)  Time: 0.287s,  111.47/s  (0.290s,  110.43/s)  LR: 2.078e-05  Data: 0.004 (0.005)\n",
            "Train: 31 [ 850/1562 ( 54%)]  Loss:  2.175263 (1.8074)  Time: 0.286s,  111.83/s  (0.290s,  110.48/s)  LR: 2.078e-05  Data: 0.004 (0.005)\n",
            "Train: 31 [ 900/1562 ( 58%)]  Loss:  1.582217 (1.8118)  Time: 0.286s,  111.71/s  (0.290s,  110.52/s)  LR: 2.078e-05  Data: 0.004 (0.005)\n",
            "Train: 31 [ 950/1562 ( 61%)]  Loss:  1.616538 (1.8108)  Time: 0.286s,  111.87/s  (0.289s,  110.56/s)  LR: 2.078e-05  Data: 0.004 (0.005)\n",
            "Train: 31 [1000/1562 ( 64%)]  Loss:  1.966142 (1.8127)  Time: 0.286s,  111.76/s  (0.289s,  110.58/s)  LR: 2.078e-05  Data: 0.004 (0.005)\n",
            "Train: 31 [1050/1562 ( 67%)]  Loss:  1.590308 (1.8183)  Time: 0.289s,  110.75/s  (0.289s,  110.61/s)  LR: 2.078e-05  Data: 0.004 (0.005)\n",
            "Train: 31 [1100/1562 ( 70%)]  Loss:  2.162112 (1.8205)  Time: 0.293s,  109.30/s  (0.289s,  110.64/s)  LR: 2.078e-05  Data: 0.004 (0.005)\n",
            "Train: 31 [1150/1562 ( 74%)]  Loss:  2.060546 (1.8294)  Time: 0.286s,  111.71/s  (0.289s,  110.67/s)  LR: 2.078e-05  Data: 0.004 (0.005)\n",
            "Train: 31 [1200/1562 ( 77%)]  Loss:  1.761025 (1.8368)  Time: 0.286s,  111.74/s  (0.289s,  110.68/s)  LR: 2.078e-05  Data: 0.004 (0.005)\n",
            "Train: 31 [1250/1562 ( 80%)]  Loss:  2.038214 (1.8364)  Time: 0.290s,  110.52/s  (0.289s,  110.70/s)  LR: 2.078e-05  Data: 0.004 (0.005)\n",
            "Train: 31 [1300/1562 ( 83%)]  Loss:  1.678914 (1.8399)  Time: 0.286s,  111.79/s  (0.289s,  110.72/s)  LR: 2.078e-05  Data: 0.004 (0.005)\n",
            "Train: 31 [1350/1562 ( 86%)]  Loss:  1.939969 (1.8413)  Time: 0.287s,  111.63/s  (0.289s,  110.74/s)  LR: 2.078e-05  Data: 0.004 (0.005)\n",
            "Train: 31 [1400/1562 ( 90%)]  Loss:  2.145606 (1.8374)  Time: 0.286s,  111.89/s  (0.289s,  110.77/s)  LR: 2.078e-05  Data: 0.004 (0.005)\n",
            "Train: 31 [1450/1562 ( 93%)]  Loss:  2.051680 (1.8394)  Time: 0.296s,  107.93/s  (0.289s,  110.78/s)  LR: 2.078e-05  Data: 0.004 (0.005)\n",
            "Train: 31 [1500/1562 ( 96%)]  Loss:  2.203637 (1.8401)  Time: 0.287s,  111.43/s  (0.289s,  110.79/s)  LR: 2.078e-05  Data: 0.004 (0.005)\n",
            "Train: 31 [1550/1562 ( 99%)]  Loss:  1.543710 (1.8382)  Time: 0.284s,  112.83/s  (0.289s,  110.81/s)  LR: 2.078e-05  Data: 0.003 (0.005)\n",
            "Train: 31 [1561/1562 (100%)]  Loss:  1.519867 (1.8367)  Time: 0.370s,   86.44/s  (0.289s,  110.80/s)  LR: 2.078e-05  Data: 0.089 (0.005)\n",
            "Test: [   0/312]  Time: 0.928 (0.928)  Loss:  0.9701 (0.9701)  Acc@1: 71.8750 (71.8750)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [  50/312]  Time: 0.101 (0.112)  Loss:  0.5322 (0.6515)  Acc@1: 87.5000 (81.9853)  Acc@5: 100.0000 (98.8358)\n",
            "Test: [ 100/312]  Time: 0.093 (0.102)  Loss:  1.2129 (0.8705)  Acc@1: 62.5000 (73.1126)  Acc@5: 100.0000 (98.1745)\n",
            "Test: [ 150/312]  Time: 0.096 (0.099)  Loss:  1.4134 (1.0104)  Acc@1: 53.1250 (67.4048)  Acc@5: 96.8750 (97.7442)\n",
            "Test: [ 200/312]  Time: 0.094 (0.098)  Loss:  0.8996 (1.0282)  Acc@1: 78.1250 (66.5889)  Acc@5: 100.0000 (97.5435)\n",
            "Test: [ 250/312]  Time: 0.087 (0.097)  Loss:  0.5140 (0.9677)  Acc@1: 93.7500 (69.4348)  Acc@5: 100.0000 (97.5847)\n",
            "Test: [ 300/312]  Time: 0.086 (0.096)  Loss:  0.3296 (0.9153)  Acc@1: 96.8750 (71.4390)  Acc@5: 100.0000 (97.7056)\n",
            "Test: [ 312/312]  Time: 0.131 (0.096)  Loss:  0.4392 (0.8997)  Acc@1: 87.5000 (72.0200)  Acc@5: 100.0000 (97.7800)\n",
            "Test (EMA): [   0/312]  Time: 0.848 (0.848)  Loss:  1.2983 (1.2983)  Acc@1: 62.5000 (62.5000)  Acc@5: 96.8750 (96.8750)\n",
            "Test (EMA): [  50/312]  Time: 0.091 (0.112)  Loss:  0.8880 (0.9638)  Acc@1: 75.0000 (72.7328)  Acc@5: 100.0000 (97.1201)\n",
            "Test (EMA): [ 100/312]  Time: 0.093 (0.102)  Loss:  1.3717 (1.1843)  Acc@1: 62.5000 (61.7265)  Acc@5: 96.8750 (96.5347)\n",
            "Test (EMA): [ 150/312]  Time: 0.089 (0.099)  Loss:  1.6458 (1.2525)  Acc@1: 31.2500 (59.5406)  Acc@5: 100.0000 (96.5439)\n",
            "Test (EMA): [ 200/312]  Time: 0.087 (0.098)  Loss:  0.7940 (1.2713)  Acc@1: 84.3750 (57.8358)  Acc@5: 100.0000 (96.5174)\n",
            "Test (EMA): [ 250/312]  Time: 0.101 (0.097)  Loss:  0.8936 (1.2031)  Acc@1: 75.0000 (61.4417)  Acc@5: 96.8750 (96.5015)\n",
            "Test (EMA): [ 300/312]  Time: 0.086 (0.096)  Loss:  0.5829 (1.1540)  Acc@1: 93.7500 (64.0262)  Acc@5: 100.0000 (96.6570)\n",
            "Test (EMA): [ 312/312]  Time: 0.130 (0.096)  Loss:  0.9019 (1.1416)  Acc@1: 75.0000 (64.7200)  Acc@5: 100.0000 (96.7200)\n",
            "Current checkpoints:\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-31.pth.tar', 64.72)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-30.pth.tar', 63.99)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-29.pth.tar', 62.86)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-28.pth.tar', 61.96)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-27.pth.tar', 61.04)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-26.pth.tar', 60.02)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-25.pth.tar', 58.95)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-24.pth.tar', 57.75)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-23.pth.tar', 56.39)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-22.pth.tar', 54.72)\n",
            "\n",
            "Train: 32 [   0/1562 (  0%)]  Loss:  1.791249 (1.7912)  Time: 1.710s,   18.71/s  (1.710s,   18.71/s)  LR: 1.859e-05  Data: 1.236 (1.236)\n",
            "Train: 32 [  50/1562 (  3%)]  Loss:  1.324218 (1.8601)  Time: 0.290s,  110.32/s  (0.320s,   99.90/s)  LR: 1.859e-05  Data: 0.004 (0.028)\n",
            "Train: 32 [ 100/1562 (  6%)]  Loss:  1.474108 (1.8143)  Time: 0.286s,  111.99/s  (0.304s,  105.22/s)  LR: 1.859e-05  Data: 0.004 (0.016)\n",
            "Train: 32 [ 150/1562 ( 10%)]  Loss:  2.070896 (1.8319)  Time: 0.288s,  111.24/s  (0.299s,  107.12/s)  LR: 1.859e-05  Data: 0.004 (0.012)\n",
            "Train: 32 [ 200/1562 ( 13%)]  Loss:  2.263935 (1.8163)  Time: 0.286s,  111.83/s  (0.296s,  108.14/s)  LR: 1.859e-05  Data: 0.004 (0.010)\n",
            "Train: 32 [ 250/1562 ( 16%)]  Loss:  1.553651 (1.8118)  Time: 0.287s,  111.54/s  (0.294s,  108.75/s)  LR: 1.859e-05  Data: 0.004 (0.009)\n",
            "Train: 32 [ 300/1562 ( 19%)]  Loss:  2.117559 (1.8126)  Time: 0.290s,  110.28/s  (0.293s,  109.15/s)  LR: 1.859e-05  Data: 0.004 (0.008)\n",
            "Train: 32 [ 350/1562 ( 22%)]  Loss:  1.583128 (1.7921)  Time: 0.286s,  111.72/s  (0.292s,  109.40/s)  LR: 1.859e-05  Data: 0.004 (0.007)\n",
            "Train: 32 [ 400/1562 ( 26%)]  Loss:  1.931835 (1.7770)  Time: 0.288s,  111.15/s  (0.292s,  109.64/s)  LR: 1.859e-05  Data: 0.004 (0.007)\n",
            "Train: 32 [ 450/1562 ( 29%)]  Loss:  2.100131 (1.7753)  Time: 0.286s,  111.85/s  (0.291s,  109.85/s)  LR: 1.859e-05  Data: 0.004 (0.007)\n",
            "Train: 32 [ 500/1562 ( 32%)]  Loss:  1.459105 (1.7784)  Time: 0.287s,  111.64/s  (0.291s,  109.99/s)  LR: 1.859e-05  Data: 0.004 (0.006)\n",
            "Train: 32 [ 550/1562 ( 35%)]  Loss:  1.605093 (1.7758)  Time: 0.299s,  107.05/s  (0.291s,  110.10/s)  LR: 1.859e-05  Data: 0.004 (0.006)\n",
            "Train: 32 [ 600/1562 ( 38%)]  Loss:  1.975979 (1.7700)  Time: 0.286s,  111.95/s  (0.290s,  110.20/s)  LR: 1.859e-05  Data: 0.004 (0.006)\n",
            "Train: 32 [ 650/1562 ( 42%)]  Loss:  1.575030 (1.7707)  Time: 0.287s,  111.69/s  (0.290s,  110.29/s)  LR: 1.859e-05  Data: 0.004 (0.006)\n",
            "Train: 32 [ 700/1562 ( 45%)]  Loss:  1.590622 (1.7729)  Time: 0.286s,  111.76/s  (0.290s,  110.37/s)  LR: 1.859e-05  Data: 0.004 (0.006)\n",
            "Train: 32 [ 750/1562 ( 48%)]  Loss:  1.806573 (1.7803)  Time: 0.287s,  111.51/s  (0.290s,  110.41/s)  LR: 1.859e-05  Data: 0.004 (0.006)\n",
            "Train: 32 [ 800/1562 ( 51%)]  Loss:  1.782363 (1.7847)  Time: 0.286s,  111.77/s  (0.290s,  110.46/s)  LR: 1.859e-05  Data: 0.004 (0.005)\n",
            "Train: 32 [ 850/1562 ( 54%)]  Loss:  2.118294 (1.7941)  Time: 0.287s,  111.64/s  (0.290s,  110.50/s)  LR: 1.859e-05  Data: 0.004 (0.005)\n",
            "Train: 32 [ 900/1562 ( 58%)]  Loss:  1.577867 (1.7991)  Time: 0.286s,  111.76/s  (0.290s,  110.53/s)  LR: 1.859e-05  Data: 0.004 (0.005)\n",
            "Train: 32 [ 950/1562 ( 61%)]  Loss:  1.514446 (1.7988)  Time: 0.287s,  111.69/s  (0.289s,  110.57/s)  LR: 1.859e-05  Data: 0.004 (0.005)\n",
            "Train: 32 [1000/1562 ( 64%)]  Loss:  2.102453 (1.8020)  Time: 0.287s,  111.59/s  (0.289s,  110.61/s)  LR: 1.859e-05  Data: 0.004 (0.005)\n",
            "Train: 32 [1050/1562 ( 67%)]  Loss:  1.505701 (1.8084)  Time: 0.287s,  111.56/s  (0.289s,  110.63/s)  LR: 1.859e-05  Data: 0.004 (0.005)\n",
            "Train: 32 [1100/1562 ( 70%)]  Loss:  1.955936 (1.8113)  Time: 0.289s,  110.58/s  (0.289s,  110.66/s)  LR: 1.859e-05  Data: 0.004 (0.005)\n",
            "Train: 32 [1150/1562 ( 74%)]  Loss:  2.052991 (1.8219)  Time: 0.286s,  111.73/s  (0.289s,  110.67/s)  LR: 1.859e-05  Data: 0.004 (0.005)\n",
            "Train: 32 [1200/1562 ( 77%)]  Loss:  1.633505 (1.8315)  Time: 0.289s,  110.66/s  (0.289s,  110.71/s)  LR: 1.859e-05  Data: 0.004 (0.005)\n",
            "Train: 32 [1250/1562 ( 80%)]  Loss:  1.980723 (1.8310)  Time: 0.286s,  111.72/s  (0.289s,  110.72/s)  LR: 1.859e-05  Data: 0.004 (0.005)\n",
            "Train: 32 [1300/1562 ( 83%)]  Loss:  1.878087 (1.8342)  Time: 0.286s,  111.71/s  (0.289s,  110.73/s)  LR: 1.859e-05  Data: 0.004 (0.005)\n",
            "Train: 32 [1350/1562 ( 86%)]  Loss:  1.888642 (1.8353)  Time: 0.286s,  111.76/s  (0.289s,  110.75/s)  LR: 1.859e-05  Data: 0.004 (0.005)\n",
            "Train: 32 [1400/1562 ( 90%)]  Loss:  2.000915 (1.8309)  Time: 0.295s,  108.65/s  (0.289s,  110.76/s)  LR: 1.859e-05  Data: 0.004 (0.005)\n",
            "Train: 32 [1450/1562 ( 93%)]  Loss:  2.003655 (1.8332)  Time: 0.290s,  110.27/s  (0.289s,  110.77/s)  LR: 1.859e-05  Data: 0.004 (0.005)\n",
            "Train: 32 [1500/1562 ( 96%)]  Loss:  2.133468 (1.8348)  Time: 0.286s,  111.74/s  (0.289s,  110.78/s)  LR: 1.859e-05  Data: 0.004 (0.005)\n",
            "Train: 32 [1550/1562 ( 99%)]  Loss:  1.611909 (1.8340)  Time: 0.284s,  112.65/s  (0.289s,  110.80/s)  LR: 1.859e-05  Data: 0.004 (0.005)\n",
            "Train: 32 [1561/1562 (100%)]  Loss:  1.981225 (1.8324)  Time: 0.372s,   85.91/s  (0.289s,  110.79/s)  LR: 1.859e-05  Data: 0.092 (0.005)\n",
            "Test: [   0/312]  Time: 0.849 (0.849)  Loss:  0.9654 (0.9654)  Acc@1: 65.6250 (65.6250)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [  50/312]  Time: 0.094 (0.113)  Loss:  0.6119 (0.6927)  Acc@1: 78.1250 (80.3922)  Acc@5: 96.8750 (98.6520)\n",
            "Test: [ 100/312]  Time: 0.096 (0.103)  Loss:  1.0934 (0.8756)  Acc@1: 71.8750 (72.8651)  Acc@5: 100.0000 (97.9270)\n",
            "Test: [ 150/312]  Time: 0.094 (0.100)  Loss:  1.2657 (0.9652)  Acc@1: 56.2500 (69.7641)  Acc@5: 100.0000 (97.8891)\n",
            "Test: [ 200/312]  Time: 0.098 (0.098)  Loss:  0.7518 (0.9872)  Acc@1: 81.2500 (68.2369)  Acc@5: 100.0000 (97.7767)\n",
            "Test: [ 250/312]  Time: 0.087 (0.097)  Loss:  0.5682 (0.9420)  Acc@1: 93.7500 (70.4806)  Acc@5: 96.8750 (97.7216)\n",
            "Test: [ 300/312]  Time: 0.086 (0.096)  Loss:  0.3769 (0.9016)  Acc@1: 90.6250 (72.1449)  Acc@5: 100.0000 (97.7263)\n",
            "Test: [ 312/312]  Time: 0.132 (0.096)  Loss:  0.4696 (0.8880)  Acc@1: 87.5000 (72.7100)  Acc@5: 100.0000 (97.7800)\n",
            "Test (EMA): [   0/312]  Time: 0.896 (0.896)  Loss:  1.2707 (1.2707)  Acc@1: 65.6250 (65.6250)  Acc@5: 96.8750 (96.8750)\n",
            "Test (EMA): [  50/312]  Time: 0.094 (0.113)  Loss:  0.8501 (0.9343)  Acc@1: 75.0000 (73.3456)  Acc@5: 100.0000 (97.5490)\n",
            "Test (EMA): [ 100/312]  Time: 0.087 (0.103)  Loss:  1.3575 (1.1562)  Acc@1: 62.5000 (62.6547)  Acc@5: 96.8750 (96.7822)\n",
            "Test (EMA): [ 150/312]  Time: 0.094 (0.100)  Loss:  1.6363 (1.2304)  Acc@1: 31.2500 (60.1200)  Acc@5: 100.0000 (96.8129)\n",
            "Test (EMA): [ 200/312]  Time: 0.087 (0.098)  Loss:  0.7909 (1.2494)  Acc@1: 84.3750 (58.4577)  Acc@5: 100.0000 (96.7506)\n",
            "Test (EMA): [ 250/312]  Time: 0.087 (0.097)  Loss:  0.8622 (1.1803)  Acc@1: 81.2500 (62.0393)  Acc@5: 100.0000 (96.7131)\n",
            "Test (EMA): [ 300/312]  Time: 0.086 (0.096)  Loss:  0.5545 (1.1306)  Acc@1: 93.7500 (64.5972)  Acc@5: 100.0000 (96.8439)\n",
            "Test (EMA): [ 312/312]  Time: 0.134 (0.096)  Loss:  0.8667 (1.1180)  Acc@1: 81.2500 (65.3000)  Acc@5: 100.0000 (96.9100)\n",
            "Current checkpoints:\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-32.pth.tar', 65.3)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-31.pth.tar', 64.72)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-30.pth.tar', 63.99)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-29.pth.tar', 62.86)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-28.pth.tar', 61.96)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-27.pth.tar', 61.04)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-26.pth.tar', 60.02)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-25.pth.tar', 58.95)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-24.pth.tar', 57.75)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-23.pth.tar', 56.39)\n",
            "\n",
            "Train: 33 [   0/1562 (  0%)]  Loss:  1.492149 (1.4921)  Time: 1.699s,   18.84/s  (1.699s,   18.84/s)  LR: 1.663e-05  Data: 1.175 (1.175)\n",
            "Train: 33 [  50/1562 (  3%)]  Loss:  1.698381 (1.8484)  Time: 0.287s,  111.60/s  (0.319s,  100.16/s)  LR: 1.663e-05  Data: 0.004 (0.028)\n",
            "Train: 33 [ 100/1562 (  6%)]  Loss:  1.213934 (1.7895)  Time: 0.286s,  111.92/s  (0.304s,  105.29/s)  LR: 1.663e-05  Data: 0.004 (0.016)\n",
            "Train: 33 [ 150/1562 ( 10%)]  Loss:  1.782616 (1.8101)  Time: 0.287s,  111.68/s  (0.298s,  107.22/s)  LR: 1.663e-05  Data: 0.004 (0.012)\n",
            "Train: 33 [ 200/1562 ( 13%)]  Loss:  1.957386 (1.7981)  Time: 0.286s,  111.79/s  (0.296s,  108.17/s)  LR: 1.663e-05  Data: 0.004 (0.010)\n",
            "Train: 33 [ 250/1562 ( 16%)]  Loss:  1.712848 (1.7939)  Time: 0.287s,  111.67/s  (0.294s,  108.72/s)  LR: 1.663e-05  Data: 0.004 (0.009)\n",
            "Train: 33 [ 300/1562 ( 19%)]  Loss:  1.881706 (1.8024)  Time: 0.287s,  111.59/s  (0.293s,  109.12/s)  LR: 1.663e-05  Data: 0.004 (0.008)\n",
            "Train: 33 [ 350/1562 ( 22%)]  Loss:  1.677893 (1.7832)  Time: 0.286s,  111.70/s  (0.292s,  109.41/s)  LR: 1.663e-05  Data: 0.004 (0.007)\n",
            "Train: 33 [ 400/1562 ( 26%)]  Loss:  2.184122 (1.7707)  Time: 0.287s,  111.48/s  (0.292s,  109.63/s)  LR: 1.663e-05  Data: 0.004 (0.007)\n",
            "Train: 33 [ 450/1562 ( 29%)]  Loss:  2.172733 (1.7699)  Time: 0.287s,  111.61/s  (0.292s,  109.76/s)  LR: 1.663e-05  Data: 0.004 (0.007)\n",
            "Train: 33 [ 500/1562 ( 32%)]  Loss:  1.625952 (1.7699)  Time: 0.287s,  111.55/s  (0.291s,  109.89/s)  LR: 1.663e-05  Data: 0.004 (0.006)\n",
            "Train: 33 [ 550/1562 ( 35%)]  Loss:  1.727235 (1.7672)  Time: 0.287s,  111.65/s  (0.291s,  109.99/s)  LR: 1.663e-05  Data: 0.004 (0.006)\n",
            "Train: 33 [ 600/1562 ( 38%)]  Loss:  1.968601 (1.7605)  Time: 0.287s,  111.53/s  (0.291s,  110.08/s)  LR: 1.663e-05  Data: 0.004 (0.006)\n",
            "Train: 33 [ 650/1562 ( 42%)]  Loss:  1.607784 (1.7665)  Time: 0.286s,  111.75/s  (0.290s,  110.17/s)  LR: 1.663e-05  Data: 0.004 (0.006)\n",
            "Train: 33 [ 700/1562 ( 45%)]  Loss:  1.507744 (1.7714)  Time: 0.286s,  111.89/s  (0.290s,  110.26/s)  LR: 1.663e-05  Data: 0.004 (0.006)\n",
            "Train: 33 [ 750/1562 ( 48%)]  Loss:  1.571344 (1.7762)  Time: 0.290s,  110.24/s  (0.290s,  110.33/s)  LR: 1.663e-05  Data: 0.004 (0.006)\n",
            "Train: 33 [ 800/1562 ( 51%)]  Loss:  1.586400 (1.7802)  Time: 0.287s,  111.46/s  (0.290s,  110.38/s)  LR: 1.663e-05  Data: 0.004 (0.005)\n",
            "Train: 33 [ 850/1562 ( 54%)]  Loss:  2.098459 (1.7892)  Time: 0.287s,  111.63/s  (0.290s,  110.41/s)  LR: 1.663e-05  Data: 0.004 (0.005)\n",
            "Train: 33 [ 900/1562 ( 58%)]  Loss:  1.679029 (1.7943)  Time: 0.287s,  111.59/s  (0.290s,  110.46/s)  LR: 1.663e-05  Data: 0.004 (0.005)\n",
            "Train: 33 [ 950/1562 ( 61%)]  Loss:  1.303360 (1.7924)  Time: 0.287s,  111.52/s  (0.290s,  110.50/s)  LR: 1.663e-05  Data: 0.004 (0.005)\n",
            "Train: 33 [1000/1562 ( 64%)]  Loss:  2.046994 (1.7958)  Time: 0.287s,  111.47/s  (0.290s,  110.53/s)  LR: 1.663e-05  Data: 0.004 (0.005)\n",
            "Train: 33 [1050/1562 ( 67%)]  Loss:  1.589044 (1.8026)  Time: 0.298s,  107.29/s  (0.289s,  110.55/s)  LR: 1.663e-05  Data: 0.004 (0.005)\n",
            "Train: 33 [1100/1562 ( 70%)]  Loss:  1.907788 (1.8052)  Time: 0.286s,  111.71/s  (0.289s,  110.58/s)  LR: 1.663e-05  Data: 0.004 (0.005)\n",
            "Train: 33 [1150/1562 ( 74%)]  Loss:  2.024405 (1.8162)  Time: 0.287s,  111.55/s  (0.289s,  110.59/s)  LR: 1.663e-05  Data: 0.004 (0.005)\n",
            "Train: 33 [1200/1562 ( 77%)]  Loss:  1.660155 (1.8234)  Time: 0.287s,  111.56/s  (0.289s,  110.61/s)  LR: 1.663e-05  Data: 0.004 (0.005)\n",
            "Train: 33 [1250/1562 ( 80%)]  Loss:  1.851950 (1.8216)  Time: 0.287s,  111.56/s  (0.289s,  110.63/s)  LR: 1.663e-05  Data: 0.004 (0.005)\n",
            "Train: 33 [1300/1562 ( 83%)]  Loss:  1.717435 (1.8247)  Time: 0.288s,  111.13/s  (0.289s,  110.64/s)  LR: 1.663e-05  Data: 0.004 (0.005)\n",
            "Train: 33 [1350/1562 ( 86%)]  Loss:  1.909945 (1.8263)  Time: 0.286s,  111.72/s  (0.289s,  110.66/s)  LR: 1.663e-05  Data: 0.004 (0.005)\n",
            "Train: 33 [1400/1562 ( 90%)]  Loss:  1.939226 (1.8211)  Time: 0.287s,  111.57/s  (0.289s,  110.68/s)  LR: 1.663e-05  Data: 0.004 (0.005)\n",
            "Train: 33 [1450/1562 ( 93%)]  Loss:  1.764852 (1.8222)  Time: 0.291s,  109.95/s  (0.289s,  110.69/s)  LR: 1.663e-05  Data: 0.004 (0.005)\n",
            "Train: 33 [1500/1562 ( 96%)]  Loss:  2.093390 (1.8242)  Time: 0.294s,  108.69/s  (0.289s,  110.71/s)  LR: 1.663e-05  Data: 0.004 (0.005)\n",
            "Train: 33 [1550/1562 ( 99%)]  Loss:  1.531175 (1.8230)  Time: 0.284s,  112.70/s  (0.289s,  110.72/s)  LR: 1.663e-05  Data: 0.004 (0.005)\n",
            "Train: 33 [1561/1562 (100%)]  Loss:  1.836778 (1.8211)  Time: 0.371s,   86.29/s  (0.289s,  110.71/s)  LR: 1.663e-05  Data: 0.091 (0.005)\n",
            "Test: [   0/312]  Time: 0.910 (0.910)  Loss:  1.0506 (1.0506)  Acc@1: 59.3750 (59.3750)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [  50/312]  Time: 0.093 (0.114)  Loss:  0.5486 (0.7000)  Acc@1: 81.2500 (79.9020)  Acc@5: 100.0000 (98.7132)\n",
            "Test: [ 100/312]  Time: 0.096 (0.103)  Loss:  1.3477 (0.8766)  Acc@1: 59.3750 (72.5557)  Acc@5: 100.0000 (98.2364)\n",
            "Test: [ 150/312]  Time: 0.093 (0.100)  Loss:  1.4005 (1.0379)  Acc@1: 50.0000 (65.7285)  Acc@5: 100.0000 (97.6614)\n",
            "Test: [ 200/312]  Time: 0.094 (0.098)  Loss:  0.8102 (1.0183)  Acc@1: 78.1250 (66.9932)  Acc@5: 100.0000 (97.6213)\n",
            "Test: [ 250/312]  Time: 0.095 (0.097)  Loss:  0.4039 (0.9591)  Acc@1: 96.8750 (69.8581)  Acc@5: 100.0000 (97.6718)\n",
            "Test: [ 300/312]  Time: 0.086 (0.096)  Loss:  0.3095 (0.8948)  Acc@1: 93.7500 (72.4564)  Acc@5: 100.0000 (97.8094)\n",
            "Test: [ 312/312]  Time: 0.140 (0.096)  Loss:  0.4263 (0.8798)  Acc@1: 87.5000 (73.0500)  Acc@5: 100.0000 (97.8700)\n",
            "Test (EMA): [   0/312]  Time: 0.891 (0.891)  Loss:  1.2452 (1.2452)  Acc@1: 65.6250 (65.6250)  Acc@5: 96.8750 (96.8750)\n",
            "Test (EMA): [  50/312]  Time: 0.088 (0.113)  Loss:  0.8172 (0.9081)  Acc@1: 75.0000 (73.9583)  Acc@5: 100.0000 (97.7328)\n",
            "Test (EMA): [ 100/312]  Time: 0.091 (0.103)  Loss:  1.3449 (1.1310)  Acc@1: 62.5000 (63.5210)  Acc@5: 96.8750 (96.9369)\n",
            "Test (EMA): [ 150/312]  Time: 0.094 (0.100)  Loss:  1.6256 (1.2101)  Acc@1: 31.2500 (60.9478)  Acc@5: 100.0000 (96.9785)\n",
            "Test (EMA): [ 200/312]  Time: 0.101 (0.098)  Loss:  0.7868 (1.2294)  Acc@1: 84.3750 (59.3284)  Acc@5: 100.0000 (96.9216)\n",
            "Test (EMA): [ 250/312]  Time: 0.095 (0.097)  Loss:  0.8294 (1.1596)  Acc@1: 84.3750 (62.8735)  Acc@5: 100.0000 (96.9746)\n",
            "Test (EMA): [ 300/312]  Time: 0.086 (0.096)  Loss:  0.5291 (1.1091)  Acc@1: 93.7500 (65.3758)  Acc@5: 100.0000 (97.0515)\n",
            "Test (EMA): [ 312/312]  Time: 0.131 (0.096)  Loss:  0.8331 (1.0963)  Acc@1: 81.2500 (66.0600)  Acc@5: 100.0000 (97.1100)\n",
            "Current checkpoints:\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-33.pth.tar', 66.06)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-32.pth.tar', 65.3)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-31.pth.tar', 64.72)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-30.pth.tar', 63.99)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-29.pth.tar', 62.86)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-28.pth.tar', 61.96)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-27.pth.tar', 61.04)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-26.pth.tar', 60.02)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-25.pth.tar', 58.95)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-24.pth.tar', 57.75)\n",
            "\n",
            "Train: 34 [   0/1562 (  0%)]  Loss:  1.443068 (1.4431)  Time: 1.662s,   19.26/s  (1.662s,   19.26/s)  LR: 1.490e-05  Data: 1.185 (1.185)\n",
            "Train: 34 [  50/1562 (  3%)]  Loss:  1.566661 (1.8828)  Time: 0.289s,  110.58/s  (0.319s,  100.31/s)  LR: 1.490e-05  Data: 0.004 (0.027)\n",
            "Train: 34 [ 100/1562 (  6%)]  Loss:  1.696101 (1.8133)  Time: 0.286s,  111.82/s  (0.303s,  105.49/s)  LR: 1.490e-05  Data: 0.004 (0.016)\n",
            "Train: 34 [ 150/1562 ( 10%)]  Loss:  2.237429 (1.8248)  Time: 0.287s,  111.45/s  (0.298s,  107.25/s)  LR: 1.490e-05  Data: 0.004 (0.012)\n",
            "Train: 34 [ 200/1562 ( 13%)]  Loss:  2.121340 (1.8091)  Time: 0.289s,  110.64/s  (0.296s,  108.16/s)  LR: 1.490e-05  Data: 0.004 (0.010)\n",
            "Train: 34 [ 250/1562 ( 16%)]  Loss:  1.539746 (1.8089)  Time: 0.287s,  111.59/s  (0.294s,  108.68/s)  LR: 1.490e-05  Data: 0.004 (0.009)\n",
            "Train: 34 [ 300/1562 ( 19%)]  Loss:  1.993912 (1.8083)  Time: 0.291s,  110.10/s  (0.293s,  109.07/s)  LR: 1.490e-05  Data: 0.004 (0.008)\n",
            "Train: 34 [ 350/1562 ( 22%)]  Loss:  1.547632 (1.7911)  Time: 0.286s,  111.70/s  (0.293s,  109.37/s)  LR: 1.490e-05  Data: 0.004 (0.007)\n",
            "Train: 34 [ 400/1562 ( 26%)]  Loss:  2.083202 (1.7762)  Time: 0.287s,  111.41/s  (0.292s,  109.59/s)  LR: 1.490e-05  Data: 0.004 (0.007)\n",
            "Train: 34 [ 450/1562 ( 29%)]  Loss:  2.075117 (1.7753)  Time: 0.286s,  111.80/s  (0.292s,  109.77/s)  LR: 1.490e-05  Data: 0.004 (0.006)\n",
            "Train: 34 [ 500/1562 ( 32%)]  Loss:  1.756028 (1.7759)  Time: 0.286s,  111.75/s  (0.291s,  109.91/s)  LR: 1.490e-05  Data: 0.004 (0.006)\n",
            "Train: 34 [ 550/1562 ( 35%)]  Loss:  1.552292 (1.7751)  Time: 0.289s,  110.57/s  (0.291s,  110.01/s)  LR: 1.490e-05  Data: 0.004 (0.006)\n",
            "Train: 34 [ 600/1562 ( 38%)]  Loss:  2.036041 (1.7707)  Time: 0.286s,  111.76/s  (0.291s,  110.11/s)  LR: 1.490e-05  Data: 0.004 (0.006)\n",
            "Train: 34 [ 650/1562 ( 42%)]  Loss:  1.615441 (1.7710)  Time: 0.286s,  111.73/s  (0.290s,  110.20/s)  LR: 1.490e-05  Data: 0.004 (0.006)\n",
            "Train: 34 [ 700/1562 ( 45%)]  Loss:  1.530593 (1.7724)  Time: 0.288s,  111.13/s  (0.290s,  110.26/s)  LR: 1.490e-05  Data: 0.004 (0.006)\n",
            "Train: 34 [ 750/1562 ( 48%)]  Loss:  1.576986 (1.7797)  Time: 0.288s,  111.29/s  (0.290s,  110.31/s)  LR: 1.490e-05  Data: 0.004 (0.005)\n",
            "Train: 34 [ 800/1562 ( 51%)]  Loss:  1.462784 (1.7821)  Time: 0.287s,  111.46/s  (0.290s,  110.36/s)  LR: 1.490e-05  Data: 0.004 (0.005)\n",
            "Train: 34 [ 850/1562 ( 54%)]  Loss:  2.018390 (1.7903)  Time: 0.293s,  109.18/s  (0.290s,  110.39/s)  LR: 1.490e-05  Data: 0.004 (0.005)\n",
            "Train: 34 [ 900/1562 ( 58%)]  Loss:  1.693986 (1.7946)  Time: 0.286s,  111.72/s  (0.290s,  110.41/s)  LR: 1.490e-05  Data: 0.004 (0.005)\n",
            "Train: 34 [ 950/1562 ( 61%)]  Loss:  1.540735 (1.7927)  Time: 0.287s,  111.41/s  (0.290s,  110.45/s)  LR: 1.490e-05  Data: 0.004 (0.005)\n",
            "Train: 34 [1000/1562 ( 64%)]  Loss:  1.957130 (1.7951)  Time: 0.287s,  111.68/s  (0.290s,  110.49/s)  LR: 1.490e-05  Data: 0.004 (0.005)\n",
            "Train: 34 [1050/1562 ( 67%)]  Loss:  1.494946 (1.8009)  Time: 0.289s,  110.64/s  (0.289s,  110.54/s)  LR: 1.490e-05  Data: 0.004 (0.005)\n",
            "Train: 34 [1100/1562 ( 70%)]  Loss:  2.095367 (1.8041)  Time: 0.287s,  111.65/s  (0.289s,  110.57/s)  LR: 1.490e-05  Data: 0.004 (0.005)\n",
            "Train: 34 [1150/1562 ( 74%)]  Loss:  2.052636 (1.8146)  Time: 0.287s,  111.67/s  (0.289s,  110.60/s)  LR: 1.490e-05  Data: 0.004 (0.005)\n",
            "Train: 34 [1200/1562 ( 77%)]  Loss:  1.409602 (1.8216)  Time: 0.287s,  111.45/s  (0.289s,  110.62/s)  LR: 1.490e-05  Data: 0.004 (0.005)\n",
            "Train: 34 [1250/1562 ( 80%)]  Loss:  1.876424 (1.8209)  Time: 0.286s,  111.75/s  (0.289s,  110.64/s)  LR: 1.490e-05  Data: 0.004 (0.005)\n",
            "Train: 34 [1300/1562 ( 83%)]  Loss:  1.702846 (1.8244)  Time: 0.286s,  111.72/s  (0.289s,  110.66/s)  LR: 1.490e-05  Data: 0.004 (0.005)\n",
            "Train: 34 [1350/1562 ( 86%)]  Loss:  1.976940 (1.8270)  Time: 0.287s,  111.68/s  (0.289s,  110.68/s)  LR: 1.490e-05  Data: 0.004 (0.005)\n",
            "Train: 34 [1400/1562 ( 90%)]  Loss:  1.949155 (1.8225)  Time: 0.294s,  108.80/s  (0.289s,  110.69/s)  LR: 1.490e-05  Data: 0.004 (0.005)\n",
            "Train: 34 [1450/1562 ( 93%)]  Loss:  2.055387 (1.8245)  Time: 0.290s,  110.45/s  (0.289s,  110.72/s)  LR: 1.490e-05  Data: 0.004 (0.005)\n",
            "Train: 34 [1500/1562 ( 96%)]  Loss:  2.053941 (1.8267)  Time: 0.292s,  109.56/s  (0.289s,  110.72/s)  LR: 1.490e-05  Data: 0.004 (0.005)\n",
            "Train: 34 [1550/1562 ( 99%)]  Loss:  1.548676 (1.8256)  Time: 0.285s,  112.37/s  (0.289s,  110.75/s)  LR: 1.490e-05  Data: 0.003 (0.005)\n",
            "Train: 34 [1561/1562 (100%)]  Loss:  1.814243 (1.8242)  Time: 0.379s,   84.43/s  (0.289s,  110.73/s)  LR: 1.490e-05  Data: 0.099 (0.005)\n",
            "Test: [   0/312]  Time: 0.973 (0.973)  Loss:  1.2088 (1.2088)  Acc@1: 53.1250 (53.1250)  Acc@5: 96.8750 (96.8750)\n",
            "Test: [  50/312]  Time: 0.091 (0.114)  Loss:  0.5742 (0.7662)  Acc@1: 84.3750 (77.5123)  Acc@5: 100.0000 (98.5294)\n",
            "Test: [ 100/312]  Time: 0.093 (0.104)  Loss:  1.1004 (0.9351)  Acc@1: 65.6250 (70.6993)  Acc@5: 100.0000 (97.9889)\n",
            "Test: [ 150/312]  Time: 0.102 (0.100)  Loss:  1.4237 (1.0287)  Acc@1: 40.6250 (66.6391)  Acc@5: 96.8750 (97.7856)\n",
            "Test: [ 200/312]  Time: 0.095 (0.098)  Loss:  0.8109 (1.0171)  Acc@1: 78.1250 (67.2419)  Acc@5: 100.0000 (97.7767)\n",
            "Test: [ 250/312]  Time: 0.091 (0.097)  Loss:  0.4206 (0.9627)  Acc@1: 96.8750 (69.9701)  Acc@5: 96.8750 (97.7341)\n",
            "Test: [ 300/312]  Time: 0.086 (0.096)  Loss:  0.3278 (0.8929)  Acc@1: 93.7500 (72.8717)  Acc@5: 100.0000 (97.8094)\n",
            "Test: [ 312/312]  Time: 0.136 (0.096)  Loss:  0.4197 (0.8775)  Acc@1: 93.7500 (73.5300)  Acc@5: 100.0000 (97.8700)\n",
            "Test (EMA): [   0/312]  Time: 0.956 (0.956)  Loss:  1.2212 (1.2212)  Acc@1: 68.7500 (68.7500)  Acc@5: 96.8750 (96.8750)\n",
            "Test (EMA): [  50/312]  Time: 0.089 (0.114)  Loss:  0.7869 (0.8837)  Acc@1: 75.0000 (74.7549)  Acc@5: 100.0000 (97.7941)\n",
            "Test (EMA): [ 100/312]  Time: 0.093 (0.104)  Loss:  1.3329 (1.1068)  Acc@1: 62.5000 (64.5111)  Acc@5: 96.8750 (97.0606)\n",
            "Test (EMA): [ 150/312]  Time: 0.098 (0.100)  Loss:  1.6142 (1.1908)  Acc@1: 31.2500 (61.7136)  Acc@5: 100.0000 (97.0613)\n",
            "Test (EMA): [ 200/312]  Time: 0.093 (0.098)  Loss:  0.7824 (1.2103)  Acc@1: 84.3750 (60.0746)  Acc@5: 100.0000 (97.0149)\n",
            "Test (EMA): [ 250/312]  Time: 0.093 (0.097)  Loss:  0.7983 (1.1400)  Acc@1: 87.5000 (63.5832)  Acc@5: 100.0000 (97.0991)\n",
            "Test (EMA): [ 300/312]  Time: 0.086 (0.097)  Loss:  0.5073 (1.0889)  Acc@1: 93.7500 (66.0091)  Acc@5: 100.0000 (97.1657)\n",
            "Test (EMA): [ 312/312]  Time: 0.132 (0.096)  Loss:  0.8037 (1.0759)  Acc@1: 81.2500 (66.6800)  Acc@5: 100.0000 (97.2200)\n",
            "Current checkpoints:\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-34.pth.tar', 66.68)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-33.pth.tar', 66.06)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-32.pth.tar', 65.3)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-31.pth.tar', 64.72)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-30.pth.tar', 63.99)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-29.pth.tar', 62.86)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-28.pth.tar', 61.96)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-27.pth.tar', 61.04)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-26.pth.tar', 60.02)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-25.pth.tar', 58.95)\n",
            "\n",
            "Train: 35 [   0/1562 (  0%)]  Loss:  1.463660 (1.4637)  Time: 1.659s,   19.29/s  (1.659s,   19.29/s)  LR: 1.343e-05  Data: 1.203 (1.203)\n",
            "Train: 35 [  50/1562 (  3%)]  Loss:  1.575015 (1.8613)  Time: 0.286s,  111.96/s  (0.319s,  100.43/s)  LR: 1.343e-05  Data: 0.004 (0.028)\n",
            "Train: 35 [ 100/1562 (  6%)]  Loss:  1.420503 (1.8048)  Time: 0.294s,  108.84/s  (0.303s,  105.56/s)  LR: 1.343e-05  Data: 0.004 (0.016)\n",
            "Train: 35 [ 150/1562 ( 10%)]  Loss:  2.000856 (1.8221)  Time: 0.286s,  111.92/s  (0.298s,  107.44/s)  LR: 1.343e-05  Data: 0.004 (0.012)\n",
            "Train: 35 [ 200/1562 ( 13%)]  Loss:  1.983798 (1.8019)  Time: 0.327s,   97.95/s  (0.296s,  108.22/s)  LR: 1.343e-05  Data: 0.008 (0.010)\n",
            "Train: 35 [ 250/1562 ( 16%)]  Loss:  1.775999 (1.8059)  Time: 0.291s,  110.03/s  (0.294s,  108.77/s)  LR: 1.343e-05  Data: 0.005 (0.009)\n",
            "Train: 35 [ 300/1562 ( 19%)]  Loss:  2.150690 (1.8101)  Time: 0.288s,  111.29/s  (0.293s,  109.11/s)  LR: 1.343e-05  Data: 0.004 (0.008)\n",
            "Train: 35 [ 350/1562 ( 22%)]  Loss:  1.757295 (1.7926)  Time: 0.287s,  111.62/s  (0.292s,  109.42/s)  LR: 1.343e-05  Data: 0.004 (0.007)\n",
            "Train: 35 [ 400/1562 ( 26%)]  Loss:  2.125386 (1.7745)  Time: 0.286s,  111.72/s  (0.292s,  109.63/s)  LR: 1.343e-05  Data: 0.004 (0.007)\n",
            "Train: 35 [ 450/1562 ( 29%)]  Loss:  2.121897 (1.7734)  Time: 0.287s,  111.57/s  (0.291s,  109.78/s)  LR: 1.343e-05  Data: 0.004 (0.007)\n",
            "Train: 35 [ 500/1562 ( 32%)]  Loss:  1.760614 (1.7759)  Time: 0.293s,  109.32/s  (0.291s,  109.90/s)  LR: 1.343e-05  Data: 0.004 (0.006)\n",
            "Train: 35 [ 550/1562 ( 35%)]  Loss:  1.618997 (1.7704)  Time: 0.287s,  111.59/s  (0.291s,  110.02/s)  LR: 1.343e-05  Data: 0.004 (0.006)\n",
            "Train: 35 [ 600/1562 ( 38%)]  Loss:  1.755915 (1.7664)  Time: 0.287s,  111.61/s  (0.291s,  110.11/s)  LR: 1.343e-05  Data: 0.004 (0.006)\n",
            "Train: 35 [ 650/1562 ( 42%)]  Loss:  1.401091 (1.7688)  Time: 0.286s,  111.83/s  (0.290s,  110.20/s)  LR: 1.343e-05  Data: 0.004 (0.006)\n",
            "Train: 35 [ 700/1562 ( 45%)]  Loss:  1.425521 (1.7731)  Time: 0.287s,  111.56/s  (0.290s,  110.26/s)  LR: 1.343e-05  Data: 0.004 (0.006)\n",
            "Train: 35 [ 750/1562 ( 48%)]  Loss:  1.522162 (1.7777)  Time: 0.290s,  110.32/s  (0.290s,  110.32/s)  LR: 1.343e-05  Data: 0.004 (0.006)\n",
            "Train: 35 [ 800/1562 ( 51%)]  Loss:  1.631268 (1.7791)  Time: 0.287s,  111.43/s  (0.290s,  110.39/s)  LR: 1.343e-05  Data: 0.004 (0.005)\n",
            "Train: 35 [ 850/1562 ( 54%)]  Loss:  2.158137 (1.7868)  Time: 0.292s,  109.74/s  (0.290s,  110.43/s)  LR: 1.343e-05  Data: 0.009 (0.005)\n",
            "Train: 35 [ 900/1562 ( 58%)]  Loss:  1.822842 (1.7911)  Time: 0.286s,  111.89/s  (0.290s,  110.48/s)  LR: 1.343e-05  Data: 0.004 (0.005)\n",
            "Train: 35 [ 950/1562 ( 61%)]  Loss:  1.569510 (1.7891)  Time: 0.287s,  111.65/s  (0.290s,  110.52/s)  LR: 1.343e-05  Data: 0.004 (0.005)\n",
            "Train: 35 [1000/1562 ( 64%)]  Loss:  1.826593 (1.7927)  Time: 0.287s,  111.62/s  (0.289s,  110.54/s)  LR: 1.343e-05  Data: 0.004 (0.005)\n",
            "Train: 35 [1050/1562 ( 67%)]  Loss:  1.390578 (1.7993)  Time: 0.286s,  111.90/s  (0.289s,  110.58/s)  LR: 1.343e-05  Data: 0.004 (0.005)\n",
            "Train: 35 [1100/1562 ( 70%)]  Loss:  1.911088 (1.8015)  Time: 0.292s,  109.68/s  (0.289s,  110.60/s)  LR: 1.343e-05  Data: 0.004 (0.005)\n",
            "Train: 35 [1150/1562 ( 74%)]  Loss:  2.126122 (1.8124)  Time: 0.295s,  108.30/s  (0.289s,  110.61/s)  LR: 1.343e-05  Data: 0.004 (0.005)\n",
            "Train: 35 [1200/1562 ( 77%)]  Loss:  1.569185 (1.8205)  Time: 0.287s,  111.57/s  (0.289s,  110.63/s)  LR: 1.343e-05  Data: 0.004 (0.005)\n",
            "Train: 35 [1250/1562 ( 80%)]  Loss:  2.140896 (1.8197)  Time: 0.286s,  111.74/s  (0.289s,  110.65/s)  LR: 1.343e-05  Data: 0.004 (0.005)\n",
            "Train: 35 [1300/1562 ( 83%)]  Loss:  1.685232 (1.8236)  Time: 0.287s,  111.55/s  (0.289s,  110.67/s)  LR: 1.343e-05  Data: 0.004 (0.005)\n",
            "Train: 35 [1350/1562 ( 86%)]  Loss:  1.921910 (1.8252)  Time: 0.287s,  111.37/s  (0.289s,  110.69/s)  LR: 1.343e-05  Data: 0.004 (0.005)\n",
            "Train: 35 [1400/1562 ( 90%)]  Loss:  2.114278 (1.8197)  Time: 0.288s,  111.01/s  (0.289s,  110.70/s)  LR: 1.343e-05  Data: 0.004 (0.005)\n",
            "Train: 35 [1450/1562 ( 93%)]  Loss:  1.918819 (1.8220)  Time: 0.287s,  111.66/s  (0.289s,  110.71/s)  LR: 1.343e-05  Data: 0.004 (0.005)\n",
            "Train: 35 [1500/1562 ( 96%)]  Loss:  1.900640 (1.8233)  Time: 0.286s,  111.90/s  (0.289s,  110.73/s)  LR: 1.343e-05  Data: 0.004 (0.005)\n",
            "Train: 35 [1550/1562 ( 99%)]  Loss:  1.635334 (1.8214)  Time: 0.284s,  112.78/s  (0.289s,  110.74/s)  LR: 1.343e-05  Data: 0.003 (0.005)\n",
            "Train: 35 [1561/1562 (100%)]  Loss:  1.722271 (1.8199)  Time: 0.371s,   86.31/s  (0.289s,  110.74/s)  LR: 1.343e-05  Data: 0.090 (0.005)\n",
            "Test: [   0/312]  Time: 0.908 (0.908)  Loss:  0.9499 (0.9499)  Acc@1: 71.8750 (71.8750)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [  50/312]  Time: 0.105 (0.112)  Loss:  0.5087 (0.6288)  Acc@1: 87.5000 (83.1495)  Acc@5: 100.0000 (99.2647)\n",
            "Test: [ 100/312]  Time: 0.098 (0.103)  Loss:  1.2149 (0.8439)  Acc@1: 59.3750 (74.1027)  Acc@5: 100.0000 (98.2673)\n",
            "Test: [ 150/312]  Time: 0.096 (0.100)  Loss:  1.3766 (0.9647)  Acc@1: 43.7500 (69.2053)  Acc@5: 96.8750 (97.8270)\n",
            "Test: [ 200/312]  Time: 0.098 (0.098)  Loss:  0.7626 (0.9774)  Acc@1: 84.3750 (68.6878)  Acc@5: 100.0000 (97.6368)\n",
            "Test: [ 250/312]  Time: 0.096 (0.097)  Loss:  0.4302 (0.9323)  Acc@1: 96.8750 (70.9910)  Acc@5: 96.8750 (97.6345)\n",
            "Test: [ 300/312]  Time: 0.086 (0.096)  Loss:  0.3335 (0.8788)  Acc@1: 96.8750 (73.0378)  Acc@5: 100.0000 (97.7263)\n",
            "Test: [ 312/312]  Time: 0.131 (0.096)  Loss:  0.4539 (0.8668)  Acc@1: 87.5000 (73.5100)  Acc@5: 100.0000 (97.7900)\n",
            "Test (EMA): [   0/312]  Time: 0.927 (0.927)  Loss:  1.1992 (1.1992)  Acc@1: 68.7500 (68.7500)  Acc@5: 96.8750 (96.8750)\n",
            "Test (EMA): [  50/312]  Time: 0.094 (0.113)  Loss:  0.7583 (0.8607)  Acc@1: 75.0000 (75.6127)  Acc@5: 100.0000 (97.8554)\n",
            "Test (EMA): [ 100/312]  Time: 0.094 (0.103)  Loss:  1.3205 (1.0837)  Acc@1: 62.5000 (65.6559)  Acc@5: 96.8750 (97.0916)\n",
            "Test (EMA): [ 150/312]  Time: 0.103 (0.100)  Loss:  1.6007 (1.1719)  Acc@1: 34.3750 (62.6242)  Acc@5: 100.0000 (97.0613)\n",
            "Test (EMA): [ 200/312]  Time: 0.097 (0.098)  Loss:  0.7793 (1.1915)  Acc@1: 84.3750 (61.0697)  Acc@5: 100.0000 (97.0149)\n",
            "Test (EMA): [ 250/312]  Time: 0.091 (0.097)  Loss:  0.7688 (1.1213)  Acc@1: 87.5000 (64.5543)  Acc@5: 100.0000 (97.1116)\n",
            "Test (EMA): [ 300/312]  Time: 0.087 (0.096)  Loss:  0.4872 (1.0697)  Acc@1: 93.7500 (66.9124)  Acc@5: 100.0000 (97.1761)\n",
            "Test (EMA): [ 312/312]  Time: 0.130 (0.096)  Loss:  0.7754 (1.0566)  Acc@1: 87.5000 (67.5200)  Acc@5: 100.0000 (97.2500)\n",
            "Current checkpoints:\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-35.pth.tar', 67.52)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-34.pth.tar', 66.68)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-33.pth.tar', 66.06)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-32.pth.tar', 65.3)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-31.pth.tar', 64.72)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-30.pth.tar', 63.99)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-29.pth.tar', 62.86)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-28.pth.tar', 61.96)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-27.pth.tar', 61.04)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-26.pth.tar', 60.02)\n",
            "\n",
            "Train: 36 [   0/1562 (  0%)]  Loss:  1.403167 (1.4032)  Time: 1.644s,   19.47/s  (1.644s,   19.47/s)  LR: 1.220e-05  Data: 1.180 (1.180)\n",
            "Train: 36 [  50/1562 (  3%)]  Loss:  1.432638 (1.8486)  Time: 0.287s,  111.64/s  (0.319s,  100.26/s)  LR: 1.220e-05  Data: 0.004 (0.028)\n",
            "Train: 36 [ 100/1562 (  6%)]  Loss:  1.529507 (1.8088)  Time: 0.286s,  111.88/s  (0.303s,  105.47/s)  LR: 1.220e-05  Data: 0.004 (0.016)\n",
            "Train: 36 [ 150/1562 ( 10%)]  Loss:  2.032353 (1.8246)  Time: 0.286s,  111.88/s  (0.298s,  107.34/s)  LR: 1.220e-05  Data: 0.004 (0.012)\n",
            "Train: 36 [ 200/1562 ( 13%)]  Loss:  1.864930 (1.8131)  Time: 0.290s,  110.47/s  (0.295s,  108.30/s)  LR: 1.220e-05  Data: 0.004 (0.010)\n",
            "Train: 36 [ 250/1562 ( 16%)]  Loss:  1.596869 (1.8092)  Time: 0.286s,  111.77/s  (0.294s,  108.89/s)  LR: 1.220e-05  Data: 0.004 (0.009)\n",
            "Train: 36 [ 300/1562 ( 19%)]  Loss:  1.833125 (1.8128)  Time: 0.286s,  111.83/s  (0.293s,  109.30/s)  LR: 1.220e-05  Data: 0.004 (0.008)\n",
            "Train: 36 [ 350/1562 ( 22%)]  Loss:  1.721132 (1.7886)  Time: 0.286s,  111.99/s  (0.292s,  109.58/s)  LR: 1.220e-05  Data: 0.004 (0.007)\n",
            "Train: 36 [ 400/1562 ( 26%)]  Loss:  2.075067 (1.7715)  Time: 0.286s,  111.96/s  (0.292s,  109.78/s)  LR: 1.220e-05  Data: 0.004 (0.007)\n",
            "Train: 36 [ 450/1562 ( 29%)]  Loss:  1.987589 (1.7718)  Time: 0.286s,  111.84/s  (0.291s,  109.97/s)  LR: 1.220e-05  Data: 0.004 (0.006)\n",
            "Train: 36 [ 500/1562 ( 32%)]  Loss:  1.593783 (1.7732)  Time: 0.286s,  111.73/s  (0.291s,  110.09/s)  LR: 1.220e-05  Data: 0.004 (0.006)\n",
            "Train: 36 [ 550/1562 ( 35%)]  Loss:  1.605236 (1.7677)  Time: 0.286s,  111.75/s  (0.290s,  110.22/s)  LR: 1.220e-05  Data: 0.004 (0.006)\n",
            "Train: 36 [ 600/1562 ( 38%)]  Loss:  2.087245 (1.7624)  Time: 0.286s,  111.97/s  (0.290s,  110.31/s)  LR: 1.220e-05  Data: 0.004 (0.006)\n",
            "Train: 36 [ 650/1562 ( 42%)]  Loss:  1.798847 (1.7651)  Time: 0.286s,  111.73/s  (0.290s,  110.40/s)  LR: 1.220e-05  Data: 0.004 (0.006)\n",
            "Train: 36 [ 700/1562 ( 45%)]  Loss:  1.676227 (1.7668)  Time: 0.286s,  112.07/s  (0.290s,  110.47/s)  LR: 1.220e-05  Data: 0.004 (0.006)\n",
            "Train: 36 [ 750/1562 ( 48%)]  Loss:  1.481819 (1.7745)  Time: 0.290s,  110.43/s  (0.290s,  110.52/s)  LR: 1.220e-05  Data: 0.004 (0.005)\n",
            "Train: 36 [ 800/1562 ( 51%)]  Loss:  1.562203 (1.7774)  Time: 0.286s,  111.83/s  (0.289s,  110.56/s)  LR: 1.220e-05  Data: 0.004 (0.005)\n",
            "Train: 36 [ 850/1562 ( 54%)]  Loss:  2.097065 (1.7886)  Time: 0.286s,  111.89/s  (0.289s,  110.60/s)  LR: 1.220e-05  Data: 0.004 (0.005)\n",
            "Train: 36 [ 900/1562 ( 58%)]  Loss:  1.830948 (1.7936)  Time: 0.290s,  110.42/s  (0.289s,  110.63/s)  LR: 1.220e-05  Data: 0.004 (0.005)\n",
            "Train: 36 [ 950/1562 ( 61%)]  Loss:  1.515296 (1.7902)  Time: 0.286s,  111.96/s  (0.289s,  110.66/s)  LR: 1.220e-05  Data: 0.004 (0.005)\n",
            "Train: 36 [1000/1562 ( 64%)]  Loss:  1.786976 (1.7914)  Time: 0.290s,  110.26/s  (0.289s,  110.70/s)  LR: 1.220e-05  Data: 0.004 (0.005)\n",
            "Train: 36 [1050/1562 ( 67%)]  Loss:  1.435288 (1.7982)  Time: 0.286s,  111.87/s  (0.289s,  110.74/s)  LR: 1.220e-05  Data: 0.004 (0.005)\n",
            "Train: 36 [1100/1562 ( 70%)]  Loss:  2.086457 (1.8010)  Time: 0.286s,  111.83/s  (0.289s,  110.75/s)  LR: 1.220e-05  Data: 0.004 (0.005)\n",
            "Train: 36 [1150/1562 ( 74%)]  Loss:  2.245197 (1.8107)  Time: 0.286s,  111.80/s  (0.289s,  110.77/s)  LR: 1.220e-05  Data: 0.004 (0.005)\n",
            "Train: 36 [1200/1562 ( 77%)]  Loss:  1.684794 (1.8184)  Time: 0.287s,  111.33/s  (0.289s,  110.80/s)  LR: 1.220e-05  Data: 0.004 (0.005)\n",
            "Train: 36 [1250/1562 ( 80%)]  Loss:  2.074736 (1.8180)  Time: 0.288s,  111.01/s  (0.289s,  110.82/s)  LR: 1.220e-05  Data: 0.004 (0.005)\n",
            "Train: 36 [1300/1562 ( 83%)]  Loss:  1.647408 (1.8222)  Time: 0.287s,  111.49/s  (0.289s,  110.84/s)  LR: 1.220e-05  Data: 0.004 (0.005)\n",
            "Train: 36 [1350/1562 ( 86%)]  Loss:  1.842036 (1.8241)  Time: 0.287s,  111.36/s  (0.289s,  110.86/s)  LR: 1.220e-05  Data: 0.004 (0.005)\n",
            "Train: 36 [1400/1562 ( 90%)]  Loss:  1.926425 (1.8192)  Time: 0.287s,  111.63/s  (0.289s,  110.87/s)  LR: 1.220e-05  Data: 0.004 (0.005)\n",
            "Train: 36 [1450/1562 ( 93%)]  Loss:  2.058981 (1.8210)  Time: 0.287s,  111.44/s  (0.289s,  110.89/s)  LR: 1.220e-05  Data: 0.004 (0.005)\n",
            "Train: 36 [1500/1562 ( 96%)]  Loss:  2.314169 (1.8226)  Time: 0.287s,  111.51/s  (0.289s,  110.91/s)  LR: 1.220e-05  Data: 0.004 (0.005)\n",
            "Train: 36 [1550/1562 ( 99%)]  Loss:  1.463502 (1.8200)  Time: 0.284s,  112.80/s  (0.288s,  110.93/s)  LR: 1.220e-05  Data: 0.003 (0.005)\n",
            "Train: 36 [1561/1562 (100%)]  Loss:  1.697708 (1.8182)  Time: 0.368s,   87.01/s  (0.289s,  110.92/s)  LR: 1.220e-05  Data: 0.088 (0.005)\n",
            "Test: [   0/312]  Time: 0.873 (0.873)  Loss:  0.9313 (0.9313)  Acc@1: 75.0000 (75.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [  50/312]  Time: 0.085 (0.113)  Loss:  0.5429 (0.6209)  Acc@1: 87.5000 (83.5172)  Acc@5: 100.0000 (98.8971)\n",
            "Test: [ 100/312]  Time: 0.094 (0.103)  Loss:  1.1678 (0.8697)  Acc@1: 65.6250 (73.2054)  Acc@5: 100.0000 (97.7723)\n",
            "Test: [ 150/312]  Time: 0.096 (0.099)  Loss:  1.3566 (0.9870)  Acc@1: 43.7500 (67.9843)  Acc@5: 100.0000 (97.6407)\n",
            "Test: [ 200/312]  Time: 0.112 (0.098)  Loss:  0.6987 (0.9870)  Acc@1: 84.3750 (68.2680)  Acc@5: 100.0000 (97.5124)\n",
            "Test: [ 250/312]  Time: 0.095 (0.097)  Loss:  0.4569 (0.9250)  Acc@1: 93.7500 (71.1280)  Acc@5: 96.8750 (97.5971)\n",
            "Test: [ 300/312]  Time: 0.085 (0.096)  Loss:  0.3286 (0.8715)  Acc@1: 96.8750 (73.1208)  Acc@5: 100.0000 (97.6952)\n",
            "Test: [ 312/312]  Time: 0.130 (0.096)  Loss:  0.4296 (0.8583)  Acc@1: 87.5000 (73.6500)  Acc@5: 100.0000 (97.7600)\n",
            "Test (EMA): [   0/312]  Time: 0.978 (0.978)  Loss:  1.1767 (1.1767)  Acc@1: 71.8750 (71.8750)  Acc@5: 96.8750 (96.8750)\n",
            "Test (EMA): [  50/312]  Time: 0.093 (0.113)  Loss:  0.7335 (0.8387)  Acc@1: 78.1250 (76.3480)  Acc@5: 96.8750 (97.9779)\n",
            "Test (EMA): [ 100/312]  Time: 0.098 (0.103)  Loss:  1.3096 (1.0622)  Acc@1: 62.5000 (66.5532)  Acc@5: 96.8750 (97.2463)\n",
            "Test (EMA): [ 150/312]  Time: 0.097 (0.100)  Loss:  1.5859 (1.1542)  Acc@1: 34.3750 (63.2657)  Acc@5: 100.0000 (97.1854)\n",
            "Test (EMA): [ 200/312]  Time: 0.090 (0.098)  Loss:  0.7753 (1.1739)  Acc@1: 84.3750 (61.8004)  Acc@5: 100.0000 (97.0927)\n",
            "Test (EMA): [ 250/312]  Time: 0.087 (0.097)  Loss:  0.7411 (1.1038)  Acc@1: 87.5000 (65.1892)  Acc@5: 100.0000 (97.1863)\n",
            "Test (EMA): [ 300/312]  Time: 0.087 (0.096)  Loss:  0.4688 (1.0519)  Acc@1: 93.7500 (67.5664)  Acc@5: 100.0000 (97.2384)\n",
            "Test (EMA): [ 312/312]  Time: 0.129 (0.096)  Loss:  0.7489 (1.0388)  Acc@1: 87.5000 (68.1600)  Acc@5: 100.0000 (97.3100)\n",
            "Current checkpoints:\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-36.pth.tar', 68.16)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-35.pth.tar', 67.52)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-34.pth.tar', 66.68)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-33.pth.tar', 66.06)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-32.pth.tar', 65.3)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-31.pth.tar', 64.72)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-30.pth.tar', 63.99)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-29.pth.tar', 62.86)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-28.pth.tar', 61.96)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-27.pth.tar', 61.04)\n",
            "\n",
            "Train: 37 [   0/1562 (  0%)]  Loss:  1.479934 (1.4799)  Time: 1.855s,   17.25/s  (1.855s,   17.25/s)  LR: 1.124e-05  Data: 1.317 (1.317)\n",
            "Train: 37 [  50/1562 (  3%)]  Loss:  1.565922 (1.8773)  Time: 0.287s,  111.68/s  (0.321s,   99.83/s)  LR: 1.124e-05  Data: 0.004 (0.030)\n",
            "Train: 37 [ 100/1562 (  6%)]  Loss:  1.398078 (1.8144)  Time: 0.288s,  111.26/s  (0.304s,  105.25/s)  LR: 1.124e-05  Data: 0.004 (0.017)\n",
            "Train: 37 [ 150/1562 ( 10%)]  Loss:  1.849794 (1.8266)  Time: 0.286s,  111.93/s  (0.299s,  107.18/s)  LR: 1.124e-05  Data: 0.004 (0.013)\n",
            "Train: 37 [ 200/1562 ( 13%)]  Loss:  2.021783 (1.8168)  Time: 0.288s,  111.21/s  (0.296s,  108.08/s)  LR: 1.124e-05  Data: 0.004 (0.010)\n",
            "Train: 37 [ 250/1562 ( 16%)]  Loss:  1.737037 (1.8078)  Time: 0.287s,  111.63/s  (0.294s,  108.67/s)  LR: 1.124e-05  Data: 0.004 (0.009)\n",
            "Train: 37 [ 300/1562 ( 19%)]  Loss:  2.125555 (1.8106)  Time: 0.287s,  111.69/s  (0.293s,  109.08/s)  LR: 1.124e-05  Data: 0.004 (0.008)\n",
            "Train: 37 [ 350/1562 ( 22%)]  Loss:  1.737405 (1.7943)  Time: 0.288s,  111.07/s  (0.293s,  109.35/s)  LR: 1.124e-05  Data: 0.004 (0.008)\n",
            "Train: 37 [ 400/1562 ( 26%)]  Loss:  1.950835 (1.7775)  Time: 0.287s,  111.47/s  (0.292s,  109.56/s)  LR: 1.124e-05  Data: 0.004 (0.007)\n",
            "Train: 37 [ 450/1562 ( 29%)]  Loss:  1.993922 (1.7736)  Time: 0.286s,  111.82/s  (0.292s,  109.74/s)  LR: 1.124e-05  Data: 0.004 (0.007)\n",
            "Train: 37 [ 500/1562 ( 32%)]  Loss:  1.523858 (1.7735)  Time: 0.287s,  111.34/s  (0.291s,  109.88/s)  LR: 1.124e-05  Data: 0.004 (0.007)\n",
            "Train: 37 [ 550/1562 ( 35%)]  Loss:  1.725552 (1.7672)  Time: 0.286s,  111.71/s  (0.291s,  110.02/s)  LR: 1.124e-05  Data: 0.004 (0.006)\n",
            "Train: 37 [ 600/1562 ( 38%)]  Loss:  1.880755 (1.7605)  Time: 0.286s,  111.80/s  (0.291s,  110.13/s)  LR: 1.124e-05  Data: 0.004 (0.006)\n",
            "Train: 37 [ 650/1562 ( 42%)]  Loss:  1.388195 (1.7635)  Time: 0.286s,  111.85/s  (0.290s,  110.23/s)  LR: 1.124e-05  Data: 0.004 (0.006)\n",
            "Train: 37 [ 700/1562 ( 45%)]  Loss:  1.653624 (1.7661)  Time: 0.286s,  111.85/s  (0.290s,  110.30/s)  LR: 1.124e-05  Data: 0.004 (0.006)\n",
            "Train: 37 [ 750/1562 ( 48%)]  Loss:  1.586454 (1.7730)  Time: 0.290s,  110.42/s  (0.290s,  110.37/s)  LR: 1.124e-05  Data: 0.004 (0.006)\n",
            "Train: 37 [ 800/1562 ( 51%)]  Loss:  1.708192 (1.7771)  Time: 0.287s,  111.58/s  (0.290s,  110.40/s)  LR: 1.124e-05  Data: 0.004 (0.006)\n",
            "Train: 37 [ 850/1562 ( 54%)]  Loss:  2.007629 (1.7854)  Time: 0.294s,  108.81/s  (0.290s,  110.44/s)  LR: 1.124e-05  Data: 0.004 (0.005)\n",
            "Train: 37 [ 900/1562 ( 58%)]  Loss:  1.682619 (1.7891)  Time: 0.290s,  110.28/s  (0.290s,  110.47/s)  LR: 1.124e-05  Data: 0.004 (0.005)\n",
            "Train: 37 [ 950/1562 ( 61%)]  Loss:  1.613645 (1.7886)  Time: 0.287s,  111.55/s  (0.290s,  110.51/s)  LR: 1.124e-05  Data: 0.005 (0.005)\n",
            "Train: 37 [1000/1562 ( 64%)]  Loss:  2.114026 (1.7913)  Time: 0.286s,  111.83/s  (0.289s,  110.55/s)  LR: 1.124e-05  Data: 0.004 (0.005)\n",
            "Train: 37 [1050/1562 ( 67%)]  Loss:  1.656915 (1.7967)  Time: 0.286s,  111.87/s  (0.289s,  110.59/s)  LR: 1.124e-05  Data: 0.004 (0.005)\n",
            "Train: 37 [1100/1562 ( 70%)]  Loss:  1.956430 (1.7990)  Time: 0.286s,  112.01/s  (0.289s,  110.63/s)  LR: 1.124e-05  Data: 0.004 (0.005)\n",
            "Train: 37 [1150/1562 ( 74%)]  Loss:  2.097549 (1.8088)  Time: 0.287s,  111.69/s  (0.289s,  110.65/s)  LR: 1.124e-05  Data: 0.004 (0.005)\n",
            "Train: 37 [1200/1562 ( 77%)]  Loss:  1.680398 (1.8165)  Time: 0.286s,  111.79/s  (0.289s,  110.69/s)  LR: 1.124e-05  Data: 0.004 (0.005)\n",
            "Train: 37 [1250/1562 ( 80%)]  Loss:  1.933361 (1.8158)  Time: 0.286s,  112.07/s  (0.289s,  110.72/s)  LR: 1.124e-05  Data: 0.004 (0.005)\n",
            "Train: 37 [1300/1562 ( 83%)]  Loss:  1.704321 (1.8183)  Time: 0.289s,  110.90/s  (0.289s,  110.74/s)  LR: 1.124e-05  Data: 0.004 (0.005)\n",
            "Train: 37 [1350/1562 ( 86%)]  Loss:  1.861712 (1.8194)  Time: 0.287s,  111.66/s  (0.289s,  110.76/s)  LR: 1.124e-05  Data: 0.004 (0.005)\n",
            "Train: 37 [1400/1562 ( 90%)]  Loss:  1.953637 (1.8141)  Time: 0.287s,  111.51/s  (0.289s,  110.78/s)  LR: 1.124e-05  Data: 0.004 (0.005)\n",
            "Train: 37 [1450/1562 ( 93%)]  Loss:  2.046374 (1.8156)  Time: 0.286s,  111.72/s  (0.289s,  110.81/s)  LR: 1.124e-05  Data: 0.004 (0.005)\n",
            "Train: 37 [1500/1562 ( 96%)]  Loss:  2.073054 (1.8174)  Time: 0.286s,  111.78/s  (0.289s,  110.83/s)  LR: 1.124e-05  Data: 0.004 (0.005)\n",
            "Train: 37 [1550/1562 ( 99%)]  Loss:  1.683442 (1.8152)  Time: 0.283s,  112.95/s  (0.289s,  110.85/s)  LR: 1.124e-05  Data: 0.003 (0.005)\n",
            "Train: 37 [1561/1562 (100%)]  Loss:  1.888240 (1.8134)  Time: 0.370s,   86.51/s  (0.289s,  110.84/s)  LR: 1.124e-05  Data: 0.090 (0.005)\n",
            "Test: [   0/312]  Time: 0.896 (0.896)  Loss:  0.9662 (0.9662)  Acc@1: 68.7500 (68.7500)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [  50/312]  Time: 0.088 (0.113)  Loss:  0.5546 (0.6623)  Acc@1: 81.2500 (81.9240)  Acc@5: 100.0000 (98.6520)\n",
            "Test: [ 100/312]  Time: 0.087 (0.103)  Loss:  1.2641 (0.8875)  Acc@1: 59.3750 (72.6485)  Acc@5: 100.0000 (97.4938)\n",
            "Test: [ 150/312]  Time: 0.087 (0.100)  Loss:  1.3991 (1.0272)  Acc@1: 43.7500 (66.3907)  Acc@5: 96.8750 (97.1026)\n",
            "Test: [ 200/312]  Time: 0.101 (0.098)  Loss:  0.7844 (1.0104)  Acc@1: 81.2500 (67.1486)  Acc@5: 100.0000 (97.1549)\n",
            "Test: [ 250/312]  Time: 0.087 (0.097)  Loss:  0.4899 (0.9399)  Acc@1: 90.6250 (70.3934)  Acc@5: 96.8750 (97.2983)\n",
            "Test: [ 300/312]  Time: 0.086 (0.096)  Loss:  0.2933 (0.8821)  Acc@1: 96.8750 (72.6744)  Acc@5: 100.0000 (97.5083)\n",
            "Test: [ 312/312]  Time: 0.132 (0.096)  Loss:  0.3816 (0.8665)  Acc@1: 93.7500 (73.3500)  Acc@5: 100.0000 (97.5800)\n",
            "Test (EMA): [   0/312]  Time: 0.783 (0.783)  Loss:  1.1563 (1.1563)  Acc@1: 71.8750 (71.8750)  Acc@5: 96.8750 (96.8750)\n",
            "Test (EMA): [  50/312]  Time: 0.087 (0.112)  Loss:  0.7118 (0.8188)  Acc@1: 78.1250 (76.9608)  Acc@5: 100.0000 (98.1618)\n",
            "Test (EMA): [ 100/312]  Time: 0.087 (0.102)  Loss:  1.2999 (1.0424)  Acc@1: 62.5000 (67.1411)  Acc@5: 96.8750 (97.4319)\n",
            "Test (EMA): [ 150/312]  Time: 0.094 (0.099)  Loss:  1.5709 (1.1379)  Acc@1: 34.3750 (63.7417)  Acc@5: 100.0000 (97.3303)\n",
            "Test (EMA): [ 200/312]  Time: 0.093 (0.097)  Loss:  0.7718 (1.1573)  Acc@1: 84.3750 (62.2979)  Acc@5: 100.0000 (97.2481)\n",
            "Test (EMA): [ 250/312]  Time: 0.086 (0.096)  Loss:  0.7146 (1.0875)  Acc@1: 87.5000 (65.6873)  Acc@5: 100.0000 (97.3606)\n",
            "Test (EMA): [ 300/312]  Time: 0.086 (0.096)  Loss:  0.4525 (1.0352)  Acc@1: 93.7500 (68.0129)  Acc@5: 100.0000 (97.3837)\n",
            "Test (EMA): [ 312/312]  Time: 0.137 (0.095)  Loss:  0.7240 (1.0221)  Acc@1: 87.5000 (68.6000)  Acc@5: 100.0000 (97.4400)\n",
            "Current checkpoints:\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-37.pth.tar', 68.6)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-36.pth.tar', 68.16)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-35.pth.tar', 67.52)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-34.pth.tar', 66.68)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-33.pth.tar', 66.06)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-32.pth.tar', 65.3)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-31.pth.tar', 64.72)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-30.pth.tar', 63.99)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-29.pth.tar', 62.86)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-28.pth.tar', 61.96)\n",
            "\n",
            "Train: 38 [   0/1562 (  0%)]  Loss:  1.646480 (1.6465)  Time: 1.685s,   18.99/s  (1.685s,   18.99/s)  LR: 1.055e-05  Data: 1.186 (1.186)\n",
            "Train: 38 [  50/1562 (  3%)]  Loss:  1.608930 (1.8532)  Time: 0.287s,  111.63/s  (0.318s,  100.51/s)  LR: 1.055e-05  Data: 0.004 (0.027)\n",
            "Train: 38 [ 100/1562 (  6%)]  Loss:  1.533581 (1.8037)  Time: 0.286s,  111.75/s  (0.303s,  105.53/s)  LR: 1.055e-05  Data: 0.004 (0.016)\n",
            "Train: 38 [ 150/1562 ( 10%)]  Loss:  2.069493 (1.8169)  Time: 0.286s,  111.90/s  (0.298s,  107.46/s)  LR: 1.055e-05  Data: 0.004 (0.012)\n",
            "Train: 38 [ 200/1562 ( 13%)]  Loss:  1.993615 (1.8017)  Time: 0.286s,  111.92/s  (0.295s,  108.37/s)  LR: 1.055e-05  Data: 0.004 (0.010)\n",
            "Train: 38 [ 250/1562 ( 16%)]  Loss:  1.623797 (1.7994)  Time: 0.287s,  111.65/s  (0.294s,  108.98/s)  LR: 1.055e-05  Data: 0.004 (0.009)\n",
            "Train: 38 [ 300/1562 ( 19%)]  Loss:  2.009627 (1.8017)  Time: 0.286s,  112.04/s  (0.293s,  109.38/s)  LR: 1.055e-05  Data: 0.004 (0.008)\n",
            "Train: 38 [ 350/1562 ( 22%)]  Loss:  1.762747 (1.7843)  Time: 0.286s,  111.98/s  (0.292s,  109.66/s)  LR: 1.055e-05  Data: 0.004 (0.007)\n",
            "Train: 38 [ 400/1562 ( 26%)]  Loss:  1.888972 (1.7728)  Time: 0.296s,  108.03/s  (0.291s,  109.86/s)  LR: 1.055e-05  Data: 0.004 (0.007)\n",
            "Train: 38 [ 450/1562 ( 29%)]  Loss:  2.101004 (1.7698)  Time: 0.286s,  112.00/s  (0.291s,  110.02/s)  LR: 1.055e-05  Data: 0.004 (0.007)\n",
            "Train: 38 [ 500/1562 ( 32%)]  Loss:  1.297249 (1.7715)  Time: 0.287s,  111.39/s  (0.290s,  110.16/s)  LR: 1.055e-05  Data: 0.004 (0.006)\n",
            "Train: 38 [ 550/1562 ( 35%)]  Loss:  1.487453 (1.7653)  Time: 0.295s,  108.37/s  (0.290s,  110.28/s)  LR: 1.055e-05  Data: 0.004 (0.006)\n",
            "Train: 38 [ 600/1562 ( 38%)]  Loss:  2.270087 (1.7605)  Time: 0.286s,  111.76/s  (0.290s,  110.35/s)  LR: 1.055e-05  Data: 0.004 (0.006)\n",
            "Train: 38 [ 650/1562 ( 42%)]  Loss:  1.448193 (1.7610)  Time: 0.287s,  111.33/s  (0.290s,  110.40/s)  LR: 1.055e-05  Data: 0.004 (0.006)\n",
            "Train: 38 [ 700/1562 ( 45%)]  Loss:  1.405180 (1.7628)  Time: 0.297s,  107.88/s  (0.290s,  110.47/s)  LR: 1.055e-05  Data: 0.004 (0.006)\n",
            "Train: 38 [ 750/1562 ( 48%)]  Loss:  1.488723 (1.7665)  Time: 0.287s,  111.47/s  (0.289s,  110.54/s)  LR: 1.055e-05  Data: 0.004 (0.005)\n",
            "Train: 38 [ 800/1562 ( 51%)]  Loss:  1.468535 (1.7690)  Time: 0.286s,  111.84/s  (0.289s,  110.58/s)  LR: 1.055e-05  Data: 0.004 (0.005)\n",
            "Train: 38 [ 850/1562 ( 54%)]  Loss:  2.101448 (1.7781)  Time: 0.287s,  111.54/s  (0.289s,  110.63/s)  LR: 1.055e-05  Data: 0.004 (0.005)\n",
            "Train: 38 [ 900/1562 ( 58%)]  Loss:  1.724777 (1.7816)  Time: 0.286s,  111.74/s  (0.289s,  110.66/s)  LR: 1.055e-05  Data: 0.004 (0.005)\n",
            "Train: 38 [ 950/1562 ( 61%)]  Loss:  1.521966 (1.7799)  Time: 0.289s,  110.64/s  (0.289s,  110.70/s)  LR: 1.055e-05  Data: 0.004 (0.005)\n",
            "Train: 38 [1000/1562 ( 64%)]  Loss:  2.223490 (1.7825)  Time: 0.287s,  111.36/s  (0.289s,  110.70/s)  LR: 1.055e-05  Data: 0.004 (0.005)\n",
            "Train: 38 [1050/1562 ( 67%)]  Loss:  1.364836 (1.7885)  Time: 0.288s,  111.15/s  (0.289s,  110.71/s)  LR: 1.055e-05  Data: 0.004 (0.005)\n",
            "Train: 38 [1100/1562 ( 70%)]  Loss:  2.056685 (1.7908)  Time: 0.287s,  111.31/s  (0.289s,  110.72/s)  LR: 1.055e-05  Data: 0.004 (0.005)\n",
            "Train: 38 [1150/1562 ( 74%)]  Loss:  2.165472 (1.8023)  Time: 0.288s,  110.98/s  (0.289s,  110.72/s)  LR: 1.055e-05  Data: 0.005 (0.005)\n",
            "Train: 38 [1200/1562 ( 77%)]  Loss:  1.571772 (1.8109)  Time: 0.288s,  111.26/s  (0.289s,  110.72/s)  LR: 1.055e-05  Data: 0.004 (0.005)\n",
            "Train: 38 [1250/1562 ( 80%)]  Loss:  1.904768 (1.8103)  Time: 0.288s,  111.04/s  (0.289s,  110.73/s)  LR: 1.055e-05  Data: 0.004 (0.005)\n",
            "Train: 38 [1300/1562 ( 83%)]  Loss:  1.595742 (1.8140)  Time: 0.288s,  111.15/s  (0.289s,  110.73/s)  LR: 1.055e-05  Data: 0.004 (0.005)\n",
            "Train: 38 [1350/1562 ( 86%)]  Loss:  2.135634 (1.8167)  Time: 0.287s,  111.31/s  (0.289s,  110.72/s)  LR: 1.055e-05  Data: 0.004 (0.005)\n",
            "Train: 38 [1400/1562 ( 90%)]  Loss:  1.986481 (1.8119)  Time: 0.292s,  109.48/s  (0.289s,  110.73/s)  LR: 1.055e-05  Data: 0.004 (0.005)\n",
            "Train: 38 [1450/1562 ( 93%)]  Loss:  1.778516 (1.8132)  Time: 0.287s,  111.39/s  (0.289s,  110.74/s)  LR: 1.055e-05  Data: 0.004 (0.005)\n",
            "Train: 38 [1500/1562 ( 96%)]  Loss:  2.054513 (1.8150)  Time: 0.289s,  110.91/s  (0.289s,  110.75/s)  LR: 1.055e-05  Data: 0.004 (0.005)\n",
            "Train: 38 [1550/1562 ( 99%)]  Loss:  1.518079 (1.8133)  Time: 0.286s,  112.04/s  (0.289s,  110.75/s)  LR: 1.055e-05  Data: 0.004 (0.005)\n",
            "Train: 38 [1561/1562 (100%)]  Loss:  1.804749 (1.8115)  Time: 0.376s,   85.11/s  (0.289s,  110.74/s)  LR: 1.055e-05  Data: 0.092 (0.005)\n",
            "Test: [   0/312]  Time: 0.887 (0.887)  Loss:  1.0074 (1.0074)  Acc@1: 62.5000 (62.5000)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [  50/312]  Time: 0.090 (0.116)  Loss:  0.5216 (0.6666)  Acc@1: 84.3750 (81.3113)  Acc@5: 100.0000 (98.7745)\n",
            "Test: [ 100/312]  Time: 0.095 (0.105)  Loss:  1.2616 (0.8258)  Acc@1: 59.3750 (74.3812)  Acc@5: 96.8750 (98.3911)\n",
            "Test: [ 150/312]  Time: 0.098 (0.102)  Loss:  1.3927 (0.9688)  Acc@1: 40.6250 (68.2947)  Acc@5: 96.8750 (97.7856)\n",
            "Test: [ 200/312]  Time: 0.096 (0.100)  Loss:  0.7657 (0.9843)  Acc@1: 81.2500 (67.8483)  Acc@5: 100.0000 (97.7456)\n",
            "Test: [ 250/312]  Time: 0.087 (0.099)  Loss:  0.4481 (0.9271)  Acc@1: 96.8750 (70.6051)  Acc@5: 100.0000 (97.7590)\n",
            "Test: [ 300/312]  Time: 0.087 (0.098)  Loss:  0.3068 (0.8683)  Acc@1: 96.8750 (73.1105)  Acc@5: 100.0000 (97.8924)\n",
            "Test: [ 312/312]  Time: 0.137 (0.098)  Loss:  0.4518 (0.8540)  Acc@1: 87.5000 (73.7300)  Acc@5: 100.0000 (97.9500)\n",
            "Test (EMA): [   0/312]  Time: 0.904 (0.904)  Loss:  1.1376 (1.1376)  Acc@1: 71.8750 (71.8750)  Acc@5: 96.8750 (96.8750)\n",
            "Test (EMA): [  50/312]  Time: 0.110 (0.118)  Loss:  0.6920 (0.8007)  Acc@1: 78.1250 (77.5735)  Acc@5: 100.0000 (98.2230)\n",
            "Test (EMA): [ 100/312]  Time: 0.087 (0.106)  Loss:  1.2894 (1.0242)  Acc@1: 62.5000 (67.7908)  Acc@5: 96.8750 (97.5248)\n",
            "Test (EMA): [ 150/312]  Time: 0.088 (0.102)  Loss:  1.5563 (1.1227)  Acc@1: 34.3750 (64.2384)  Acc@5: 100.0000 (97.4338)\n",
            "Test (EMA): [ 200/312]  Time: 0.087 (0.100)  Loss:  0.7682 (1.1417)  Acc@1: 84.3750 (62.8731)  Acc@5: 100.0000 (97.3414)\n",
            "Test (EMA): [ 250/312]  Time: 0.094 (0.099)  Loss:  0.6910 (1.0722)  Acc@1: 87.5000 (66.2226)  Acc@5: 100.0000 (97.4104)\n",
            "Test (EMA): [ 300/312]  Time: 0.087 (0.098)  Loss:  0.4374 (1.0197)  Acc@1: 96.8750 (68.5735)  Acc@5: 100.0000 (97.4460)\n",
            "Test (EMA): [ 312/312]  Time: 0.141 (0.097)  Loss:  0.7002 (1.0066)  Acc@1: 87.5000 (69.1400)  Acc@5: 100.0000 (97.5100)\n",
            "Current checkpoints:\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-38.pth.tar', 69.14)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-37.pth.tar', 68.6)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-36.pth.tar', 68.16)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-35.pth.tar', 67.52)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-34.pth.tar', 66.68)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-33.pth.tar', 66.06)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-32.pth.tar', 65.3)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-31.pth.tar', 64.72)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-30.pth.tar', 63.99)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-29.pth.tar', 62.86)\n",
            "\n",
            "Train: 39 [   0/1562 (  0%)]  Loss:  1.446853 (1.4469)  Time: 1.742s,   18.37/s  (1.742s,   18.37/s)  LR: 1.014e-05  Data: 1.246 (1.246)\n",
            "Train: 39 [  50/1562 (  3%)]  Loss:  1.543843 (1.8502)  Time: 0.291s,  109.97/s  (0.322s,   99.51/s)  LR: 1.014e-05  Data: 0.004 (0.029)\n",
            "Train: 39 [ 100/1562 (  6%)]  Loss:  1.352914 (1.7981)  Time: 0.287s,  111.31/s  (0.306s,  104.67/s)  LR: 1.014e-05  Data: 0.004 (0.017)\n",
            "Train: 39 [ 150/1562 ( 10%)]  Loss:  2.004610 (1.8145)  Time: 0.288s,  111.26/s  (0.300s,  106.63/s)  LR: 1.014e-05  Data: 0.004 (0.013)\n",
            "Train: 39 [ 200/1562 ( 13%)]  Loss:  1.885102 (1.8004)  Time: 0.288s,  111.30/s  (0.297s,  107.65/s)  LR: 1.014e-05  Data: 0.004 (0.010)\n",
            "Train: 39 [ 250/1562 ( 16%)]  Loss:  1.437684 (1.7931)  Time: 0.290s,  110.42/s  (0.295s,  108.31/s)  LR: 1.014e-05  Data: 0.004 (0.009)\n",
            "Train: 39 [ 300/1562 ( 19%)]  Loss:  2.065131 (1.7963)  Time: 0.286s,  111.77/s  (0.294s,  108.77/s)  LR: 1.014e-05  Data: 0.004 (0.008)\n",
            "Train: 39 [ 350/1562 ( 22%)]  Loss:  1.834514 (1.7838)  Time: 0.292s,  109.77/s  (0.293s,  109.12/s)  LR: 1.014e-05  Data: 0.006 (0.008)\n",
            "Train: 39 [ 400/1562 ( 26%)]  Loss:  1.946258 (1.7687)  Time: 0.293s,  109.24/s  (0.293s,  109.36/s)  LR: 1.014e-05  Data: 0.004 (0.007)\n",
            "Train: 39 [ 450/1562 ( 29%)]  Loss:  1.911374 (1.7648)  Time: 0.286s,  112.04/s  (0.292s,  109.57/s)  LR: 1.014e-05  Data: 0.004 (0.007)\n",
            "Train: 39 [ 500/1562 ( 32%)]  Loss:  1.513108 (1.7667)  Time: 0.286s,  111.93/s  (0.292s,  109.75/s)  LR: 1.014e-05  Data: 0.004 (0.007)\n",
            "Train: 39 [ 550/1562 ( 35%)]  Loss:  1.632420 (1.7629)  Time: 0.286s,  111.84/s  (0.291s,  109.90/s)  LR: 1.014e-05  Data: 0.004 (0.006)\n",
            "Train: 39 [ 600/1562 ( 38%)]  Loss:  2.011476 (1.7564)  Time: 0.285s,  112.10/s  (0.291s,  110.03/s)  LR: 1.014e-05  Data: 0.004 (0.006)\n",
            "Train: 39 [ 650/1562 ( 42%)]  Loss:  1.745262 (1.7592)  Time: 0.290s,  110.45/s  (0.291s,  110.14/s)  LR: 1.014e-05  Data: 0.004 (0.006)\n",
            "Train: 39 [ 700/1562 ( 45%)]  Loss:  1.544647 (1.7627)  Time: 0.286s,  111.80/s  (0.290s,  110.24/s)  LR: 1.014e-05  Data: 0.004 (0.006)\n",
            "Train: 39 [ 750/1562 ( 48%)]  Loss:  1.703984 (1.7695)  Time: 0.286s,  111.87/s  (0.290s,  110.31/s)  LR: 1.014e-05  Data: 0.004 (0.006)\n",
            "Train: 39 [ 800/1562 ( 51%)]  Loss:  1.550577 (1.7712)  Time: 0.294s,  108.89/s  (0.290s,  110.38/s)  LR: 1.014e-05  Data: 0.004 (0.006)\n",
            "Train: 39 [ 850/1562 ( 54%)]  Loss:  2.142433 (1.7810)  Time: 0.289s,  110.62/s  (0.290s,  110.45/s)  LR: 1.014e-05  Data: 0.004 (0.005)\n",
            "Train: 39 [ 900/1562 ( 58%)]  Loss:  1.668304 (1.7859)  Time: 0.286s,  111.89/s  (0.290s,  110.48/s)  LR: 1.014e-05  Data: 0.004 (0.005)\n",
            "Train: 39 [ 950/1562 ( 61%)]  Loss:  1.576422 (1.7850)  Time: 0.293s,  109.24/s  (0.290s,  110.52/s)  LR: 1.014e-05  Data: 0.004 (0.005)\n",
            "Train: 39 [1000/1562 ( 64%)]  Loss:  1.917081 (1.7861)  Time: 0.288s,  111.30/s  (0.289s,  110.56/s)  LR: 1.014e-05  Data: 0.004 (0.005)\n",
            "Train: 39 [1050/1562 ( 67%)]  Loss:  1.448008 (1.7917)  Time: 0.286s,  111.78/s  (0.289s,  110.58/s)  LR: 1.014e-05  Data: 0.004 (0.005)\n",
            "Train: 39 [1100/1562 ( 70%)]  Loss:  1.983770 (1.7946)  Time: 0.291s,  109.94/s  (0.289s,  110.62/s)  LR: 1.014e-05  Data: 0.004 (0.005)\n",
            "Train: 39 [1150/1562 ( 74%)]  Loss:  1.733948 (1.8055)  Time: 0.286s,  111.82/s  (0.289s,  110.65/s)  LR: 1.014e-05  Data: 0.004 (0.005)\n",
            "Train: 39 [1200/1562 ( 77%)]  Loss:  1.833763 (1.8126)  Time: 0.293s,  109.14/s  (0.289s,  110.68/s)  LR: 1.014e-05  Data: 0.004 (0.005)\n",
            "Train: 39 [1250/1562 ( 80%)]  Loss:  1.918073 (1.8126)  Time: 0.286s,  112.08/s  (0.289s,  110.71/s)  LR: 1.014e-05  Data: 0.004 (0.005)\n",
            "Train: 39 [1300/1562 ( 83%)]  Loss:  1.580529 (1.8161)  Time: 0.287s,  111.65/s  (0.289s,  110.74/s)  LR: 1.014e-05  Data: 0.004 (0.005)\n",
            "Train: 39 [1350/1562 ( 86%)]  Loss:  2.027116 (1.8176)  Time: 0.289s,  110.58/s  (0.289s,  110.76/s)  LR: 1.014e-05  Data: 0.004 (0.005)\n",
            "Train: 39 [1400/1562 ( 90%)]  Loss:  2.032463 (1.8127)  Time: 0.286s,  111.86/s  (0.289s,  110.78/s)  LR: 1.014e-05  Data: 0.004 (0.005)\n",
            "Train: 39 [1450/1562 ( 93%)]  Loss:  2.037581 (1.8154)  Time: 0.291s,  110.08/s  (0.289s,  110.80/s)  LR: 1.014e-05  Data: 0.004 (0.005)\n",
            "Train: 39 [1500/1562 ( 96%)]  Loss:  1.802922 (1.8167)  Time: 0.286s,  111.70/s  (0.289s,  110.82/s)  LR: 1.014e-05  Data: 0.004 (0.005)\n",
            "Train: 39 [1550/1562 ( 99%)]  Loss:  1.545224 (1.8149)  Time: 0.285s,  112.23/s  (0.289s,  110.85/s)  LR: 1.014e-05  Data: 0.003 (0.005)\n",
            "Train: 39 [1561/1562 (100%)]  Loss:  1.835802 (1.8132)  Time: 0.379s,   84.45/s  (0.289s,  110.84/s)  LR: 1.014e-05  Data: 0.098 (0.005)\n",
            "Test: [   0/312]  Time: 0.938 (0.938)  Loss:  1.0073 (1.0073)  Acc@1: 65.6250 (65.6250)  Acc@5: 96.8750 (96.8750)\n",
            "Test: [  50/312]  Time: 0.093 (0.114)  Loss:  0.5959 (0.6976)  Acc@1: 78.1250 (80.6373)  Acc@5: 100.0000 (98.4681)\n",
            "Test: [ 100/312]  Time: 0.093 (0.103)  Loss:  1.0909 (0.8758)  Acc@1: 62.5000 (72.8342)  Acc@5: 100.0000 (98.0817)\n",
            "Test: [ 150/312]  Time: 0.098 (0.100)  Loss:  1.3426 (0.9786)  Acc@1: 37.5000 (68.0257)  Acc@5: 100.0000 (97.9305)\n",
            "Test: [ 200/312]  Time: 0.087 (0.098)  Loss:  0.7206 (0.9687)  Acc@1: 87.5000 (68.2836)  Acc@5: 100.0000 (98.0100)\n",
            "Test: [ 250/312]  Time: 0.087 (0.097)  Loss:  0.4437 (0.9096)  Acc@1: 96.8750 (71.2400)  Acc@5: 96.8750 (98.0204)\n",
            "Test: [ 300/312]  Time: 0.086 (0.097)  Loss:  0.3222 (0.8580)  Acc@1: 96.8750 (73.3908)  Acc@5: 100.0000 (98.0170)\n",
            "Test: [ 312/312]  Time: 0.130 (0.096)  Loss:  0.4523 (0.8460)  Acc@1: 87.5000 (73.9600)  Acc@5: 100.0000 (98.0700)\n",
            "Test (EMA): [   0/312]  Time: 0.895 (0.895)  Loss:  1.1181 (1.1181)  Acc@1: 71.8750 (71.8750)  Acc@5: 96.8750 (96.8750)\n",
            "Test (EMA): [  50/312]  Time: 0.096 (0.113)  Loss:  0.6725 (0.7827)  Acc@1: 78.1250 (78.3088)  Acc@5: 100.0000 (98.2230)\n",
            "Test (EMA): [ 100/312]  Time: 0.092 (0.103)  Loss:  1.2804 (1.0062)  Acc@1: 62.5000 (68.5953)  Acc@5: 96.8750 (97.6485)\n",
            "Test (EMA): [ 150/312]  Time: 0.100 (0.099)  Loss:  1.5430 (1.1080)  Acc@1: 37.5000 (64.8386)  Acc@5: 100.0000 (97.4959)\n",
            "Test (EMA): [ 200/312]  Time: 0.096 (0.098)  Loss:  0.7669 (1.1268)  Acc@1: 87.5000 (63.4950)  Acc@5: 100.0000 (97.4502)\n",
            "Test (EMA): [ 250/312]  Time: 0.096 (0.097)  Loss:  0.6683 (1.0578)  Acc@1: 87.5000 (66.7455)  Acc@5: 100.0000 (97.5224)\n",
            "Test (EMA): [ 300/312]  Time: 0.086 (0.096)  Loss:  0.4243 (1.0052)  Acc@1: 96.8750 (69.0822)  Acc@5: 100.0000 (97.5498)\n",
            "Test (EMA): [ 312/312]  Time: 0.133 (0.096)  Loss:  0.6787 (0.9920)  Acc@1: 87.5000 (69.6300)  Acc@5: 100.0000 (97.6200)\n",
            "Current checkpoints:\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-39.pth.tar', 69.63)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-38.pth.tar', 69.14)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-37.pth.tar', 68.6)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-36.pth.tar', 68.16)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-35.pth.tar', 67.52)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-34.pth.tar', 66.68)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-33.pth.tar', 66.06)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-32.pth.tar', 65.3)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-31.pth.tar', 64.72)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-30.pth.tar', 63.99)\n",
            "\n",
            "Train: 40 [   0/1562 (  0%)]  Loss:  1.702349 (1.7023)  Time: 1.618s,   19.77/s  (1.618s,   19.77/s)  LR: 1.000e-05  Data: 1.096 (1.096)\n",
            "Train: 40 [  50/1562 (  3%)]  Loss:  1.492898 (1.8762)  Time: 0.287s,  111.66/s  (0.317s,  100.82/s)  LR: 1.000e-05  Data: 0.004 (0.026)\n",
            "Train: 40 [ 100/1562 (  6%)]  Loss:  1.369179 (1.8122)  Time: 0.287s,  111.43/s  (0.302s,  105.86/s)  LR: 1.000e-05  Data: 0.004 (0.015)\n",
            "Train: 40 [ 150/1562 ( 10%)]  Loss:  1.929943 (1.8188)  Time: 0.286s,  111.89/s  (0.297s,  107.57/s)  LR: 1.000e-05  Data: 0.004 (0.011)\n",
            "Train: 40 [ 200/1562 ( 13%)]  Loss:  2.002926 (1.8024)  Time: 0.286s,  111.75/s  (0.295s,  108.47/s)  LR: 1.000e-05  Data: 0.004 (0.009)\n",
            "Train: 40 [ 250/1562 ( 16%)]  Loss:  1.463006 (1.7968)  Time: 0.286s,  111.80/s  (0.293s,  109.07/s)  LR: 1.000e-05  Data: 0.004 (0.008)\n",
            "Train: 40 [ 300/1562 ( 19%)]  Loss:  2.089532 (1.7968)  Time: 0.286s,  112.05/s  (0.292s,  109.45/s)  LR: 1.000e-05  Data: 0.004 (0.008)\n",
            "Train: 40 [ 350/1562 ( 22%)]  Loss:  1.930819 (1.7805)  Time: 0.299s,  107.20/s  (0.292s,  109.72/s)  LR: 1.000e-05  Data: 0.004 (0.007)\n",
            "Train: 40 [ 400/1562 ( 26%)]  Loss:  1.972414 (1.7656)  Time: 0.286s,  111.91/s  (0.291s,  109.94/s)  LR: 1.000e-05  Data: 0.004 (0.007)\n",
            "Train: 40 [ 450/1562 ( 29%)]  Loss:  1.975892 (1.7613)  Time: 0.290s,  110.40/s  (0.291s,  110.09/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 40 [ 500/1562 ( 32%)]  Loss:  1.374328 (1.7614)  Time: 0.286s,  111.71/s  (0.290s,  110.22/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 40 [ 550/1562 ( 35%)]  Loss:  1.716891 (1.7554)  Time: 0.287s,  111.69/s  (0.290s,  110.33/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 40 [ 600/1562 ( 38%)]  Loss:  2.069332 (1.7491)  Time: 0.287s,  111.63/s  (0.290s,  110.41/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 40 [ 650/1562 ( 42%)]  Loss:  1.498645 (1.7506)  Time: 0.286s,  111.99/s  (0.290s,  110.51/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 40 [ 700/1562 ( 45%)]  Loss:  1.509548 (1.7528)  Time: 0.287s,  111.51/s  (0.289s,  110.57/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 40 [ 750/1562 ( 48%)]  Loss:  1.545793 (1.7596)  Time: 0.286s,  111.88/s  (0.289s,  110.64/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 40 [ 800/1562 ( 51%)]  Loss:  1.376443 (1.7609)  Time: 0.287s,  111.38/s  (0.289s,  110.67/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 40 [ 850/1562 ( 54%)]  Loss:  1.947181 (1.7700)  Time: 0.286s,  111.96/s  (0.289s,  110.72/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 40 [ 900/1562 ( 58%)]  Loss:  1.682831 (1.7733)  Time: 0.291s,  109.90/s  (0.289s,  110.75/s)  LR: 1.000e-05  Data: 0.006 (0.005)\n",
            "Train: 40 [ 950/1562 ( 61%)]  Loss:  1.482584 (1.7712)  Time: 0.286s,  111.70/s  (0.289s,  110.78/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 40 [1000/1562 ( 64%)]  Loss:  2.136266 (1.7747)  Time: 0.286s,  111.99/s  (0.289s,  110.81/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 40 [1050/1562 ( 67%)]  Loss:  1.466982 (1.7807)  Time: 0.287s,  111.63/s  (0.289s,  110.85/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 40 [1100/1562 ( 70%)]  Loss:  1.947093 (1.7834)  Time: 0.286s,  111.97/s  (0.289s,  110.87/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 40 [1150/1562 ( 74%)]  Loss:  2.155112 (1.7945)  Time: 0.294s,  108.82/s  (0.289s,  110.89/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 40 [1200/1562 ( 77%)]  Loss:  1.572490 (1.8028)  Time: 0.289s,  110.81/s  (0.289s,  110.90/s)  LR: 1.000e-05  Data: 0.006 (0.005)\n",
            "Train: 40 [1250/1562 ( 80%)]  Loss:  2.062483 (1.8034)  Time: 0.287s,  111.50/s  (0.289s,  110.91/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 40 [1300/1562 ( 83%)]  Loss:  1.811737 (1.8073)  Time: 0.286s,  111.83/s  (0.288s,  110.92/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 40 [1350/1562 ( 86%)]  Loss:  1.933235 (1.8089)  Time: 0.287s,  111.62/s  (0.288s,  110.93/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 40 [1400/1562 ( 90%)]  Loss:  1.889966 (1.8033)  Time: 0.288s,  111.12/s  (0.288s,  110.94/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 40 [1450/1562 ( 93%)]  Loss:  2.031834 (1.8054)  Time: 0.291s,  110.12/s  (0.288s,  110.94/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 40 [1500/1562 ( 96%)]  Loss:  2.131224 (1.8075)  Time: 0.286s,  111.69/s  (0.288s,  110.96/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 40 [1550/1562 ( 99%)]  Loss:  1.454576 (1.8050)  Time: 0.283s,  113.05/s  (0.288s,  110.96/s)  LR: 1.000e-05  Data: 0.003 (0.005)\n",
            "Train: 40 [1561/1562 (100%)]  Loss:  1.784312 (1.8030)  Time: 0.369s,   86.69/s  (0.288s,  110.95/s)  LR: 1.000e-05  Data: 0.089 (0.005)\n",
            "Test: [   0/312]  Time: 0.904 (0.904)  Loss:  0.8845 (0.8845)  Acc@1: 75.0000 (75.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [  50/312]  Time: 0.099 (0.113)  Loss:  0.5094 (0.5835)  Acc@1: 87.5000 (85.3554)  Acc@5: 100.0000 (99.0196)\n",
            "Test: [ 100/312]  Time: 0.096 (0.103)  Loss:  1.2451 (0.8415)  Acc@1: 59.3750 (74.1027)  Acc@5: 100.0000 (97.9270)\n",
            "Test: [ 150/312]  Time: 0.096 (0.099)  Loss:  1.4630 (0.9989)  Acc@1: 46.8750 (66.9495)  Acc@5: 96.8750 (97.6407)\n",
            "Test: [ 200/312]  Time: 0.102 (0.098)  Loss:  0.8560 (0.9937)  Acc@1: 71.8750 (67.4907)  Acc@5: 100.0000 (97.6213)\n",
            "Test: [ 250/312]  Time: 0.092 (0.096)  Loss:  0.4428 (0.9229)  Acc@1: 93.7500 (70.7545)  Acc@5: 96.8750 (97.6594)\n",
            "Test: [ 300/312]  Time: 0.086 (0.096)  Loss:  0.3092 (0.8706)  Acc@1: 96.8750 (72.6952)  Acc@5: 100.0000 (97.7679)\n",
            "Test: [ 312/312]  Time: 0.131 (0.096)  Loss:  0.4360 (0.8576)  Acc@1: 87.5000 (73.2500)  Acc@5: 100.0000 (97.8300)\n",
            "Test (EMA): [   0/312]  Time: 0.956 (0.956)  Loss:  1.1013 (1.1013)  Acc@1: 71.8750 (71.8750)  Acc@5: 96.8750 (96.8750)\n",
            "Test (EMA): [  50/312]  Time: 0.092 (0.113)  Loss:  0.6555 (0.7669)  Acc@1: 78.1250 (78.4314)  Acc@5: 100.0000 (98.3456)\n",
            "Test (EMA): [ 100/312]  Time: 0.095 (0.102)  Loss:  1.2721 (0.9900)  Acc@1: 62.5000 (68.9975)  Acc@5: 96.8750 (97.7413)\n",
            "Test (EMA): [ 150/312]  Time: 0.093 (0.099)  Loss:  1.5292 (1.0947)  Acc@1: 40.6250 (65.1904)  Acc@5: 100.0000 (97.5579)\n",
            "Test (EMA): [ 200/312]  Time: 0.095 (0.097)  Loss:  0.7644 (1.1132)  Acc@1: 84.3750 (64.0081)  Acc@5: 100.0000 (97.5124)\n",
            "Test (EMA): [ 250/312]  Time: 0.108 (0.097)  Loss:  0.6459 (1.0445)  Acc@1: 90.6250 (67.2062)  Acc@5: 100.0000 (97.5722)\n",
            "Test (EMA): [ 300/312]  Time: 0.086 (0.096)  Loss:  0.4126 (0.9917)  Acc@1: 96.8750 (69.5287)  Acc@5: 100.0000 (97.6121)\n",
            "Test (EMA): [ 312/312]  Time: 0.135 (0.096)  Loss:  0.6584 (0.9785)  Acc@1: 87.5000 (70.0700)  Acc@5: 100.0000 (97.6700)\n",
            "Current checkpoints:\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-40.pth.tar', 70.07)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-39.pth.tar', 69.63)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-38.pth.tar', 69.14)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-37.pth.tar', 68.6)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-36.pth.tar', 68.16)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-35.pth.tar', 67.52)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-34.pth.tar', 66.68)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-33.pth.tar', 66.06)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-32.pth.tar', 65.3)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-31.pth.tar', 64.72)\n",
            "\n",
            "Train: 41 [   0/1562 (  0%)]  Loss:  1.714438 (1.7144)  Time: 1.695s,   18.87/s  (1.695s,   18.87/s)  LR: 1.000e-05  Data: 1.151 (1.151)\n",
            "Train: 41 [  50/1562 (  3%)]  Loss:  1.731362 (1.8475)  Time: 0.286s,  112.03/s  (0.320s,   99.96/s)  LR: 1.000e-05  Data: 0.004 (0.027)\n",
            "Train: 41 [ 100/1562 (  6%)]  Loss:  1.476088 (1.7939)  Time: 0.286s,  111.86/s  (0.304s,  105.38/s)  LR: 1.000e-05  Data: 0.004 (0.015)\n",
            "Train: 41 [ 150/1562 ( 10%)]  Loss:  2.031343 (1.8119)  Time: 0.287s,  111.59/s  (0.298s,  107.26/s)  LR: 1.000e-05  Data: 0.004 (0.012)\n",
            "Train: 41 [ 200/1562 ( 13%)]  Loss:  1.956465 (1.7973)  Time: 0.286s,  111.92/s  (0.295s,  108.30/s)  LR: 1.000e-05  Data: 0.004 (0.010)\n",
            "Train: 41 [ 250/1562 ( 16%)]  Loss:  1.158036 (1.7934)  Time: 0.286s,  112.05/s  (0.294s,  108.91/s)  LR: 1.000e-05  Data: 0.004 (0.009)\n",
            "Train: 41 [ 300/1562 ( 19%)]  Loss:  1.956613 (1.7961)  Time: 0.287s,  111.36/s  (0.293s,  109.34/s)  LR: 1.000e-05  Data: 0.004 (0.008)\n",
            "Train: 41 [ 350/1562 ( 22%)]  Loss:  1.668818 (1.7779)  Time: 0.289s,  110.76/s  (0.292s,  109.57/s)  LR: 1.000e-05  Data: 0.006 (0.007)\n",
            "Train: 41 [ 400/1562 ( 26%)]  Loss:  1.966965 (1.7629)  Time: 0.288s,  111.19/s  (0.292s,  109.74/s)  LR: 1.000e-05  Data: 0.004 (0.007)\n",
            "Train: 41 [ 450/1562 ( 29%)]  Loss:  1.976590 (1.7584)  Time: 0.289s,  110.60/s  (0.291s,  109.86/s)  LR: 1.000e-05  Data: 0.004 (0.007)\n",
            "Train: 41 [ 500/1562 ( 32%)]  Loss:  1.480868 (1.7597)  Time: 0.287s,  111.31/s  (0.291s,  109.97/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 41 [ 550/1562 ( 35%)]  Loss:  1.801319 (1.7560)  Time: 0.292s,  109.57/s  (0.291s,  110.06/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 41 [ 600/1562 ( 38%)]  Loss:  1.985030 (1.7514)  Time: 0.287s,  111.32/s  (0.291s,  110.11/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 41 [ 650/1562 ( 42%)]  Loss:  1.489751 (1.7540)  Time: 0.292s,  109.49/s  (0.291s,  110.14/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 41 [ 700/1562 ( 45%)]  Loss:  1.517430 (1.7576)  Time: 0.287s,  111.32/s  (0.290s,  110.18/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 41 [ 750/1562 ( 48%)]  Loss:  1.545393 (1.7655)  Time: 0.288s,  111.23/s  (0.290s,  110.23/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 41 [ 800/1562 ( 51%)]  Loss:  1.487169 (1.7673)  Time: 0.288s,  111.30/s  (0.290s,  110.26/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 41 [ 850/1562 ( 54%)]  Loss:  2.157706 (1.7772)  Time: 0.294s,  108.96/s  (0.290s,  110.29/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 41 [ 900/1562 ( 58%)]  Loss:  1.685066 (1.7818)  Time: 0.287s,  111.33/s  (0.290s,  110.33/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 41 [ 950/1562 ( 61%)]  Loss:  1.600527 (1.7818)  Time: 0.287s,  111.41/s  (0.290s,  110.37/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 41 [1000/1562 ( 64%)]  Loss:  2.136466 (1.7845)  Time: 0.288s,  111.28/s  (0.290s,  110.39/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 41 [1050/1562 ( 67%)]  Loss:  1.565318 (1.7899)  Time: 0.288s,  111.21/s  (0.290s,  110.40/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 41 [1100/1562 ( 70%)]  Loss:  1.976441 (1.7926)  Time: 0.292s,  109.66/s  (0.290s,  110.42/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 41 [1150/1562 ( 74%)]  Loss:  2.120859 (1.8034)  Time: 0.288s,  111.25/s  (0.290s,  110.43/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 41 [1200/1562 ( 77%)]  Loss:  1.390066 (1.8114)  Time: 0.289s,  110.77/s  (0.290s,  110.46/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 41 [1250/1562 ( 80%)]  Loss:  2.055987 (1.8112)  Time: 0.287s,  111.31/s  (0.290s,  110.47/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 41 [1300/1562 ( 83%)]  Loss:  1.765668 (1.8140)  Time: 0.294s,  108.86/s  (0.290s,  110.47/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 41 [1350/1562 ( 86%)]  Loss:  2.048648 (1.8159)  Time: 0.288s,  111.09/s  (0.290s,  110.49/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 41 [1400/1562 ( 90%)]  Loss:  2.058446 (1.8106)  Time: 0.288s,  111.12/s  (0.290s,  110.50/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 41 [1450/1562 ( 93%)]  Loss:  2.008416 (1.8123)  Time: 0.288s,  111.30/s  (0.290s,  110.51/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 41 [1500/1562 ( 96%)]  Loss:  2.013082 (1.8128)  Time: 0.286s,  111.89/s  (0.290s,  110.53/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 41 [1550/1562 ( 99%)]  Loss:  1.684544 (1.8107)  Time: 0.283s,  112.98/s  (0.289s,  110.57/s)  LR: 1.000e-05  Data: 0.003 (0.005)\n",
            "Train: 41 [1561/1562 (100%)]  Loss:  2.014624 (1.8091)  Time: 0.370s,   86.51/s  (0.289s,  110.56/s)  LR: 1.000e-05  Data: 0.090 (0.005)\n",
            "Test: [   0/312]  Time: 0.960 (0.960)  Loss:  1.0582 (1.0582)  Acc@1: 62.5000 (62.5000)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [  50/312]  Time: 0.089 (0.113)  Loss:  0.5272 (0.6698)  Acc@1: 84.3750 (81.3725)  Acc@5: 100.0000 (98.7132)\n",
            "Test: [ 100/312]  Time: 0.099 (0.103)  Loss:  1.1657 (0.8553)  Acc@1: 65.6250 (73.6386)  Acc@5: 100.0000 (98.0507)\n",
            "Test: [ 150/312]  Time: 0.093 (0.099)  Loss:  1.3833 (0.9788)  Acc@1: 40.6250 (68.1084)  Acc@5: 100.0000 (97.7856)\n",
            "Test: [ 200/312]  Time: 0.093 (0.098)  Loss:  0.7210 (0.9683)  Acc@1: 84.3750 (68.8122)  Acc@5: 100.0000 (97.7456)\n",
            "Test: [ 250/312]  Time: 0.087 (0.097)  Loss:  0.4240 (0.9066)  Acc@1: 96.8750 (71.7007)  Acc@5: 100.0000 (97.7714)\n",
            "Test: [ 300/312]  Time: 0.086 (0.096)  Loss:  0.2925 (0.8517)  Acc@1: 96.8750 (73.7853)  Acc@5: 100.0000 (97.8717)\n",
            "Test: [ 312/312]  Time: 0.134 (0.096)  Loss:  0.4158 (0.8378)  Acc@1: 93.7500 (74.3600)  Acc@5: 100.0000 (97.9300)\n",
            "Test (EMA): [   0/312]  Time: 0.923 (0.923)  Loss:  1.0876 (1.0876)  Acc@1: 75.0000 (75.0000)  Acc@5: 96.8750 (96.8750)\n",
            "Test (EMA): [  50/312]  Time: 0.098 (0.114)  Loss:  0.6405 (0.7529)  Acc@1: 78.1250 (78.8603)  Acc@5: 100.0000 (98.3456)\n",
            "Test (EMA): [ 100/312]  Time: 0.094 (0.103)  Loss:  1.2631 (0.9754)  Acc@1: 62.5000 (69.5854)  Acc@5: 96.8750 (97.7104)\n",
            "Test (EMA): [ 150/312]  Time: 0.093 (0.100)  Loss:  1.5143 (1.0823)  Acc@1: 40.6250 (65.6043)  Acc@5: 100.0000 (97.5786)\n",
            "Test (EMA): [ 200/312]  Time: 0.087 (0.098)  Loss:  0.7632 (1.1006)  Acc@1: 84.3750 (64.4590)  Acc@5: 100.0000 (97.5435)\n",
            "Test (EMA): [ 250/312]  Time: 0.087 (0.097)  Loss:  0.6262 (1.0322)  Acc@1: 90.6250 (67.6046)  Acc@5: 100.0000 (97.5722)\n",
            "Test (EMA): [ 300/312]  Time: 0.086 (0.096)  Loss:  0.4011 (0.9792)  Acc@1: 96.8750 (69.8920)  Acc@5: 100.0000 (97.6017)\n",
            "Test (EMA): [ 312/312]  Time: 0.136 (0.096)  Loss:  0.6387 (0.9661)  Acc@1: 87.5000 (70.4600)  Acc@5: 100.0000 (97.6600)\n",
            "Current checkpoints:\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-41.pth.tar', 70.46)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-40.pth.tar', 70.07)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-39.pth.tar', 69.63)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-38.pth.tar', 69.14)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-37.pth.tar', 68.6)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-36.pth.tar', 68.16)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-35.pth.tar', 67.52)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-34.pth.tar', 66.68)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-33.pth.tar', 66.06)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-32.pth.tar', 65.3)\n",
            "\n",
            "Train: 42 [   0/1562 (  0%)]  Loss:  1.551799 (1.5518)  Time: 1.562s,   20.49/s  (1.562s,   20.49/s)  LR: 1.000e-05  Data: 1.055 (1.055)\n",
            "Train: 42 [  50/1562 (  3%)]  Loss:  1.639419 (1.8597)  Time: 0.287s,  111.33/s  (0.317s,  100.83/s)  LR: 1.000e-05  Data: 0.005 (0.025)\n",
            "Train: 42 [ 100/1562 (  6%)]  Loss:  1.412998 (1.8063)  Time: 0.286s,  111.80/s  (0.303s,  105.76/s)  LR: 1.000e-05  Data: 0.004 (0.015)\n",
            "Train: 42 [ 150/1562 ( 10%)]  Loss:  1.939951 (1.8211)  Time: 0.294s,  108.67/s  (0.298s,  107.56/s)  LR: 1.000e-05  Data: 0.004 (0.011)\n",
            "Train: 42 [ 200/1562 ( 13%)]  Loss:  1.843862 (1.7984)  Time: 0.286s,  111.94/s  (0.295s,  108.52/s)  LR: 1.000e-05  Data: 0.004 (0.009)\n",
            "Train: 42 [ 250/1562 ( 16%)]  Loss:  1.496194 (1.7935)  Time: 0.286s,  111.94/s  (0.293s,  109.12/s)  LR: 1.000e-05  Data: 0.004 (0.008)\n",
            "Train: 42 [ 300/1562 ( 19%)]  Loss:  1.904487 (1.7936)  Time: 0.286s,  112.00/s  (0.292s,  109.51/s)  LR: 1.000e-05  Data: 0.004 (0.007)\n",
            "Train: 42 [ 350/1562 ( 22%)]  Loss:  1.655641 (1.7721)  Time: 0.286s,  111.91/s  (0.291s,  109.79/s)  LR: 1.000e-05  Data: 0.004 (0.007)\n",
            "Train: 42 [ 400/1562 ( 26%)]  Loss:  1.940310 (1.7549)  Time: 0.286s,  111.74/s  (0.291s,  109.99/s)  LR: 1.000e-05  Data: 0.004 (0.007)\n",
            "Train: 42 [ 450/1562 ( 29%)]  Loss:  2.157288 (1.7552)  Time: 0.286s,  111.94/s  (0.291s,  110.15/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 42 [ 500/1562 ( 32%)]  Loss:  1.319825 (1.7573)  Time: 0.286s,  111.82/s  (0.290s,  110.29/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 42 [ 550/1562 ( 35%)]  Loss:  1.584553 (1.7511)  Time: 0.286s,  111.96/s  (0.290s,  110.38/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 42 [ 600/1562 ( 38%)]  Loss:  2.061942 (1.7452)  Time: 0.286s,  111.83/s  (0.290s,  110.45/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 42 [ 650/1562 ( 42%)]  Loss:  1.481088 (1.7471)  Time: 0.286s,  111.95/s  (0.290s,  110.51/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 42 [ 700/1562 ( 45%)]  Loss:  1.493984 (1.7510)  Time: 0.286s,  111.82/s  (0.289s,  110.59/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 42 [ 750/1562 ( 48%)]  Loss:  1.559520 (1.7574)  Time: 0.286s,  111.78/s  (0.289s,  110.66/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 42 [ 800/1562 ( 51%)]  Loss:  1.773244 (1.7609)  Time: 0.286s,  111.99/s  (0.289s,  110.71/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 42 [ 850/1562 ( 54%)]  Loss:  2.080823 (1.7708)  Time: 0.293s,  109.14/s  (0.289s,  110.74/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 42 [ 900/1562 ( 58%)]  Loss:  1.738634 (1.7764)  Time: 0.286s,  112.03/s  (0.289s,  110.78/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 42 [ 950/1562 ( 61%)]  Loss:  1.409814 (1.7750)  Time: 0.286s,  111.97/s  (0.289s,  110.81/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 42 [1000/1562 ( 64%)]  Loss:  2.043872 (1.7793)  Time: 0.286s,  111.97/s  (0.289s,  110.84/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 42 [1050/1562 ( 67%)]  Loss:  1.516855 (1.7847)  Time: 0.285s,  112.10/s  (0.289s,  110.85/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 42 [1100/1562 ( 70%)]  Loss:  1.987251 (1.7868)  Time: 0.290s,  110.42/s  (0.289s,  110.87/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 42 [1150/1562 ( 74%)]  Loss:  2.165699 (1.7983)  Time: 0.287s,  111.54/s  (0.289s,  110.90/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 42 [1200/1562 ( 77%)]  Loss:  1.670453 (1.8056)  Time: 0.290s,  110.19/s  (0.289s,  110.91/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 42 [1250/1562 ( 80%)]  Loss:  1.805998 (1.8048)  Time: 0.286s,  111.86/s  (0.288s,  110.94/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 42 [1300/1562 ( 83%)]  Loss:  1.653393 (1.8076)  Time: 0.287s,  111.65/s  (0.288s,  110.95/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 42 [1350/1562 ( 86%)]  Loss:  1.968607 (1.8090)  Time: 0.286s,  111.75/s  (0.288s,  110.97/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 42 [1400/1562 ( 90%)]  Loss:  1.874091 (1.8048)  Time: 0.286s,  111.75/s  (0.288s,  110.99/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 42 [1450/1562 ( 93%)]  Loss:  2.001678 (1.8062)  Time: 0.286s,  111.85/s  (0.288s,  111.01/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 42 [1500/1562 ( 96%)]  Loss:  1.942908 (1.8080)  Time: 0.286s,  111.75/s  (0.288s,  111.04/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 42 [1550/1562 ( 99%)]  Loss:  1.509520 (1.8062)  Time: 0.284s,  112.69/s  (0.288s,  111.05/s)  LR: 1.000e-05  Data: 0.003 (0.005)\n",
            "Train: 42 [1561/1562 (100%)]  Loss:  2.027358 (1.8043)  Time: 0.371s,   86.28/s  (0.288s,  111.04/s)  LR: 1.000e-05  Data: 0.091 (0.005)\n",
            "Test: [   0/312]  Time: 0.912 (0.912)  Loss:  1.0370 (1.0370)  Acc@1: 62.5000 (62.5000)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [  50/312]  Time: 0.087 (0.114)  Loss:  0.4538 (0.6464)  Acc@1: 87.5000 (82.0466)  Acc@5: 100.0000 (98.4681)\n",
            "Test: [ 100/312]  Time: 0.090 (0.103)  Loss:  1.2253 (0.8118)  Acc@1: 59.3750 (75.4332)  Acc@5: 100.0000 (98.2983)\n",
            "Test: [ 150/312]  Time: 0.094 (0.100)  Loss:  1.4390 (0.9620)  Acc@1: 37.5000 (68.7500)  Acc@5: 100.0000 (97.8684)\n",
            "Test: [ 200/312]  Time: 0.093 (0.098)  Loss:  0.7441 (0.9676)  Acc@1: 84.3750 (68.6567)  Acc@5: 100.0000 (97.8234)\n",
            "Test: [ 250/312]  Time: 0.090 (0.097)  Loss:  0.3695 (0.9053)  Acc@1: 96.8750 (71.6633)  Acc@5: 96.8750 (97.7714)\n",
            "Test: [ 300/312]  Time: 0.086 (0.096)  Loss:  0.3659 (0.8539)  Acc@1: 96.8750 (73.7542)  Acc@5: 100.0000 (97.7990)\n",
            "Test: [ 312/312]  Time: 0.137 (0.096)  Loss:  0.5008 (0.8445)  Acc@1: 87.5000 (74.1400)  Acc@5: 100.0000 (97.8500)\n",
            "Test (EMA): [   0/312]  Time: 0.930 (0.930)  Loss:  1.0763 (1.0763)  Acc@1: 75.0000 (75.0000)  Acc@5: 96.8750 (96.8750)\n",
            "Test (EMA): [  50/312]  Time: 0.093 (0.113)  Loss:  0.6255 (0.7404)  Acc@1: 81.2500 (79.4118)  Acc@5: 100.0000 (98.4069)\n",
            "Test (EMA): [ 100/312]  Time: 0.095 (0.103)  Loss:  1.2555 (0.9621)  Acc@1: 62.5000 (70.2042)  Acc@5: 96.8750 (97.7413)\n",
            "Test (EMA): [ 150/312]  Time: 0.087 (0.100)  Loss:  1.5011 (1.0712)  Acc@1: 40.6250 (66.1424)  Acc@5: 100.0000 (97.6407)\n",
            "Test (EMA): [ 200/312]  Time: 0.088 (0.098)  Loss:  0.7609 (1.0888)  Acc@1: 84.3750 (65.0031)  Acc@5: 100.0000 (97.6057)\n",
            "Test (EMA): [ 250/312]  Time: 0.087 (0.097)  Loss:  0.6056 (1.0207)  Acc@1: 90.6250 (68.1150)  Acc@5: 100.0000 (97.6220)\n",
            "Test (EMA): [ 300/312]  Time: 0.086 (0.096)  Loss:  0.3906 (0.9674)  Acc@1: 96.8750 (70.3904)  Acc@5: 100.0000 (97.6329)\n",
            "Test (EMA): [ 312/312]  Time: 0.131 (0.096)  Loss:  0.6211 (0.9543)  Acc@1: 87.5000 (70.9400)  Acc@5: 100.0000 (97.6900)\n",
            "Current checkpoints:\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-42.pth.tar', 70.94)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-41.pth.tar', 70.46)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-40.pth.tar', 70.07)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-39.pth.tar', 69.63)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-38.pth.tar', 69.14)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-37.pth.tar', 68.6)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-36.pth.tar', 68.16)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-35.pth.tar', 67.52)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-34.pth.tar', 66.68)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-33.pth.tar', 66.06)\n",
            "\n",
            "Train: 43 [   0/1562 (  0%)]  Loss:  1.525422 (1.5254)  Time: 1.598s,   20.03/s  (1.598s,   20.03/s)  LR: 1.000e-05  Data: 1.118 (1.118)\n",
            "Train: 43 [  50/1562 (  3%)]  Loss:  1.435138 (1.8338)  Time: 0.286s,  111.77/s  (0.317s,  100.86/s)  LR: 1.000e-05  Data: 0.004 (0.027)\n",
            "Train: 43 [ 100/1562 (  6%)]  Loss:  1.433444 (1.7978)  Time: 0.286s,  111.80/s  (0.302s,  105.85/s)  LR: 1.000e-05  Data: 0.004 (0.015)\n",
            "Train: 43 [ 150/1562 ( 10%)]  Loss:  1.858086 (1.8220)  Time: 0.286s,  111.71/s  (0.297s,  107.57/s)  LR: 1.000e-05  Data: 0.004 (0.012)\n",
            "Train: 43 [ 200/1562 ( 13%)]  Loss:  1.990389 (1.8068)  Time: 0.286s,  111.72/s  (0.295s,  108.44/s)  LR: 1.000e-05  Data: 0.004 (0.010)\n",
            "Train: 43 [ 250/1562 ( 16%)]  Loss:  1.510915 (1.7989)  Time: 0.286s,  111.74/s  (0.294s,  108.97/s)  LR: 1.000e-05  Data: 0.004 (0.009)\n",
            "Train: 43 [ 300/1562 ( 19%)]  Loss:  1.891870 (1.7997)  Time: 0.286s,  111.70/s  (0.293s,  109.36/s)  LR: 1.000e-05  Data: 0.004 (0.008)\n",
            "Train: 43 [ 350/1562 ( 22%)]  Loss:  1.962646 (1.7854)  Time: 0.286s,  112.00/s  (0.292s,  109.63/s)  LR: 1.000e-05  Data: 0.004 (0.007)\n",
            "Train: 43 [ 400/1562 ( 26%)]  Loss:  2.178012 (1.7679)  Time: 0.291s,  109.82/s  (0.291s,  109.83/s)  LR: 1.000e-05  Data: 0.007 (0.007)\n",
            "Train: 43 [ 450/1562 ( 29%)]  Loss:  1.840022 (1.7583)  Time: 0.289s,  110.79/s  (0.291s,  110.01/s)  LR: 1.000e-05  Data: 0.004 (0.007)\n",
            "Train: 43 [ 500/1562 ( 32%)]  Loss:  1.226806 (1.7592)  Time: 0.286s,  111.73/s  (0.291s,  110.12/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 43 [ 550/1562 ( 35%)]  Loss:  1.439095 (1.7547)  Time: 0.287s,  111.59/s  (0.290s,  110.21/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 43 [ 600/1562 ( 38%)]  Loss:  2.111623 (1.7492)  Time: 0.286s,  111.78/s  (0.290s,  110.29/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 43 [ 650/1562 ( 42%)]  Loss:  1.666864 (1.7520)  Time: 0.290s,  110.37/s  (0.290s,  110.36/s)  LR: 1.000e-05  Data: 0.006 (0.006)\n",
            "Train: 43 [ 700/1562 ( 45%)]  Loss:  1.602320 (1.7550)  Time: 0.286s,  111.99/s  (0.290s,  110.43/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 43 [ 750/1562 ( 48%)]  Loss:  1.557444 (1.7621)  Time: 0.291s,  109.86/s  (0.290s,  110.50/s)  LR: 1.000e-05  Data: 0.005 (0.005)\n",
            "Train: 43 [ 800/1562 ( 51%)]  Loss:  1.494133 (1.7631)  Time: 0.287s,  111.59/s  (0.289s,  110.54/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 43 [ 850/1562 ( 54%)]  Loss:  2.201917 (1.7732)  Time: 0.287s,  111.65/s  (0.289s,  110.57/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 43 [ 900/1562 ( 58%)]  Loss:  1.511288 (1.7781)  Time: 0.294s,  108.86/s  (0.289s,  110.60/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 43 [ 950/1562 ( 61%)]  Loss:  1.686202 (1.7762)  Time: 0.286s,  111.75/s  (0.289s,  110.63/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 43 [1000/1562 ( 64%)]  Loss:  2.113840 (1.7788)  Time: 0.286s,  111.93/s  (0.289s,  110.68/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 43 [1050/1562 ( 67%)]  Loss:  1.612413 (1.7848)  Time: 0.287s,  111.68/s  (0.289s,  110.71/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 43 [1100/1562 ( 70%)]  Loss:  2.099333 (1.7886)  Time: 0.286s,  111.69/s  (0.289s,  110.73/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 43 [1150/1562 ( 74%)]  Loss:  2.170014 (1.7997)  Time: 0.287s,  111.60/s  (0.289s,  110.76/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 43 [1200/1562 ( 77%)]  Loss:  1.562543 (1.8067)  Time: 0.287s,  111.47/s  (0.289s,  110.78/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 43 [1250/1562 ( 80%)]  Loss:  1.894125 (1.8056)  Time: 0.286s,  112.01/s  (0.289s,  110.80/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 43 [1300/1562 ( 83%)]  Loss:  1.707061 (1.8085)  Time: 0.289s,  110.74/s  (0.289s,  110.83/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 43 [1350/1562 ( 86%)]  Loss:  1.783120 (1.8104)  Time: 0.287s,  111.58/s  (0.289s,  110.85/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 43 [1400/1562 ( 90%)]  Loss:  2.087403 (1.8048)  Time: 0.287s,  111.64/s  (0.289s,  110.85/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 43 [1450/1562 ( 93%)]  Loss:  1.918492 (1.8064)  Time: 0.287s,  111.69/s  (0.289s,  110.86/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 43 [1500/1562 ( 96%)]  Loss:  1.974194 (1.8084)  Time: 0.287s,  111.62/s  (0.289s,  110.88/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 43 [1550/1562 ( 99%)]  Loss:  1.466699 (1.8064)  Time: 0.291s,  110.11/s  (0.289s,  110.89/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 43 [1561/1562 (100%)]  Loss:  1.818737 (1.8045)  Time: 0.372s,   85.99/s  (0.289s,  110.88/s)  LR: 1.000e-05  Data: 0.092 (0.005)\n",
            "Test: [   0/312]  Time: 0.986 (0.986)  Loss:  0.8337 (0.8337)  Acc@1: 68.7500 (68.7500)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [  50/312]  Time: 0.098 (0.113)  Loss:  0.5369 (0.5753)  Acc@1: 81.2500 (85.3554)  Acc@5: 100.0000 (99.1422)\n",
            "Test: [ 100/312]  Time: 0.090 (0.103)  Loss:  1.1959 (0.7806)  Acc@1: 62.5000 (76.3614)  Acc@5: 100.0000 (98.4839)\n",
            "Test: [ 150/312]  Time: 0.100 (0.100)  Loss:  1.4515 (0.9386)  Acc@1: 50.0000 (69.3088)  Acc@5: 96.8750 (97.9925)\n",
            "Test: [ 200/312]  Time: 0.097 (0.098)  Loss:  0.8822 (0.9470)  Acc@1: 75.0000 (69.3563)  Acc@5: 100.0000 (97.8234)\n",
            "Test: [ 250/312]  Time: 0.095 (0.097)  Loss:  0.4090 (0.9004)  Acc@1: 96.8750 (71.7131)  Acc@5: 96.8750 (97.7590)\n",
            "Test: [ 300/312]  Time: 0.086 (0.096)  Loss:  0.3257 (0.8496)  Acc@1: 96.8750 (73.6503)  Acc@5: 100.0000 (97.8717)\n",
            "Test: [ 312/312]  Time: 0.132 (0.096)  Loss:  0.4348 (0.8375)  Acc@1: 93.7500 (74.2100)  Acc@5: 100.0000 (97.9300)\n",
            "Test (EMA): [   0/312]  Time: 0.864 (0.864)  Loss:  1.0653 (1.0653)  Acc@1: 75.0000 (75.0000)  Acc@5: 96.8750 (96.8750)\n",
            "Test (EMA): [  50/312]  Time: 0.093 (0.112)  Loss:  0.6130 (0.7286)  Acc@1: 81.2500 (79.4118)  Acc@5: 100.0000 (98.4681)\n",
            "Test (EMA): [ 100/312]  Time: 0.093 (0.102)  Loss:  1.2477 (0.9499)  Acc@1: 62.5000 (70.3899)  Acc@5: 96.8750 (97.8032)\n",
            "Test (EMA): [ 150/312]  Time: 0.086 (0.099)  Loss:  1.4900 (1.0610)  Acc@1: 40.6250 (66.2045)  Acc@5: 100.0000 (97.6821)\n",
            "Test (EMA): [ 200/312]  Time: 0.097 (0.098)  Loss:  0.7581 (1.0780)  Acc@1: 81.2500 (65.1430)  Acc@5: 100.0000 (97.6213)\n",
            "Test (EMA): [ 250/312]  Time: 0.098 (0.097)  Loss:  0.5873 (1.0100)  Acc@1: 90.6250 (68.3142)  Acc@5: 100.0000 (97.6469)\n",
            "Test (EMA): [ 300/312]  Time: 0.086 (0.096)  Loss:  0.3819 (0.9566)  Acc@1: 96.8750 (70.6292)  Acc@5: 100.0000 (97.6640)\n",
            "Test (EMA): [ 312/312]  Time: 0.132 (0.096)  Loss:  0.6057 (0.9435)  Acc@1: 87.5000 (71.1800)  Acc@5: 100.0000 (97.7200)\n",
            "Current checkpoints:\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-43.pth.tar', 71.18)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-42.pth.tar', 70.94)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-41.pth.tar', 70.46)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-40.pth.tar', 70.07)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-39.pth.tar', 69.63)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-38.pth.tar', 69.14)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-37.pth.tar', 68.6)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-36.pth.tar', 68.16)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-35.pth.tar', 67.52)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-34.pth.tar', 66.68)\n",
            "\n",
            "Train: 44 [   0/1562 (  0%)]  Loss:  1.321771 (1.3218)  Time: 1.708s,   18.73/s  (1.708s,   18.73/s)  LR: 1.000e-05  Data: 1.195 (1.195)\n",
            "Train: 44 [  50/1562 (  3%)]  Loss:  1.482947 (1.8379)  Time: 0.286s,  111.76/s  (0.319s,  100.41/s)  LR: 1.000e-05  Data: 0.004 (0.028)\n",
            "Train: 44 [ 100/1562 (  6%)]  Loss:  1.307318 (1.7827)  Time: 0.287s,  111.67/s  (0.303s,  105.55/s)  LR: 1.000e-05  Data: 0.004 (0.016)\n",
            "Train: 44 [ 150/1562 ( 10%)]  Loss:  1.992639 (1.7957)  Time: 0.292s,  109.45/s  (0.298s,  107.41/s)  LR: 1.000e-05  Data: 0.004 (0.012)\n",
            "Train: 44 [ 200/1562 ( 13%)]  Loss:  1.941009 (1.7780)  Time: 0.286s,  111.87/s  (0.295s,  108.43/s)  LR: 1.000e-05  Data: 0.004 (0.010)\n",
            "Train: 44 [ 250/1562 ( 16%)]  Loss:  1.865488 (1.7814)  Time: 0.289s,  110.73/s  (0.294s,  109.01/s)  LR: 1.000e-05  Data: 0.004 (0.009)\n",
            "Train: 44 [ 300/1562 ( 19%)]  Loss:  2.015672 (1.7873)  Time: 0.287s,  111.67/s  (0.293s,  109.37/s)  LR: 1.000e-05  Data: 0.004 (0.008)\n",
            "Train: 44 [ 350/1562 ( 22%)]  Loss:  1.678730 (1.7665)  Time: 0.287s,  111.62/s  (0.292s,  109.66/s)  LR: 1.000e-05  Data: 0.004 (0.007)\n",
            "Train: 44 [ 400/1562 ( 26%)]  Loss:  2.011284 (1.7530)  Time: 0.286s,  111.86/s  (0.291s,  109.85/s)  LR: 1.000e-05  Data: 0.004 (0.007)\n",
            "Train: 44 [ 450/1562 ( 29%)]  Loss:  2.109025 (1.7548)  Time: 0.287s,  111.39/s  (0.291s,  110.02/s)  LR: 1.000e-05  Data: 0.004 (0.007)\n",
            "Train: 44 [ 500/1562 ( 32%)]  Loss:  1.742099 (1.7532)  Time: 0.286s,  111.84/s  (0.291s,  110.14/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 44 [ 550/1562 ( 35%)]  Loss:  1.876492 (1.7527)  Time: 0.287s,  111.42/s  (0.290s,  110.26/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 44 [ 600/1562 ( 38%)]  Loss:  1.921428 (1.7463)  Time: 0.287s,  111.48/s  (0.290s,  110.31/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 44 [ 650/1562 ( 42%)]  Loss:  1.272093 (1.7478)  Time: 0.287s,  111.51/s  (0.290s,  110.39/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 44 [ 700/1562 ( 45%)]  Loss:  1.534961 (1.7508)  Time: 0.289s,  110.78/s  (0.290s,  110.46/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 44 [ 750/1562 ( 48%)]  Loss:  1.579893 (1.7573)  Time: 0.287s,  111.55/s  (0.290s,  110.52/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 44 [ 800/1562 ( 51%)]  Loss:  1.582947 (1.7595)  Time: 0.286s,  111.91/s  (0.289s,  110.59/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 44 [ 850/1562 ( 54%)]  Loss:  2.161885 (1.7682)  Time: 0.294s,  108.81/s  (0.289s,  110.64/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 44 [ 900/1562 ( 58%)]  Loss:  1.553795 (1.7735)  Time: 0.293s,  109.11/s  (0.289s,  110.68/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 44 [ 950/1562 ( 61%)]  Loss:  1.418893 (1.7716)  Time: 0.286s,  111.71/s  (0.289s,  110.71/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 44 [1000/1562 ( 64%)]  Loss:  2.101678 (1.7759)  Time: 0.289s,  110.77/s  (0.289s,  110.75/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 44 [1050/1562 ( 67%)]  Loss:  1.287678 (1.7819)  Time: 0.286s,  112.01/s  (0.289s,  110.79/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 44 [1100/1562 ( 70%)]  Loss:  1.937504 (1.7843)  Time: 0.286s,  111.98/s  (0.289s,  110.81/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 44 [1150/1562 ( 74%)]  Loss:  1.964874 (1.7939)  Time: 0.288s,  111.04/s  (0.289s,  110.84/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 44 [1200/1562 ( 77%)]  Loss:  1.492503 (1.8021)  Time: 0.288s,  111.27/s  (0.289s,  110.87/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 44 [1250/1562 ( 80%)]  Loss:  1.924596 (1.8021)  Time: 0.286s,  111.84/s  (0.289s,  110.89/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 44 [1300/1562 ( 83%)]  Loss:  1.551747 (1.8057)  Time: 0.289s,  110.56/s  (0.289s,  110.91/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 44 [1350/1562 ( 86%)]  Loss:  1.772250 (1.8076)  Time: 0.286s,  111.85/s  (0.288s,  110.93/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 44 [1400/1562 ( 90%)]  Loss:  1.906837 (1.8023)  Time: 0.287s,  111.61/s  (0.288s,  110.95/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 44 [1450/1562 ( 93%)]  Loss:  2.013250 (1.8045)  Time: 0.286s,  111.81/s  (0.288s,  110.96/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 44 [1500/1562 ( 96%)]  Loss:  2.001352 (1.8058)  Time: 0.286s,  111.85/s  (0.288s,  110.97/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 44 [1550/1562 ( 99%)]  Loss:  1.474800 (1.8037)  Time: 0.291s,  110.06/s  (0.288s,  110.99/s)  LR: 1.000e-05  Data: 0.003 (0.005)\n",
            "Train: 44 [1561/1562 (100%)]  Loss:  1.693479 (1.8017)  Time: 0.371s,   86.35/s  (0.288s,  110.98/s)  LR: 1.000e-05  Data: 0.090 (0.005)\n",
            "Test: [   0/312]  Time: 1.021 (1.021)  Loss:  1.0042 (1.0042)  Acc@1: 68.7500 (68.7500)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [  50/312]  Time: 0.093 (0.114)  Loss:  0.5006 (0.6493)  Acc@1: 87.5000 (82.1078)  Acc@5: 100.0000 (98.7132)\n",
            "Test: [ 100/312]  Time: 0.087 (0.104)  Loss:  1.2177 (0.8245)  Acc@1: 65.6250 (74.7834)  Acc@5: 100.0000 (98.2054)\n",
            "Test: [ 150/312]  Time: 0.096 (0.100)  Loss:  1.3615 (0.9594)  Acc@1: 46.8750 (68.4810)  Acc@5: 96.8750 (97.9512)\n",
            "Test: [ 200/312]  Time: 0.093 (0.098)  Loss:  0.7821 (0.9459)  Acc@1: 81.2500 (69.4185)  Acc@5: 100.0000 (97.9789)\n",
            "Test: [ 250/312]  Time: 0.100 (0.097)  Loss:  0.3900 (0.8932)  Acc@1: 96.8750 (72.0369)  Acc@5: 96.8750 (97.9333)\n",
            "Test: [ 300/312]  Time: 0.086 (0.096)  Loss:  0.3033 (0.8405)  Acc@1: 96.8750 (74.2421)  Acc@5: 100.0000 (98.0170)\n",
            "Test: [ 312/312]  Time: 0.135 (0.096)  Loss:  0.4979 (0.8290)  Acc@1: 87.5000 (74.7300)  Acc@5: 100.0000 (98.0700)\n",
            "Test (EMA): [   0/312]  Time: 0.968 (0.968)  Loss:  1.0541 (1.0541)  Acc@1: 75.0000 (75.0000)  Acc@5: 96.8750 (96.8750)\n",
            "Test (EMA): [  50/312]  Time: 0.093 (0.113)  Loss:  0.6013 (0.7175)  Acc@1: 78.1250 (79.5956)  Acc@5: 100.0000 (98.6520)\n",
            "Test (EMA): [ 100/312]  Time: 0.104 (0.103)  Loss:  1.2387 (0.9378)  Acc@1: 62.5000 (70.8849)  Acc@5: 96.8750 (97.9579)\n",
            "Test (EMA): [ 150/312]  Time: 0.099 (0.100)  Loss:  1.4796 (1.0508)  Acc@1: 43.7500 (66.6391)  Acc@5: 100.0000 (97.7856)\n",
            "Test (EMA): [ 200/312]  Time: 0.089 (0.098)  Loss:  0.7544 (1.0670)  Acc@1: 81.2500 (65.6561)  Acc@5: 100.0000 (97.6835)\n",
            "Test (EMA): [ 250/312]  Time: 0.087 (0.097)  Loss:  0.5694 (0.9995)  Acc@1: 90.6250 (68.7375)  Acc@5: 100.0000 (97.7092)\n",
            "Test (EMA): [ 300/312]  Time: 0.086 (0.096)  Loss:  0.3741 (0.9460)  Acc@1: 93.7500 (71.0652)  Acc@5: 100.0000 (97.7159)\n",
            "Test (EMA): [ 312/312]  Time: 0.131 (0.096)  Loss:  0.5924 (0.9329)  Acc@1: 87.5000 (71.6200)  Acc@5: 100.0000 (97.7800)\n",
            "Current checkpoints:\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-44.pth.tar', 71.62)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-43.pth.tar', 71.18)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-42.pth.tar', 70.94)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-41.pth.tar', 70.46)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-40.pth.tar', 70.07)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-39.pth.tar', 69.63)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-38.pth.tar', 69.14)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-37.pth.tar', 68.6)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-36.pth.tar', 68.16)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-35.pth.tar', 67.52)\n",
            "\n",
            "Train: 45 [   0/1562 (  0%)]  Loss:  1.801495 (1.8015)  Time: 1.744s,   18.35/s  (1.744s,   18.35/s)  LR: 1.000e-05  Data: 1.277 (1.277)\n",
            "Train: 45 [  50/1562 (  3%)]  Loss:  1.476211 (1.8495)  Time: 0.286s,  111.86/s  (0.319s,  100.32/s)  LR: 1.000e-05  Data: 0.004 (0.029)\n",
            "Train: 45 [ 100/1562 (  6%)]  Loss:  1.422806 (1.7849)  Time: 0.290s,  110.27/s  (0.303s,  105.66/s)  LR: 1.000e-05  Data: 0.004 (0.016)\n",
            "Train: 45 [ 150/1562 ( 10%)]  Loss:  1.962626 (1.8092)  Time: 0.286s,  111.91/s  (0.298s,  107.50/s)  LR: 1.000e-05  Data: 0.004 (0.012)\n",
            "Train: 45 [ 200/1562 ( 13%)]  Loss:  2.162740 (1.7892)  Time: 0.287s,  111.39/s  (0.295s,  108.47/s)  LR: 1.000e-05  Data: 0.004 (0.010)\n",
            "Train: 45 [ 250/1562 ( 16%)]  Loss:  1.712347 (1.7847)  Time: 0.285s,  112.11/s  (0.293s,  109.05/s)  LR: 1.000e-05  Data: 0.004 (0.009)\n",
            "Train: 45 [ 300/1562 ( 19%)]  Loss:  1.828834 (1.7850)  Time: 0.286s,  111.98/s  (0.292s,  109.46/s)  LR: 1.000e-05  Data: 0.004 (0.008)\n",
            "Train: 45 [ 350/1562 ( 22%)]  Loss:  1.911572 (1.7682)  Time: 0.293s,  109.38/s  (0.292s,  109.70/s)  LR: 1.000e-05  Data: 0.004 (0.007)\n",
            "Train: 45 [ 400/1562 ( 26%)]  Loss:  1.887582 (1.7554)  Time: 0.289s,  110.71/s  (0.291s,  109.91/s)  LR: 1.000e-05  Data: 0.004 (0.007)\n",
            "Train: 45 [ 450/1562 ( 29%)]  Loss:  2.017947 (1.7517)  Time: 0.287s,  111.48/s  (0.291s,  110.07/s)  LR: 1.000e-05  Data: 0.004 (0.007)\n",
            "Train: 45 [ 500/1562 ( 32%)]  Loss:  1.675645 (1.7551)  Time: 0.286s,  111.92/s  (0.290s,  110.19/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 45 [ 550/1562 ( 35%)]  Loss:  1.713881 (1.7491)  Time: 0.293s,  109.09/s  (0.290s,  110.31/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 45 [ 600/1562 ( 38%)]  Loss:  1.908435 (1.7458)  Time: 0.286s,  111.87/s  (0.290s,  110.39/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 45 [ 650/1562 ( 42%)]  Loss:  1.532338 (1.7478)  Time: 0.286s,  112.00/s  (0.290s,  110.48/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 45 [ 700/1562 ( 45%)]  Loss:  1.709854 (1.7513)  Time: 0.287s,  111.68/s  (0.289s,  110.55/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 45 [ 750/1562 ( 48%)]  Loss:  1.401340 (1.7578)  Time: 0.286s,  111.75/s  (0.289s,  110.61/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 45 [ 800/1562 ( 51%)]  Loss:  1.663957 (1.7604)  Time: 0.286s,  111.71/s  (0.289s,  110.64/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 45 [ 850/1562 ( 54%)]  Loss:  1.990725 (1.7689)  Time: 0.289s,  110.66/s  (0.289s,  110.69/s)  LR: 1.000e-05  Data: 0.007 (0.005)\n",
            "Train: 45 [ 900/1562 ( 58%)]  Loss:  1.616622 (1.7739)  Time: 0.286s,  111.83/s  (0.289s,  110.74/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 45 [ 950/1562 ( 61%)]  Loss:  1.542369 (1.7705)  Time: 0.295s,  108.55/s  (0.289s,  110.76/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 45 [1000/1562 ( 64%)]  Loss:  1.735271 (1.7732)  Time: 0.286s,  112.00/s  (0.289s,  110.80/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 45 [1050/1562 ( 67%)]  Loss:  1.426571 (1.7803)  Time: 0.287s,  111.35/s  (0.289s,  110.82/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 45 [1100/1562 ( 70%)]  Loss:  2.148238 (1.7837)  Time: 0.287s,  111.43/s  (0.289s,  110.84/s)  LR: 1.000e-05  Data: 0.005 (0.005)\n",
            "Train: 45 [1150/1562 ( 74%)]  Loss:  2.084008 (1.7952)  Time: 0.286s,  111.74/s  (0.289s,  110.87/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 45 [1200/1562 ( 77%)]  Loss:  1.611345 (1.8028)  Time: 0.289s,  110.64/s  (0.289s,  110.89/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 45 [1250/1562 ( 80%)]  Loss:  1.801294 (1.8019)  Time: 0.286s,  111.84/s  (0.289s,  110.91/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 45 [1300/1562 ( 83%)]  Loss:  1.318524 (1.8044)  Time: 0.294s,  108.66/s  (0.289s,  110.92/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 45 [1350/1562 ( 86%)]  Loss:  1.989118 (1.8066)  Time: 0.296s,  108.18/s  (0.288s,  110.94/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 45 [1400/1562 ( 90%)]  Loss:  2.014697 (1.8003)  Time: 0.287s,  111.66/s  (0.288s,  110.94/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 45 [1450/1562 ( 93%)]  Loss:  1.951947 (1.8016)  Time: 0.286s,  111.82/s  (0.288s,  110.96/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 45 [1500/1562 ( 96%)]  Loss:  2.000085 (1.8041)  Time: 0.286s,  111.72/s  (0.288s,  110.98/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 45 [1550/1562 ( 99%)]  Loss:  1.676111 (1.8032)  Time: 0.284s,  112.77/s  (0.288s,  110.99/s)  LR: 1.000e-05  Data: 0.003 (0.005)\n",
            "Train: 45 [1561/1562 (100%)]  Loss:  1.819558 (1.8015)  Time: 0.379s,   84.36/s  (0.288s,  110.98/s)  LR: 1.000e-05  Data: 0.092 (0.005)\n",
            "Test: [   0/312]  Time: 0.965 (0.965)  Loss:  1.0185 (1.0185)  Acc@1: 68.7500 (68.7500)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [  50/312]  Time: 0.097 (0.114)  Loss:  0.3990 (0.6332)  Acc@1: 87.5000 (82.9044)  Acc@5: 100.0000 (98.7745)\n",
            "Test: [ 100/312]  Time: 0.094 (0.103)  Loss:  1.2668 (0.8075)  Acc@1: 56.2500 (75.6498)  Acc@5: 96.8750 (98.2054)\n",
            "Test: [ 150/312]  Time: 0.094 (0.100)  Loss:  1.3781 (0.9574)  Acc@1: 46.8750 (68.8535)  Acc@5: 96.8750 (97.8684)\n",
            "Test: [ 200/312]  Time: 0.087 (0.098)  Loss:  0.7166 (0.9610)  Acc@1: 81.2500 (68.8588)  Acc@5: 100.0000 (97.7767)\n",
            "Test: [ 250/312]  Time: 0.106 (0.097)  Loss:  0.4160 (0.8956)  Acc@1: 96.8750 (72.0369)  Acc@5: 96.8750 (97.8586)\n",
            "Test: [ 300/312]  Time: 0.086 (0.096)  Loss:  0.3527 (0.8505)  Acc@1: 96.8750 (73.8372)  Acc@5: 100.0000 (97.8821)\n",
            "Test: [ 312/312]  Time: 0.142 (0.096)  Loss:  0.5094 (0.8407)  Acc@1: 87.5000 (74.2100)  Acc@5: 100.0000 (97.9400)\n",
            "Test (EMA): [   0/312]  Time: 0.953 (0.953)  Loss:  1.0444 (1.0444)  Acc@1: 75.0000 (75.0000)  Acc@5: 96.8750 (96.8750)\n",
            "Test (EMA): [  50/312]  Time: 0.087 (0.113)  Loss:  0.5894 (0.7070)  Acc@1: 78.1250 (80.0858)  Acc@5: 100.0000 (98.6520)\n",
            "Test (EMA): [ 100/312]  Time: 0.087 (0.103)  Loss:  1.2318 (0.9264)  Acc@1: 62.5000 (71.4109)  Acc@5: 96.8750 (97.9579)\n",
            "Test (EMA): [ 150/312]  Time: 0.093 (0.100)  Loss:  1.4694 (1.0412)  Acc@1: 40.6250 (66.9495)  Acc@5: 100.0000 (97.7856)\n",
            "Test (EMA): [ 200/312]  Time: 0.092 (0.098)  Loss:  0.7520 (1.0570)  Acc@1: 81.2500 (66.0603)  Acc@5: 100.0000 (97.6679)\n",
            "Test (EMA): [ 250/312]  Time: 0.087 (0.097)  Loss:  0.5530 (0.9898)  Acc@1: 90.6250 (69.0986)  Acc@5: 100.0000 (97.6967)\n",
            "Test (EMA): [ 300/312]  Time: 0.086 (0.096)  Loss:  0.3665 (0.9362)  Acc@1: 93.7500 (71.4182)  Acc@5: 100.0000 (97.7159)\n",
            "Test (EMA): [ 312/312]  Time: 0.133 (0.096)  Loss:  0.5803 (0.9232)  Acc@1: 87.5000 (71.9600)  Acc@5: 100.0000 (97.7800)\n",
            "Current checkpoints:\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-45.pth.tar', 71.96)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-44.pth.tar', 71.62)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-43.pth.tar', 71.18)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-42.pth.tar', 70.94)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-41.pth.tar', 70.46)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-40.pth.tar', 70.07)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-39.pth.tar', 69.63)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-38.pth.tar', 69.14)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-37.pth.tar', 68.6)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-36.pth.tar', 68.16)\n",
            "\n",
            "Train: 46 [   0/1562 (  0%)]  Loss:  1.669189 (1.6692)  Time: 1.686s,   18.98/s  (1.686s,   18.98/s)  LR: 1.000e-05  Data: 1.204 (1.204)\n",
            "Train: 46 [  50/1562 (  3%)]  Loss:  1.561689 (1.8676)  Time: 0.286s,  111.85/s  (0.317s,  100.85/s)  LR: 1.000e-05  Data: 0.004 (0.027)\n",
            "Train: 46 [ 100/1562 (  6%)]  Loss:  1.605087 (1.8118)  Time: 0.286s,  111.82/s  (0.303s,  105.76/s)  LR: 1.000e-05  Data: 0.004 (0.016)\n",
            "Train: 46 [ 150/1562 ( 10%)]  Loss:  2.024404 (1.8284)  Time: 0.286s,  111.92/s  (0.298s,  107.33/s)  LR: 1.000e-05  Data: 0.004 (0.012)\n",
            "Train: 46 [ 200/1562 ( 13%)]  Loss:  1.908465 (1.8110)  Time: 0.286s,  111.99/s  (0.295s,  108.29/s)  LR: 1.000e-05  Data: 0.004 (0.010)\n",
            "Train: 46 [ 250/1562 ( 16%)]  Loss:  1.795477 (1.8027)  Time: 0.286s,  111.92/s  (0.294s,  108.89/s)  LR: 1.000e-05  Data: 0.004 (0.009)\n",
            "Train: 46 [ 300/1562 ( 19%)]  Loss:  1.941430 (1.8035)  Time: 0.286s,  111.79/s  (0.293s,  109.26/s)  LR: 1.000e-05  Data: 0.004 (0.008)\n",
            "Train: 46 [ 350/1562 ( 22%)]  Loss:  1.749445 (1.7819)  Time: 0.287s,  111.40/s  (0.292s,  109.54/s)  LR: 1.000e-05  Data: 0.004 (0.007)\n",
            "Train: 46 [ 400/1562 ( 26%)]  Loss:  2.187753 (1.7642)  Time: 0.287s,  111.55/s  (0.292s,  109.71/s)  LR: 1.000e-05  Data: 0.004 (0.007)\n",
            "Train: 46 [ 450/1562 ( 29%)]  Loss:  2.292364 (1.7621)  Time: 0.290s,  110.53/s  (0.291s,  109.85/s)  LR: 1.000e-05  Data: 0.004 (0.007)\n",
            "Train: 46 [ 500/1562 ( 32%)]  Loss:  1.400012 (1.7610)  Time: 0.286s,  111.85/s  (0.291s,  110.00/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 46 [ 550/1562 ( 35%)]  Loss:  1.659117 (1.7560)  Time: 0.290s,  110.36/s  (0.291s,  110.11/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 46 [ 600/1562 ( 38%)]  Loss:  2.018362 (1.7533)  Time: 0.286s,  111.82/s  (0.290s,  110.21/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 46 [ 650/1562 ( 42%)]  Loss:  1.549822 (1.7550)  Time: 0.287s,  111.42/s  (0.290s,  110.27/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 46 [ 700/1562 ( 45%)]  Loss:  1.448890 (1.7556)  Time: 0.287s,  111.67/s  (0.290s,  110.33/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 46 [ 750/1562 ( 48%)]  Loss:  1.372369 (1.7635)  Time: 0.286s,  112.00/s  (0.290s,  110.38/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 46 [ 800/1562 ( 51%)]  Loss:  1.363406 (1.7669)  Time: 0.286s,  111.86/s  (0.290s,  110.43/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 46 [ 850/1562 ( 54%)]  Loss:  2.008592 (1.7758)  Time: 0.286s,  111.86/s  (0.290s,  110.49/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 46 [ 900/1562 ( 58%)]  Loss:  1.678534 (1.7793)  Time: 0.294s,  108.78/s  (0.289s,  110.54/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 46 [ 950/1562 ( 61%)]  Loss:  1.648801 (1.7762)  Time: 0.286s,  111.75/s  (0.289s,  110.59/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 46 [1000/1562 ( 64%)]  Loss:  2.262939 (1.7796)  Time: 0.286s,  111.81/s  (0.289s,  110.63/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 46 [1050/1562 ( 67%)]  Loss:  1.545134 (1.7856)  Time: 0.290s,  110.52/s  (0.289s,  110.65/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 46 [1100/1562 ( 70%)]  Loss:  2.073004 (1.7894)  Time: 0.285s,  112.13/s  (0.289s,  110.69/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 46 [1150/1562 ( 74%)]  Loss:  1.918267 (1.7994)  Time: 0.286s,  111.83/s  (0.289s,  110.72/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 46 [1200/1562 ( 77%)]  Loss:  1.416570 (1.8069)  Time: 0.287s,  111.68/s  (0.289s,  110.75/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 46 [1250/1562 ( 80%)]  Loss:  1.928179 (1.8055)  Time: 0.286s,  111.88/s  (0.289s,  110.76/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 46 [1300/1562 ( 83%)]  Loss:  1.759459 (1.8085)  Time: 0.286s,  111.71/s  (0.289s,  110.78/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 46 [1350/1562 ( 86%)]  Loss:  1.803135 (1.8099)  Time: 0.287s,  111.64/s  (0.289s,  110.80/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 46 [1400/1562 ( 90%)]  Loss:  1.949966 (1.8056)  Time: 0.287s,  111.60/s  (0.289s,  110.83/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 46 [1450/1562 ( 93%)]  Loss:  1.903759 (1.8081)  Time: 0.287s,  111.46/s  (0.289s,  110.85/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 46 [1500/1562 ( 96%)]  Loss:  1.920357 (1.8092)  Time: 0.287s,  111.59/s  (0.289s,  110.85/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 46 [1550/1562 ( 99%)]  Loss:  1.698673 (1.8060)  Time: 0.283s,  113.14/s  (0.289s,  110.87/s)  LR: 1.000e-05  Data: 0.003 (0.005)\n",
            "Train: 46 [1561/1562 (100%)]  Loss:  1.701140 (1.8041)  Time: 0.373s,   85.71/s  (0.289s,  110.86/s)  LR: 1.000e-05  Data: 0.089 (0.005)\n",
            "Test: [   0/312]  Time: 0.919 (0.919)  Loss:  1.0116 (1.0116)  Acc@1: 65.6250 (65.6250)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [  50/312]  Time: 0.087 (0.114)  Loss:  0.4339 (0.6088)  Acc@1: 84.3750 (82.9044)  Acc@5: 100.0000 (99.0809)\n",
            "Test: [ 100/312]  Time: 0.101 (0.103)  Loss:  1.1328 (0.8235)  Acc@1: 62.5000 (73.9480)  Acc@5: 100.0000 (98.0507)\n",
            "Test: [ 150/312]  Time: 0.093 (0.100)  Loss:  1.4651 (0.9530)  Acc@1: 50.0000 (68.5637)  Acc@5: 96.8750 (97.8063)\n",
            "Test: [ 200/312]  Time: 0.093 (0.098)  Loss:  0.8117 (0.9533)  Acc@1: 78.1250 (69.0299)  Acc@5: 100.0000 (97.7923)\n",
            "Test: [ 250/312]  Time: 0.092 (0.097)  Loss:  0.3954 (0.8946)  Acc@1: 96.8750 (71.8127)  Acc@5: 100.0000 (97.8337)\n",
            "Test: [ 300/312]  Time: 0.086 (0.096)  Loss:  0.2840 (0.8380)  Acc@1: 96.8750 (74.0656)  Acc@5: 100.0000 (97.9755)\n",
            "Test: [ 312/312]  Time: 0.135 (0.096)  Loss:  0.4604 (0.8240)  Acc@1: 93.7500 (74.6300)  Acc@5: 100.0000 (98.0400)\n",
            "Test (EMA): [   0/312]  Time: 0.811 (0.811)  Loss:  1.0379 (1.0379)  Acc@1: 75.0000 (75.0000)  Acc@5: 96.8750 (96.8750)\n",
            "Test (EMA): [  50/312]  Time: 0.096 (0.112)  Loss:  0.5773 (0.6979)  Acc@1: 78.1250 (80.3922)  Acc@5: 100.0000 (98.5907)\n",
            "Test (EMA): [ 100/312]  Time: 0.087 (0.102)  Loss:  1.2241 (0.9158)  Acc@1: 65.6250 (71.7203)  Acc@5: 96.8750 (97.9270)\n",
            "Test (EMA): [ 150/312]  Time: 0.093 (0.099)  Loss:  1.4636 (1.0325)  Acc@1: 40.6250 (67.1565)  Acc@5: 100.0000 (97.7649)\n",
            "Test (EMA): [ 200/312]  Time: 0.096 (0.098)  Loss:  0.7494 (1.0475)  Acc@1: 81.2500 (66.2469)  Acc@5: 100.0000 (97.6835)\n",
            "Test (EMA): [ 250/312]  Time: 0.093 (0.097)  Loss:  0.5383 (0.9808)  Acc@1: 90.6250 (69.3476)  Acc@5: 100.0000 (97.7092)\n",
            "Test (EMA): [ 300/312]  Time: 0.087 (0.096)  Loss:  0.3595 (0.9271)  Acc@1: 93.7500 (71.6466)  Acc@5: 100.0000 (97.7263)\n",
            "Test (EMA): [ 312/312]  Time: 0.133 (0.096)  Loss:  0.5693 (0.9142)  Acc@1: 87.5000 (72.1900)  Acc@5: 100.0000 (97.7900)\n",
            "Current checkpoints:\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-46.pth.tar', 72.19)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-45.pth.tar', 71.96)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-44.pth.tar', 71.62)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-43.pth.tar', 71.18)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-42.pth.tar', 70.94)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-41.pth.tar', 70.46)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-40.pth.tar', 70.07)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-39.pth.tar', 69.63)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-38.pth.tar', 69.14)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-37.pth.tar', 68.6)\n",
            "\n",
            "Train: 47 [   0/1562 (  0%)]  Loss:  1.483734 (1.4837)  Time: 1.580s,   20.25/s  (1.580s,   20.25/s)  LR: 1.000e-05  Data: 1.097 (1.097)\n",
            "Train: 47 [  50/1562 (  3%)]  Loss:  1.312719 (1.8560)  Time: 0.286s,  111.86/s  (0.318s,  100.69/s)  LR: 1.000e-05  Data: 0.004 (0.026)\n",
            "Train: 47 [ 100/1562 (  6%)]  Loss:  1.392563 (1.8038)  Time: 0.287s,  111.45/s  (0.303s,  105.57/s)  LR: 1.000e-05  Data: 0.004 (0.015)\n",
            "Train: 47 [ 150/1562 ( 10%)]  Loss:  1.864746 (1.8125)  Time: 0.286s,  111.95/s  (0.298s,  107.45/s)  LR: 1.000e-05  Data: 0.004 (0.011)\n",
            "Train: 47 [ 200/1562 ( 13%)]  Loss:  1.985558 (1.7968)  Time: 0.286s,  111.98/s  (0.295s,  108.38/s)  LR: 1.000e-05  Data: 0.004 (0.010)\n",
            "Train: 47 [ 250/1562 ( 16%)]  Loss:  1.452491 (1.7924)  Time: 0.286s,  112.01/s  (0.294s,  108.96/s)  LR: 1.000e-05  Data: 0.004 (0.008)\n",
            "Train: 47 [ 300/1562 ( 19%)]  Loss:  2.091882 (1.7890)  Time: 0.287s,  111.69/s  (0.293s,  109.35/s)  LR: 1.000e-05  Data: 0.004 (0.008)\n",
            "Train: 47 [ 350/1562 ( 22%)]  Loss:  1.613825 (1.7729)  Time: 0.287s,  111.54/s  (0.292s,  109.63/s)  LR: 1.000e-05  Data: 0.004 (0.007)\n",
            "Train: 47 [ 400/1562 ( 26%)]  Loss:  2.110201 (1.7576)  Time: 0.286s,  111.78/s  (0.291s,  109.86/s)  LR: 1.000e-05  Data: 0.004 (0.007)\n",
            "Train: 47 [ 450/1562 ( 29%)]  Loss:  1.994521 (1.7544)  Time: 0.286s,  111.88/s  (0.291s,  110.02/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 47 [ 500/1562 ( 32%)]  Loss:  1.427409 (1.7525)  Time: 0.286s,  111.75/s  (0.291s,  110.15/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 47 [ 550/1562 ( 35%)]  Loss:  1.642537 (1.7496)  Time: 0.288s,  110.97/s  (0.290s,  110.26/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 47 [ 600/1562 ( 38%)]  Loss:  2.216144 (1.7437)  Time: 0.286s,  111.78/s  (0.290s,  110.33/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 47 [ 650/1562 ( 42%)]  Loss:  1.630674 (1.7454)  Time: 0.291s,  109.94/s  (0.290s,  110.41/s)  LR: 1.000e-05  Data: 0.009 (0.006)\n",
            "Train: 47 [ 700/1562 ( 45%)]  Loss:  1.685012 (1.7494)  Time: 0.286s,  111.72/s  (0.290s,  110.47/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 47 [ 750/1562 ( 48%)]  Loss:  1.583384 (1.7566)  Time: 0.289s,  110.69/s  (0.290s,  110.53/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 47 [ 800/1562 ( 51%)]  Loss:  1.441173 (1.7577)  Time: 0.286s,  111.88/s  (0.289s,  110.58/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 47 [ 850/1562 ( 54%)]  Loss:  1.872016 (1.7685)  Time: 0.286s,  111.74/s  (0.289s,  110.63/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 47 [ 900/1562 ( 58%)]  Loss:  1.812582 (1.7719)  Time: 0.286s,  111.76/s  (0.289s,  110.65/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 47 [ 950/1562 ( 61%)]  Loss:  1.429996 (1.7702)  Time: 0.287s,  111.54/s  (0.289s,  110.69/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 47 [1000/1562 ( 64%)]  Loss:  2.042306 (1.7729)  Time: 0.286s,  111.72/s  (0.289s,  110.71/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 47 [1050/1562 ( 67%)]  Loss:  1.600405 (1.7796)  Time: 0.287s,  111.31/s  (0.289s,  110.72/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 47 [1100/1562 ( 70%)]  Loss:  1.974291 (1.7820)  Time: 0.287s,  111.38/s  (0.289s,  110.74/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 47 [1150/1562 ( 74%)]  Loss:  1.965350 (1.7919)  Time: 0.287s,  111.68/s  (0.289s,  110.75/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 47 [1200/1562 ( 77%)]  Loss:  1.484508 (1.8007)  Time: 0.287s,  111.66/s  (0.289s,  110.77/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 47 [1250/1562 ( 80%)]  Loss:  1.872854 (1.8009)  Time: 0.287s,  111.43/s  (0.289s,  110.80/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 47 [1300/1562 ( 83%)]  Loss:  1.733588 (1.8046)  Time: 0.287s,  111.56/s  (0.289s,  110.82/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 47 [1350/1562 ( 86%)]  Loss:  1.884352 (1.8063)  Time: 0.293s,  109.16/s  (0.289s,  110.83/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 47 [1400/1562 ( 90%)]  Loss:  1.978594 (1.8006)  Time: 0.288s,  111.23/s  (0.289s,  110.85/s)  LR: 1.000e-05  Data: 0.005 (0.005)\n",
            "Train: 47 [1450/1562 ( 93%)]  Loss:  1.909555 (1.8020)  Time: 0.286s,  111.82/s  (0.289s,  110.87/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 47 [1500/1562 ( 96%)]  Loss:  1.901246 (1.8027)  Time: 0.287s,  111.62/s  (0.289s,  110.90/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 47 [1550/1562 ( 99%)]  Loss:  1.498115 (1.8007)  Time: 0.284s,  112.56/s  (0.288s,  110.92/s)  LR: 1.000e-05  Data: 0.003 (0.005)\n",
            "Train: 47 [1561/1562 (100%)]  Loss:  1.665298 (1.7991)  Time: 0.370s,   86.59/s  (0.289s,  110.91/s)  LR: 1.000e-05  Data: 0.090 (0.005)\n",
            "Test: [   0/312]  Time: 0.881 (0.881)  Loss:  0.9683 (0.9683)  Acc@1: 68.7500 (68.7500)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [  50/312]  Time: 0.087 (0.111)  Loss:  0.4183 (0.5918)  Acc@1: 87.5000 (84.3750)  Acc@5: 100.0000 (98.8971)\n",
            "Test: [ 100/312]  Time: 0.097 (0.102)  Loss:  1.1679 (0.8040)  Acc@1: 65.6250 (75.4332)  Acc@5: 96.8750 (98.0507)\n",
            "Test: [ 150/312]  Time: 0.087 (0.099)  Loss:  1.2762 (0.9203)  Acc@1: 56.2500 (70.3022)  Acc@5: 96.8750 (97.7649)\n",
            "Test: [ 200/312]  Time: 0.101 (0.098)  Loss:  0.7844 (0.9167)  Acc@1: 84.3750 (70.9111)  Acc@5: 100.0000 (97.8700)\n",
            "Test: [ 250/312]  Time: 0.093 (0.097)  Loss:  0.4432 (0.8800)  Acc@1: 93.7500 (72.8337)  Acc@5: 96.8750 (97.8461)\n",
            "Test: [ 300/312]  Time: 0.086 (0.096)  Loss:  0.3004 (0.8346)  Acc@1: 96.8750 (74.5743)  Acc@5: 100.0000 (97.9547)\n",
            "Test: [ 312/312]  Time: 0.136 (0.096)  Loss:  0.4728 (0.8223)  Acc@1: 87.5000 (75.1000)  Acc@5: 100.0000 (98.0200)\n",
            "Test (EMA): [   0/312]  Time: 0.740 (0.740)  Loss:  1.0305 (1.0305)  Acc@1: 75.0000 (75.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test (EMA): [  50/312]  Time: 0.096 (0.111)  Loss:  0.5674 (0.6889)  Acc@1: 78.1250 (80.7598)  Acc@5: 100.0000 (98.7132)\n",
            "Test (EMA): [ 100/312]  Time: 0.097 (0.102)  Loss:  1.2171 (0.9057)  Acc@1: 65.6250 (72.1535)  Acc@5: 96.8750 (97.9889)\n",
            "Test (EMA): [ 150/312]  Time: 0.096 (0.099)  Loss:  1.4550 (1.0240)  Acc@1: 37.5000 (67.4255)  Acc@5: 100.0000 (97.8270)\n",
            "Test (EMA): [ 200/312]  Time: 0.101 (0.098)  Loss:  0.7483 (1.0382)  Acc@1: 81.2500 (66.6200)  Acc@5: 100.0000 (97.7301)\n",
            "Test (EMA): [ 250/312]  Time: 0.088 (0.097)  Loss:  0.5245 (0.9722)  Acc@1: 90.6250 (69.6589)  Acc@5: 100.0000 (97.7465)\n",
            "Test (EMA): [ 300/312]  Time: 0.086 (0.096)  Loss:  0.3538 (0.9186)  Acc@1: 93.7500 (71.9269)  Acc@5: 100.0000 (97.7679)\n",
            "Test (EMA): [ 312/312]  Time: 0.132 (0.096)  Loss:  0.5593 (0.9057)  Acc@1: 87.5000 (72.4700)  Acc@5: 100.0000 (97.8300)\n",
            "Current checkpoints:\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-47.pth.tar', 72.47)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-46.pth.tar', 72.19)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-45.pth.tar', 71.96)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-44.pth.tar', 71.62)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-43.pth.tar', 71.18)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-42.pth.tar', 70.94)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-41.pth.tar', 70.46)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-40.pth.tar', 70.07)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-39.pth.tar', 69.63)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-38.pth.tar', 69.14)\n",
            "\n",
            "Train: 48 [   0/1562 (  0%)]  Loss:  1.704392 (1.7044)  Time: 1.609s,   19.89/s  (1.609s,   19.89/s)  LR: 1.000e-05  Data: 1.147 (1.147)\n",
            "Train: 48 [  50/1562 (  3%)]  Loss:  1.404389 (1.8568)  Time: 0.286s,  111.70/s  (0.318s,  100.66/s)  LR: 1.000e-05  Data: 0.004 (0.027)\n",
            "Train: 48 [ 100/1562 (  6%)]  Loss:  1.636815 (1.7965)  Time: 0.286s,  111.84/s  (0.303s,  105.56/s)  LR: 1.000e-05  Data: 0.004 (0.016)\n",
            "Train: 48 [ 150/1562 ( 10%)]  Loss:  2.040488 (1.8093)  Time: 0.286s,  111.70/s  (0.298s,  107.40/s)  LR: 1.000e-05  Data: 0.004 (0.012)\n",
            "Train: 48 [ 200/1562 ( 13%)]  Loss:  1.956872 (1.7985)  Time: 0.287s,  111.65/s  (0.295s,  108.36/s)  LR: 1.000e-05  Data: 0.004 (0.010)\n",
            "Train: 48 [ 250/1562 ( 16%)]  Loss:  1.428989 (1.7962)  Time: 0.286s,  111.93/s  (0.294s,  108.97/s)  LR: 1.000e-05  Data: 0.004 (0.009)\n",
            "Train: 48 [ 300/1562 ( 19%)]  Loss:  1.868161 (1.7971)  Time: 0.286s,  111.90/s  (0.293s,  109.33/s)  LR: 1.000e-05  Data: 0.004 (0.008)\n",
            "Train: 48 [ 350/1562 ( 22%)]  Loss:  1.563355 (1.7704)  Time: 0.286s,  111.76/s  (0.292s,  109.59/s)  LR: 1.000e-05  Data: 0.004 (0.007)\n",
            "Train: 48 [ 400/1562 ( 26%)]  Loss:  2.138507 (1.7505)  Time: 0.287s,  111.60/s  (0.291s,  109.83/s)  LR: 1.000e-05  Data: 0.004 (0.007)\n",
            "Train: 48 [ 450/1562 ( 29%)]  Loss:  1.950174 (1.7512)  Time: 0.287s,  111.69/s  (0.291s,  110.00/s)  LR: 1.000e-05  Data: 0.004 (0.007)\n",
            "Train: 48 [ 500/1562 ( 32%)]  Loss:  1.429395 (1.7522)  Time: 0.286s,  111.73/s  (0.291s,  110.12/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 48 [ 550/1562 ( 35%)]  Loss:  1.620781 (1.7465)  Time: 0.294s,  108.72/s  (0.290s,  110.25/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 48 [ 600/1562 ( 38%)]  Loss:  1.988016 (1.7412)  Time: 0.287s,  111.66/s  (0.290s,  110.34/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 48 [ 650/1562 ( 42%)]  Loss:  1.477879 (1.7464)  Time: 0.289s,  110.74/s  (0.290s,  110.40/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 48 [ 700/1562 ( 45%)]  Loss:  1.329427 (1.7497)  Time: 0.286s,  111.82/s  (0.290s,  110.46/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 48 [ 750/1562 ( 48%)]  Loss:  1.653048 (1.7569)  Time: 0.286s,  111.83/s  (0.290s,  110.52/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 48 [ 800/1562 ( 51%)]  Loss:  1.591003 (1.7599)  Time: 0.286s,  111.70/s  (0.289s,  110.56/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 48 [ 850/1562 ( 54%)]  Loss:  2.034878 (1.7675)  Time: 0.286s,  111.73/s  (0.289s,  110.61/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 48 [ 900/1562 ( 58%)]  Loss:  1.324178 (1.7704)  Time: 0.294s,  108.83/s  (0.289s,  110.64/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 48 [ 950/1562 ( 61%)]  Loss:  1.393175 (1.7693)  Time: 0.291s,  110.03/s  (0.289s,  110.67/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 48 [1000/1562 ( 64%)]  Loss:  2.024724 (1.7713)  Time: 0.287s,  111.61/s  (0.289s,  110.69/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 48 [1050/1562 ( 67%)]  Loss:  1.481847 (1.7777)  Time: 0.288s,  111.06/s  (0.289s,  110.71/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 48 [1100/1562 ( 70%)]  Loss:  2.041955 (1.7809)  Time: 0.288s,  111.25/s  (0.289s,  110.72/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 48 [1150/1562 ( 74%)]  Loss:  1.890093 (1.7919)  Time: 0.288s,  111.26/s  (0.289s,  110.73/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 48 [1200/1562 ( 77%)]  Loss:  1.480769 (1.7991)  Time: 0.287s,  111.35/s  (0.289s,  110.74/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 48 [1250/1562 ( 80%)]  Loss:  1.959983 (1.8001)  Time: 0.292s,  109.44/s  (0.289s,  110.75/s)  LR: 1.000e-05  Data: 0.007 (0.005)\n",
            "Train: 48 [1300/1562 ( 83%)]  Loss:  1.657725 (1.8036)  Time: 0.288s,  111.08/s  (0.289s,  110.77/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 48 [1350/1562 ( 86%)]  Loss:  1.999040 (1.8044)  Time: 0.287s,  111.55/s  (0.289s,  110.78/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 48 [1400/1562 ( 90%)]  Loss:  1.850536 (1.7994)  Time: 0.287s,  111.43/s  (0.289s,  110.78/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 48 [1450/1562 ( 93%)]  Loss:  1.980217 (1.8011)  Time: 0.290s,  110.27/s  (0.289s,  110.79/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 48 [1500/1562 ( 96%)]  Loss:  2.008310 (1.8022)  Time: 0.287s,  111.36/s  (0.289s,  110.80/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 48 [1550/1562 ( 99%)]  Loss:  1.356562 (1.7992)  Time: 0.286s,  111.88/s  (0.289s,  110.80/s)  LR: 1.000e-05  Data: 0.003 (0.005)\n",
            "Train: 48 [1561/1562 (100%)]  Loss:  1.881987 (1.7974)  Time: 0.372s,   85.93/s  (0.289s,  110.79/s)  LR: 1.000e-05  Data: 0.092 (0.005)\n",
            "Test: [   0/312]  Time: 0.781 (0.781)  Loss:  0.9811 (0.9811)  Acc@1: 65.6250 (65.6250)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [  50/312]  Time: 0.087 (0.114)  Loss:  0.4561 (0.6067)  Acc@1: 90.6250 (83.5784)  Acc@5: 100.0000 (98.7745)\n",
            "Test: [ 100/312]  Time: 0.102 (0.104)  Loss:  1.0908 (0.8286)  Acc@1: 65.6250 (74.0099)  Acc@5: 100.0000 (98.1436)\n",
            "Test: [ 150/312]  Time: 0.087 (0.100)  Loss:  1.4216 (0.9548)  Acc@1: 40.6250 (68.5224)  Acc@5: 96.8750 (97.9512)\n",
            "Test: [ 200/312]  Time: 0.088 (0.099)  Loss:  0.7920 (0.9476)  Acc@1: 78.1250 (69.0765)  Acc@5: 100.0000 (97.9167)\n",
            "Test: [ 250/312]  Time: 0.101 (0.098)  Loss:  0.3864 (0.8791)  Acc@1: 96.8750 (72.2361)  Acc@5: 96.8750 (97.9333)\n",
            "Test: [ 300/312]  Time: 0.086 (0.097)  Loss:  0.3141 (0.8285)  Acc@1: 96.8750 (74.3563)  Acc@5: 100.0000 (97.9859)\n",
            "Test: [ 312/312]  Time: 0.137 (0.097)  Loss:  0.4825 (0.8177)  Acc@1: 93.7500 (74.8500)  Acc@5: 100.0000 (98.0500)\n",
            "Test (EMA): [   0/312]  Time: 0.934 (0.934)  Loss:  1.0226 (1.0226)  Acc@1: 75.0000 (75.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test (EMA): [  50/312]  Time: 0.087 (0.114)  Loss:  0.5568 (0.6802)  Acc@1: 78.1250 (81.1887)  Acc@5: 100.0000 (98.7132)\n",
            "Test (EMA): [ 100/312]  Time: 0.104 (0.104)  Loss:  1.2108 (0.8967)  Acc@1: 65.6250 (72.6176)  Acc@5: 96.8750 (98.0817)\n",
            "Test (EMA): [ 150/312]  Time: 0.095 (0.100)  Loss:  1.4434 (1.0162)  Acc@1: 37.5000 (67.7980)  Acc@5: 100.0000 (97.9098)\n",
            "Test (EMA): [ 200/312]  Time: 0.096 (0.099)  Loss:  0.7455 (1.0297)  Acc@1: 81.2500 (67.0087)  Acc@5: 100.0000 (97.8389)\n",
            "Test (EMA): [ 250/312]  Time: 0.094 (0.097)  Loss:  0.5106 (0.9641)  Acc@1: 90.6250 (70.0199)  Acc@5: 100.0000 (97.8212)\n",
            "Test (EMA): [ 300/312]  Time: 0.086 (0.097)  Loss:  0.3479 (0.9105)  Acc@1: 93.7500 (72.2280)  Acc@5: 100.0000 (97.8405)\n",
            "Test (EMA): [ 312/312]  Time: 0.132 (0.096)  Loss:  0.5501 (0.8976)  Acc@1: 87.5000 (72.7700)  Acc@5: 100.0000 (97.9000)\n",
            "Current checkpoints:\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-48.pth.tar', 72.77)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-47.pth.tar', 72.47)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-46.pth.tar', 72.19)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-45.pth.tar', 71.96)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-44.pth.tar', 71.62)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-43.pth.tar', 71.18)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-42.pth.tar', 70.94)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-41.pth.tar', 70.46)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-40.pth.tar', 70.07)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-39.pth.tar', 69.63)\n",
            "\n",
            "Train: 49 [   0/1562 (  0%)]  Loss:  1.307523 (1.3075)  Time: 1.633s,   19.60/s  (1.633s,   19.60/s)  LR: 1.000e-05  Data: 1.186 (1.186)\n",
            "Train: 49 [  50/1562 (  3%)]  Loss:  1.361966 (1.8318)  Time: 0.287s,  111.58/s  (0.319s,  100.45/s)  LR: 1.000e-05  Data: 0.004 (0.028)\n",
            "Train: 49 [ 100/1562 (  6%)]  Loss:  1.628232 (1.7860)  Time: 0.288s,  110.92/s  (0.304s,  105.27/s)  LR: 1.000e-05  Data: 0.005 (0.016)\n",
            "Train: 49 [ 150/1562 ( 10%)]  Loss:  1.914506 (1.8001)  Time: 0.287s,  111.39/s  (0.299s,  107.05/s)  LR: 1.000e-05  Data: 0.004 (0.012)\n",
            "Train: 49 [ 200/1562 ( 13%)]  Loss:  1.782942 (1.7870)  Time: 0.287s,  111.40/s  (0.296s,  108.05/s)  LR: 1.000e-05  Data: 0.004 (0.010)\n",
            "Train: 49 [ 250/1562 ( 16%)]  Loss:  1.525444 (1.7795)  Time: 0.286s,  111.74/s  (0.295s,  108.65/s)  LR: 1.000e-05  Data: 0.004 (0.009)\n",
            "Train: 49 [ 300/1562 ( 19%)]  Loss:  1.827773 (1.7819)  Time: 0.290s,  110.23/s  (0.293s,  109.07/s)  LR: 1.000e-05  Data: 0.004 (0.008)\n",
            "Train: 49 [ 350/1562 ( 22%)]  Loss:  1.670959 (1.7612)  Time: 0.287s,  111.39/s  (0.293s,  109.36/s)  LR: 1.000e-05  Data: 0.004 (0.008)\n",
            "Train: 49 [ 400/1562 ( 26%)]  Loss:  1.952863 (1.7457)  Time: 0.288s,  111.30/s  (0.292s,  109.56/s)  LR: 1.000e-05  Data: 0.004 (0.007)\n",
            "Train: 49 [ 450/1562 ( 29%)]  Loss:  1.911063 (1.7426)  Time: 0.289s,  110.89/s  (0.292s,  109.73/s)  LR: 1.000e-05  Data: 0.004 (0.007)\n",
            "Train: 49 [ 500/1562 ( 32%)]  Loss:  1.526381 (1.7447)  Time: 0.287s,  111.46/s  (0.291s,  109.86/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 49 [ 550/1562 ( 35%)]  Loss:  1.759637 (1.7394)  Time: 0.290s,  110.34/s  (0.291s,  109.97/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 49 [ 600/1562 ( 38%)]  Loss:  1.946085 (1.7342)  Time: 0.287s,  111.44/s  (0.291s,  110.05/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 49 [ 650/1562 ( 42%)]  Loss:  1.359483 (1.7402)  Time: 0.288s,  111.28/s  (0.291s,  110.13/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 49 [ 700/1562 ( 45%)]  Loss:  1.756071 (1.7421)  Time: 0.287s,  111.59/s  (0.290s,  110.19/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 49 [ 750/1562 ( 48%)]  Loss:  1.511526 (1.7492)  Time: 0.287s,  111.56/s  (0.290s,  110.24/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 49 [ 800/1562 ( 51%)]  Loss:  1.694768 (1.7517)  Time: 0.287s,  111.50/s  (0.290s,  110.29/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 49 [ 850/1562 ( 54%)]  Loss:  1.991082 (1.7610)  Time: 0.287s,  111.43/s  (0.290s,  110.34/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 49 [ 900/1562 ( 58%)]  Loss:  1.785585 (1.7665)  Time: 0.288s,  111.26/s  (0.290s,  110.39/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 49 [ 950/1562 ( 61%)]  Loss:  1.601930 (1.7642)  Time: 0.287s,  111.38/s  (0.290s,  110.43/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 49 [1000/1562 ( 64%)]  Loss:  2.010486 (1.7675)  Time: 0.287s,  111.31/s  (0.290s,  110.47/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 49 [1050/1562 ( 67%)]  Loss:  1.379560 (1.7726)  Time: 0.292s,  109.77/s  (0.290s,  110.50/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 49 [1100/1562 ( 70%)]  Loss:  2.185483 (1.7758)  Time: 0.287s,  111.62/s  (0.290s,  110.52/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 49 [1150/1562 ( 74%)]  Loss:  2.108324 (1.7871)  Time: 0.287s,  111.36/s  (0.289s,  110.55/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 49 [1200/1562 ( 77%)]  Loss:  1.469792 (1.7941)  Time: 0.287s,  111.34/s  (0.289s,  110.58/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 49 [1250/1562 ( 80%)]  Loss:  2.114335 (1.7945)  Time: 0.287s,  111.61/s  (0.289s,  110.60/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 49 [1300/1562 ( 83%)]  Loss:  1.563729 (1.7981)  Time: 0.295s,  108.32/s  (0.289s,  110.62/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 49 [1350/1562 ( 86%)]  Loss:  2.066210 (1.7998)  Time: 0.288s,  111.30/s  (0.289s,  110.64/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 49 [1400/1562 ( 90%)]  Loss:  1.779714 (1.7943)  Time: 0.287s,  111.45/s  (0.289s,  110.65/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 49 [1450/1562 ( 93%)]  Loss:  1.956420 (1.7970)  Time: 0.291s,  110.05/s  (0.289s,  110.67/s)  LR: 1.000e-05  Data: 0.005 (0.005)\n",
            "Train: 49 [1500/1562 ( 96%)]  Loss:  2.064519 (1.7991)  Time: 0.288s,  110.98/s  (0.289s,  110.68/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 49 [1550/1562 ( 99%)]  Loss:  1.402105 (1.7967)  Time: 0.285s,  112.29/s  (0.289s,  110.69/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 49 [1561/1562 (100%)]  Loss:  1.954435 (1.7951)  Time: 0.380s,   84.20/s  (0.289s,  110.67/s)  LR: 1.000e-05  Data: 0.099 (0.005)\n",
            "Test: [   0/312]  Time: 0.965 (0.965)  Loss:  1.0378 (1.0378)  Acc@1: 65.6250 (65.6250)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [  50/312]  Time: 0.087 (0.115)  Loss:  0.4467 (0.6377)  Acc@1: 84.3750 (82.4755)  Acc@5: 100.0000 (98.7132)\n",
            "Test: [ 100/312]  Time: 0.100 (0.104)  Loss:  1.1879 (0.8214)  Acc@1: 65.6250 (74.7834)  Acc@5: 100.0000 (98.0507)\n",
            "Test: [ 150/312]  Time: 0.103 (0.101)  Loss:  1.2176 (0.9413)  Acc@1: 50.0000 (69.5571)  Acc@5: 96.8750 (97.7649)\n",
            "Test: [ 200/312]  Time: 0.097 (0.099)  Loss:  0.8628 (0.9361)  Acc@1: 71.8750 (70.1959)  Acc@5: 100.0000 (97.7456)\n",
            "Test: [ 250/312]  Time: 0.094 (0.098)  Loss:  0.3852 (0.8872)  Acc@1: 96.8750 (72.4602)  Acc@5: 100.0000 (97.7092)\n",
            "Test: [ 300/312]  Time: 0.086 (0.097)  Loss:  0.2908 (0.8318)  Acc@1: 96.8750 (74.6885)  Acc@5: 100.0000 (97.8509)\n",
            "Test: [ 312/312]  Time: 0.135 (0.097)  Loss:  0.4342 (0.8194)  Acc@1: 93.7500 (75.2200)  Acc@5: 100.0000 (97.9100)\n",
            "Test (EMA): [   0/312]  Time: 0.894 (0.894)  Loss:  1.0161 (1.0161)  Acc@1: 75.0000 (75.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test (EMA): [  50/312]  Time: 0.093 (0.113)  Loss:  0.5472 (0.6728)  Acc@1: 78.1250 (81.6176)  Acc@5: 100.0000 (98.7132)\n",
            "Test (EMA): [ 100/312]  Time: 0.091 (0.103)  Loss:  1.2029 (0.8881)  Acc@1: 65.6250 (72.9270)  Acc@5: 96.8750 (98.0817)\n",
            "Test (EMA): [ 150/312]  Time: 0.089 (0.100)  Loss:  1.4320 (1.0084)  Acc@1: 37.5000 (68.2533)  Acc@5: 100.0000 (97.8684)\n",
            "Test (EMA): [ 200/312]  Time: 0.091 (0.098)  Loss:  0.7445 (1.0214)  Acc@1: 81.2500 (67.5373)  Acc@5: 100.0000 (97.8078)\n",
            "Test (EMA): [ 250/312]  Time: 0.087 (0.097)  Loss:  0.4983 (0.9564)  Acc@1: 90.6250 (70.4930)  Acc@5: 100.0000 (97.7839)\n",
            "Test (EMA): [ 300/312]  Time: 0.086 (0.096)  Loss:  0.3428 (0.9028)  Acc@1: 93.7500 (72.6433)  Acc@5: 100.0000 (97.8094)\n",
            "Test (EMA): [ 312/312]  Time: 0.135 (0.096)  Loss:  0.5415 (0.8900)  Acc@1: 87.5000 (73.1800)  Acc@5: 100.0000 (97.8700)\n",
            "Current checkpoints:\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-49.pth.tar', 73.18)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-48.pth.tar', 72.77)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-47.pth.tar', 72.47)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-46.pth.tar', 72.19)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-45.pth.tar', 71.96)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-44.pth.tar', 71.62)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-43.pth.tar', 71.18)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-42.pth.tar', 70.94)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-41.pth.tar', 70.46)\n",
            " ('./output/train/20210219-072733-T2t_vit_14-224/checkpoint-40.pth.tar', 70.07)\n",
            "\n",
            "*** Best metric: 73.18 (epoch 49)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}